{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataai-text-A-PyTorch-RNN.ipynb","provenance":[],"collapsed_sections":[],"private_outputs":true,"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Wz9sZYV_mPPk"},"source":["---\n","> 「生まれ生まれ生まれ生まれて生の始めに暗く、死に死に死に死んで死の終わりに冥し」\n","> 空海\n","---"]},{"cell_type":"markdown","metadata":{"id":"OH7UbwZSgW8o"},"source":["再帰型ニューラルネットワーク(Reccurent)は自然言語処理の分野で高い成果をあげ、注目されている機械学習手法の一つ\n","\n","連続的な情報の利用\n","- 従来のニューラルネットワークは入力と出力データは互いに独立であるという考え\n","  - ポアソン過程的発想\n","- RNNは過去の影響を内部状態として保持し、出力データは入力と内部状態で決定するべきという考え\n","  - ステートマシーン的発想\n","\n","RNNは以前に計算された情報を覚えるための記憶力を備えているといえる\n","\n","理論的には長い期間に渡る記憶を利用できるが、工夫なく実際に実装すると2,3ステップくらい前の情報しか記憶に含むことができない\n","\n","この工夫は後で紹介するとして、その構造について触れる"]},{"cell_type":"markdown","metadata":{"id":"pzt7kv_7Y9_P"},"source":["# RNN"]},{"cell_type":"markdown","metadata":{"id":"Niaz8_W6OX34"},"source":["## RNNの構造\n","\n","PyTorchで単純な構造をもつ再帰型ニューラルネットワーク(Recurrent Neural Network:RNN)を構築する\n","\n","ややこしいが、Reccurrent NNとRecursive NNがあり、訳語はどちらも再帰型ニューラルネットワークであるが、一般にRNNはRecurrentを指す\n","- Recurcive NNは、出力にさらに別のモデルの入力が繋がるようなイメージ\n","\n","RNNの内部は次の図のような構造をもつ\n","\n","- 例えば、過去5日分のデータを使う、5ワードからなる文章を扱うなどで5個前まで見るとすると、1層1データ・ワードで5層のニューラルネットワークとしてみることができ、これをunfold、展開するという\n","- $x_t$は$t$ステップ目の入力、$s_t$は$t$ステップ時の隠れ要素でこの隠れ要素が記憶に相当する\n","- 入力に対する変換$U$、出力に対する変換$V$、それ以外のRNNの核心にあたるループに含まれる変換$W$というそれぞれの変換があるとき、\n","$$o_t=softmax(Vs_t)=softmax(Vf(Ux_x, Ws_{t-1}))$$\n","となる\n","  - unfoldしても$V, W, U$は唯一であり、$s_{t-1}$つまり一つ前の$s$を利用する点に注目する\n","  - $f$としてtanhやReLUなど比較的勾配消失に強い活性化関数が利用される\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/rnnnature.jpeg\" width=\"400\">\n","\n","なお、RNNを利用する際に、**最終出力(最も新しい段)のみ利用する手法**、例えば図が全ての展開であるならば、$o_{t+1}$のみ利用する手法と、**全出力を利用する手法**、つまり、同様に$o_{t-1}$、$o_t$、$o_{t+1}$の全てを利用する手法がある"]},{"cell_type":"markdown","metadata":{"id":"UpkvxybZ0m0l"},"source":["## RNNの応用例\n","\n","RNNが得意とする応用例は次の通り\n","- 言語モデルと文章生成\n","  - 言語モデルとして、連続した単語の羅列において、直前の単語を利用して次の単語の出現確率予測が可能であり、機械翻訳などに活用されている\n","  - 次の単語を予測できることから、出力の確率をサンプリングつまり、入力とすることで、さらに次の新しい単語をといった具合に全体で文章を生成するGenerativeなモデルが獲得できる\n","  - この学習においては、$O_t = x_{t+1}$として訓練する\n","    \n","- 機械翻訳\n","  - 言語モデルと似ているが、出力列は完全な入力列を読み込んだ後に処理を開始する点が異なる\n","\n","- スピーチ認識\n","  - 音波としての連続的音響信号を入力として連続的な音声セグメント(音素)を確率予測する\n","\n","- 画像の概要生成\n","  - CNNとRNNを用いることで、ラベルなし画像の概要生成(写真からその写真を説明する単語要素を生成する)が可能となる\n","\n","その他時系列情報を有するデータに広く応用可能であり、音声データ、動画解析、株価予測、機器の異常検出などにも応用されている"]},{"cell_type":"markdown","metadata":{"id":"vTnr-S4zHzDR"},"source":["## RNNの学習\n","\n","通常のNNと同様に学習させるが、RNNのパラメーターはunfoldされたネットワーク上の全ステップで利用されるため、ステップ毎の勾配計算の全てに同じ値を用い、過去に戻って勾配を足し合わせる必要がある\n","- Backpropagation Through Time (BPTT)と呼び、長いステップ、遠い過去程学習させるのが困難となる\n","- この問題を解決する手法としてLSTMなどが提案されている"]},{"cell_type":"markdown","metadata":{"id":"qVCvjpaaH1H4"},"source":["RNNにノイズを付与したサイン曲線を学習させ、曲線がどのように推移するかを予測させるとともに、その予測結果に基づいて曲線を描画させる\n","\n","- 学習により、主成分であるサイン曲線を学習し、ノイズのない滑らかな曲線を描くようになると予見される\n","\n","sinの式を教えずに、sinのブラフ(に類似した曲線)を得ることを目標とする"]},{"cell_type":"markdown","metadata":{"id":"LoISGl864sy9"},"source":["### 訓練用データの作成\n","\n","サイン曲線に正規分布に基づく乱数でノイズを加えてRNNに用いる訓練用のデータを作成する"]},{"cell_type":"code","metadata":{"id":"sQ1S5UNy-rpY"},"source":["cuda = \"cuda:0\"\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","sin_x = np.linspace(-2*np.pi, 2*np.pi)  # -2πから2πまで\n","sin_y = np.sin(sin_x)+np.random.normal(0, 0.3, len(sin_x))  # sin関数に乱数でノイズを加える\n","plt.plot(sin_x, sin_y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NyLBjYjr3RXu"},"source":["ノイズ付きサイン曲線の一部を入力とし、次の値を予測するようにRNNを訓練する"]},{"cell_type":"markdown","metadata":{"id":"vvRgf3-j2k76"},"source":["### データの前処理\n","入力、正解データをRNNに適した形に整形する\n","- 時系列データから次の値を予測できるように、時系列データを入力とし、正解をその時系列データの次の値とする\n","\n","`input_data = np.zeros((n_sample, n_time, 1))`は入力構造そのものである\n","- unfoldしたとき、段数がn_time\n","- 今回の入力はサイングラフのyの値一つのみ\n","- データを次々と入力するが、それがn_sample回\n","- 以上を表現すると、3次元配列で、`(n_sample, n_time, 1)`となる\n","\n","同様に`correct_data = np.zeros((n_sample, 1))`は、最後の(最新の)段の出力に対する正解データを示す\n","\n","次のforループで実際にデータを投入している\n","- pythonマジックがあり慣れないと？かもしれない\n","- `correct_data[i]`は要素一つなのに、`sin_y[i+n_time:i+n_time+1]`って要素2個じゃないの？とか他の言語を触っている人は考えてしまう、分かっていても考えてしまう\n","  - pythonフリークは、何がわからないのかさっぱりわからないであろう\n","- sin_y[0]はnumpyのfloatの値、sin_y[0:1]はnumpy arrayを返して0から1個分の配列なので、要素数が1となる\n","  - これを0から1までの配列と思うとハマる\n","  - 違いは、arrayかどうか\n","- このreshapeの使い方もこれまで通りで、独特であるがあるあるなので抑えておくこと\n","  - modelに食べさせるテンソルは3次元で、これがないと2次元となり、`y = model(x)`などでエラーになる\n","  - 動いているコードの**データの型**をよく見ておくこと\n","\n","次に、TensorDatasetでデータセットを作成\n","\n","最後にDataLoaderでミニバッチを構成\n","\n"]},{"cell_type":"code","metadata":{"id":"dFmq4Oy6apUC"},"source":["import torch\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","n_time = 10  # 時系列の数\n","n_sample = len(sin_x)-n_time  # サンプル数、len(sin_x)が50であるため、40となる\n","input_data = np.zeros((n_sample, n_time, 1))  # 入力で空の配列を生成\n","correct_data = np.zeros((n_sample, 1))  # 正解\n","for i in range(n_sample):\n","  input_data[i] = sin_y[i:i+n_time].reshape(-1, 1)\n","  correct_data[i] = sin_y[i+n_time:i+n_time+1]  # 正解は入力よりも一つ後\n","#   ここは、correct_data[i] = [sin_y[i+n_time]] このように記述しても同じです\n","input_data = torch.tensor(input_data, dtype=torch.float)  # テンソルに変換\n","correct_data = torch.tensor(correct_data, dtype=torch.float)\n","dataset = torch.utils.data.TensorDataset(input_data, correct_data)  # データセットの作成\n","train_loader = DataLoader(dataset, batch_size=8, shuffle=True)  # DataLoaderの設定\n","device = torch.device(cuda if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FalXNYaJPkoE"},"source":["### モデルの構築\n","\n","まずはマニュアルを読むこと\n","- これでわからなかったらソースコードを読む\n","- パラメータは以下の通り\n","\n","| | |\n","|:--|:--|\n","|input_size|入力の特徴量数x|\n","|hidden_size|隠れ状態の特徴量h|\n","|num_layers(=1)|スタック数、RNNを複数重ね合わせる構造|\n","|nonlinearity(=tanh)|活性化関数(`relu`/`tanh`)'|\n","|bias(=True)|バイアス重み利用切替(ON=True)|\n","|batch_first(=False)|入出力テンソルを(`batch`,`seq`,`feature`)で提供|\n","|dropout(=False)|最終層以外にDropout層を導入|\n","|bidirectional(=False)|双方向RNNとする|\n","\n","- 入力(input, $h_0$)は次の通り\n","\n","| | |\n","|:--|:--|\n","|input|入力シーケンスの特徴を含むテンソル<br>省略するがパックしてより詳細な情報を入力できる|\n","|$h_0$|内部状態初期値で省略すると0|\n","\n","- 出力(output, $h_n$)は次の通り\n","\n","| | |\n","|:--|:--|\n","|output|最終層からの出力特徴量($h_t$)を$t$ごとに含むテンソル|\n","|$h_n$|隠れ状態のテンソル|\n","\n","- 入力はパックでき、output.view(seq_len, batch, num_directions, hidden_size)であるが、パックされた場合も同様の次元をもつ\n","- 出力は$h_n$.view(num_layers, num_directions, batch, hidden_size)として分離できる\n","\n","### さて、PyTorchの癖を学ぼうか\n","\n","`nn.Module`を継承したクラスとしてモデルを構築する\n","- 特に面倒なところはPyTorchではnn.RNNとして準備されているので、これを利用するだけである\n","  - 中身の詳細がわからなくても、どういうもので、どういうときに使うかさえ知っていれば設計できる\n","  - PyTorchにはRNNとRNNCellという，ユニット全体とユニット単体を扱うクラスがあるので注意する\n","- `batch_first`をTrueにすると，`(seq_len, batch, input_size)`と指定されている入力テンソルの型を`(batch, seq_len, input_size)`にできる\n","  - 初期はDataLoaderと同じFalseの並びであったのが、互換性を維持して新規にbatch_firstを導入した\n","\n","GPUを利用するため、入力のxはGPUへ、検証の際の正解データyもGPUに送る必要がある\n","- 学習の入力は全てGPUに送っておくこと、また余計なものはおくらないこと\n","- `RNN().to('cuda')`と、最低でも書いておけば、エラーでデータがCPUとGPU両方に存在すると伝えられるので、これを順番に片付けていけばよい\n","\n","RNNの肝は、`y_rnn, hidden = self.rnn(x, None)`である\n","- 実はこれだけでよく、Noneと書くと、ゼロ初期化される\n","  - init_hiddenも実は不要\n","- Noneを具体的に書くと次の通り\n","```\n","torch.zeros(self.n_layers, batch_size, self.hidden_size)\n","```\n","- ここでは、さらに`init_hidden`と関数化している\n","  - もし、init_hiddenを関数化したならば、その戻り値はGPU内部に存在しないといけないので、`to(device)`が必要\n","\n","### さて、pythonの癖を学ぼうか\n","\n","およそ疑問に思うのは次の点であろう\n","- なぜ n_layersとhidden_sizeだけselfなのか？\n","  - まずselfを付けるということは、オブジェクト変数であることを理解する(クラス変数というのもある)\n","  - インスタンスされるたびにメモリに領域が獲得され、インスタンス毎に違う値をとることができる\n","  - 呼び出された`def __init__`内であれば、呼び出されたスコープ(この関数内)で使って捨てられてもよいのでselfは要らない\n","  - ところが、`n_layers`と`hidden_size`は`init_hidden`でも使われており、`init_hidden`を呼び出したときには既に`__init__`のスコープ外でアクセスできないのでselfを付ける必要がある\n","  - これも、忘れたところでエラーになるのでそれほど問題ではない(だったら、勝手に判断しろよと言いたい)\n","\n","- では、y_rnn, hidden, inithはselfじゃなくてよいのか？\n","  - まずforward中だけで毎回メモリから確保されても特に困らない、こだわりのスピード狂ならば、selfにしてもよい\n","\n","- `y_rnn[:, -1, :]`はなに？\n","  - まず、訓練時のy_rnnは、torch.Size([8, 10, 64])という型になる\n","  - テストのときは、torch.Size([1, 10, 64])という型になる\n","    - これはミニバッチなので当然\n","  - 次に、-1は最後のデータ、-2は最後から2つ目のデータの意味で、:は、全ての意味\n","  - もし、この`[:, -1, :]`そのものがわからないという場合は、過去の課題を再確認するとよい\n","\n","### さて、RNNのハマり所を学ぼうか\n","\n","込み入ったことをせず、一般的なRNNを記述する上では特に疑問はないと思うが、次の点は注意した方が良い\n","\n","- `n_time`回繰り返して利用するはずなのに、その指定がどこにもないけど、大丈夫か？\n","  - おそらく、疑問に思う人はいるかもしれない\n","    - 「入力xのサイズをみて判別できるが、その前にトポロジが確定しているのでダメでしょう」というごもっともそうな意見\n","    - ここまでで何も疑問を持たない人は、そのまま疑問がないまま過ぎた方が幸せかも\n","    - このごもっともそうな意見を聞いて「そうじゃん」と思ったら不幸かも\n","  - 疑問に思った人は、よく考えて欲しい、「すべての層で同じ重み、バイアスを利用する」ということを\n","    - つまり、トポロジは確定でき、入力xに従って「計算上」使いまわすだけなのだ\n","\n","- `RNN(1, 64, 1, 1)`ってなに？input_sizeはn_timeが10だから`RNN(10, 64, 1, 1)`じゃないの？\n","  - 注意してマニュアルを見ると、Inputsは入力シーケンスの特徴を含むテンソルとあり配列ではない\n","  - バッチサイズを各回で変更できるため、そのための複数指定\n","  - 普通は1となることに注意する\n","    - この1個のテンソルに、バッチサイズ$\\times$入力列$\\times$次元が格納されている、つまり1個で十分な情報がある\n","\n","例えば、これまで通りの記述でいけば、シンプルには、\n","```\n","class RNN(nn.Module):\n","    def __init__(self):\n","        super(RNN, self).__init__()\n","        self.rnn = nn.RNN(1, 64, batch_first=True)\n","        self.fc = nn.Linear(64, 1)  # 全結合層\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = x.to(device)\n","        y_rnn, hidden = self.rnn(x, None) # ここを工夫すればinit_hiddenは不要\n","        y = self.fc(y_rnn[:, -1, :])  # yは最後の時刻の出力\n","        return y\n","model = RNN().to(device)\n","```\n","でよいが、次のような記述スタイルになると、**本当に理解しているか**が確認できるであろう"]},{"cell_type":"code","metadata":{"id":"SuqqZmsh_jNK"},"source":["class RNN(nn.Module):\n","  def __init__(self, input_size, hidden_size, output_size, n_layers):\n","    super(RNN, self).__init__()\n","    self.n_layers = n_layers\n","    self.hidden_size = hidden_size\n","    self.rnn = nn.RNN(input_size, hidden_size, n_layers, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, output_size)  # 全結合層\n","  def forward(self, x):\n","    batch_size = x.size(0)\n","    x = x.to(device)\n","    inith = self.init_hidden(batch_size) \n","    y_rnn, hidden = self.rnn(x, inith) # ここを工夫すればinit_hiddenは不要\n","    y = self.fc(y_rnn[:, -1, :])  # yは最後の時刻の出力\n","    return y\n","  def init_hidden(self, batch_size):\n","    return torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device)\n","model = RNN(1, 64, 1, 1).to(device)\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qsW5zCKhQE9p"},"source":["### 学習\n","モデルを訓練する\n","\n","DataLoaderよりミニバッチを取り出しつつ訓練と評価を行う\n","\n","ここでは、途中の訓練状況を見ることで、テーラー展開のように**徐々に(というか突然気が付いたように)サイン関数曲線に近づく**ところも観察する"]},{"cell_type":"code","metadata":{"id":"u6zwN3nArbGC"},"source":["# MSE誤差関数\n","loss_fnc = nn.MSELoss()\n","# 最適化アルゴリズム\n","optimizer = optim.SGD(model.parameters(), lr=0.01)  # 学習率は0.01\n","# 損失のログ\n","record_loss_train = []\n","# 学習\n","for i in range(200):\n","  model.train()  # 訓練モード\n","  loss_train = 0\n","  for j, (x, t) in enumerate(train_loader):  # ミニバッチ（x, t）を取り出す\n","    y = model(x)\n","    loss = loss_fnc(y, t.to(device))\n","    loss_train += loss.item()\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  loss_train /= j+1\n","  record_loss_train.append(loss_train)\n","  if (i+1)%10 == 0:\n","    print(\"Epoch:\", i, \"Loss_Train:\", loss_train)\n","    predicted = list(input_data[0].reshape(-1)) # 最初の入力\n","    model.eval()\n","    with torch.no_grad():\n","      for i in range(n_sample):\n","        x = torch.tensor(predicted[-n_time:])  # 直近の時系列を取り出す\n","        x = x.reshape(1, n_time, 1)  # (バッチサイズ, 時系列の数, 入力の数)\n","        y = model(x)\n","        predicted.append(y[0].item())  # 予測結果をpredictedに追加する\n","    plt.plot(range(len(sin_y)), sin_y, label=\"Correct\")\n","    plt.plot(range(len(predicted)), predicted, label=\"Predicted\")\n","    plt.legend()\n","    plt.show()        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJwwrWTw43rx"},"source":["### 誤差の推移\n","\n","訓練データ、テストデータで誤差の推移をグラフに表示する  "]},{"cell_type":"code","metadata":{"id":"OaJx4swE45XI"},"source":["import matplotlib.pyplot as plt\n","plt.plot(range(len(record_loss_train)), record_loss_train, label=\"Train\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Error\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iMrpac0m4Nct"},"source":["RNNでは、このような変曲点が現れるグラフになることが少なくない\n","- サイングラフならば、その全体の形がいきわたることが何回か体験する必要があり、シンプルなサインなので、一度かみ合えば急激に減衰する\n","- エポックを増やして、過学習にしてみるなど、実験してみよう"]},{"cell_type":"markdown","metadata":{"id":"E36d8Vf_ZNXl"},"source":["# LSTM"]},{"cell_type":"markdown","metadata":{"id":"Qccs40h9IvMs"},"source":["## LSTMの構造\n","\n","LSTM(Long short-term memory:長・短期記憶)はRNNの拡張として1995年に登場した時系列データ(sequential data)に対するモデルである\n","\n","RNNは再帰構造（先ほどWに全結合)を用いるが、LSTMは専用のLSTM層を用いることで、様々なRNNにおける問題に対応する\n","\n","- Backpropagation Through Time(BPTT)による長いステップ、遠い過去の学習が困難であった\n","  - RNNのWに全過去の履歴を画一的に学習させるのは困難\n","  - 通常のRNNでも数十ステップの短期依存(short-term dependencies)には対応できるが、1000ステップといった長系列に依存する場合は学習できなかった\n","\n","- RNNでは勾配消失問題に加えて勾配爆発問題も深刻であった\n","  - 大きくても小さくても問題となり、tanhを使って和らげているとはいえ、ステップ数が大きいと問題が発生しやすかった\n","  - LSTMでは過去のデータをsigmoidやtanhではなく「線形和」で保持するため問題が発生しにくい\n","\n","LSTMも様々拡張されており、いくつかの有用なバージョンが存在する\n","- PyTorchでは、比較的新しい構造が実装されており、この構造について概説する\n","\n","## LSTMの構造と特徴\n","\n","以下の特徴的な構造をもつ\n","- **記憶セル**の導入による長期の記憶保持\n","- **ゲート**と呼ぶ情報の流れを調整する機構の導入\n","  - ゲートが記憶セルの内容を**忘れるか忘れないか**を判断し、必要な情報のみ次の段に引き継ぐ\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/lstmfig.png\" width=500>\n","\n","図において、$\\oplus$は要素同士の和、$\\otimes$は要素同士の積、$\\sigma$はシグモイド関数を表す\n","\n","全体の構造として、記憶セルから忘却ゲートとの積、入力ゲートとの和を経由して記憶セルに戻るパスがまず目につく\n","\n","- このパスに対して忘却ゲートは積を算出するため、継承重みを制御される\n","\n","- このパスに対する入力、つまり新しい情報の追加も入力ゲートにより制御される\n","\n","- 記憶セルの内容が出力に影響する割合も出力ゲートにより制御される\n","\n","これらのような要素により構成されている\n","\n","LSTMは強力なモデルで、こうみると色々できそうに感じると思うが、実際はやみくもに設計、動作させても意味のある出力を得ることは極めて困難であり、緻密な問題設定が必要となる\n","\n","LSTMの欠点は、その構造自体からどのような問題が解けるのか・なぜ解けない問題があるのかの判断が難しいことである\n","- 問題を選ぶ手法といえなくもない\n","- このやってみるしかない、という結論は工学的・科学的ではないと判断されやすく、機械学習研究を攻撃する格好の標的になっている\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kEIaJTZYSe9j"},"source":["## LSTMによる画像生成\n","\n","画像を時系列データと捉えてLSTMにより画像を生成させる\n","\n","- torchvision.datasetsにあるFashion-MNISTの画像データを用いて訓練し、画像の上半分をもとに画像の下半分を予測、生成させる\n","\n","- Fashion-MNISTは6万枚のファッションアイテム画像にラベルをつけたたデータセットである\n","\n","  - 今回、ラベルは利用しない\n","  - 白黒であるため、生成しやすい\n","\n","画像の学習と生成のイメージは次の図を参照するとよい\n","- 画像は次のように構成され、行ごと入力される\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/rnnimg1.png\" width=200>\n","\n","訓練においては、上半分つまり14行(t=0からt=13)を利用して15行目(t=14)を教師として学習する\n","- 次の行は図で言う(t=1からt=14)を利用して16行目(t=15)を教師として学習する\n","\n","推定も同様である\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/rnnimg2.png\" width=400>\n","\n","なお、次のような疑問はごもっともである\n","- 入力14行だけを入力として、それぞれ別個に下の14行を学習させる、つまり14個の独立したモデルを持てばよいのではないか？\n","- そのとおりであるが、唯一のモデルで時系列もしくは、シリーズデータとして扱える点がRNNのメリットである\n","\n","まず、Fashion-MNISTをロードし、25枚の画像をランダムに選び出す\n"]},{"cell_type":"code","metadata":{"id":"yBJLf456Se9o"},"source":["from torchvision.datasets import FashionMNIST\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","fmnist_data = FashionMNIST(root=\"mydata\",\n","                            train=True,download=True,\n","                            transform=transforms.ToTensor())\n","fmnist_classes = np.array([\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n","                            \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"])\n","print(\"データ数:\", len(fmnist_data))\n","n_image = 200  # バッチサイズ\n","fmnist_loader = DataLoader(fmnist_data, batch_size=n_image, shuffle=True)\n","dataiter = iter(fmnist_loader)  # イテレータ\n","images, labels = dataiter.next()  # 最初のバッチを取り出す\n","img_size = 28 # FasionMNISTの画像サイズは28x28である\n","plt.figure(figsize=(10,10))  # 画像の表示サイズ\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.imshow(images[i].reshape(img_size, img_size), cmap=\"Greys_r\")\n","    label = fmnist_classes[labels[i]]\n","    plt.title(label)\n","    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # ラベルとメモリを非表示に"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uq5-aKDESe9x"},"source":["### データの前処理\n","\n","画像データをPyTorchでの処理に適した形に整形する\n","\n","- 画像の各行を時刻とみて時系列データに変換し、正解データは時系列における次の行とする\n","\n","`train_imgs = train_imgs.reshape(-1, img_size, img_size)`について\n","\n","- もともとは、`torch.Size([60000, 1, 28, 28])`というサイズであるが、これを`torch.Size([60000, 28, 28])`に変換している\n","- PyTorchではこのような処理はしばしば現れるため専用の`torch.squeeze`が用意されている\n","  - 例えば`train_imgs = train_imgs.squeeze()`としても同じ結果が得られる\n"]},{"cell_type":"code","metadata":{"id":"bUcJiVtDV7Ad"},"source":["import torch\n","from torch.utils.data import DataLoader\n","n_time = 14  # 時系列の数\n","n_in = img_size  # 入力層のニューロン数\n","n_mid = 400  # 中間層のニューロン数 精度がそれほど必要なければ256でもよい。\n","n_out = img_size  # 出力層のニューロン数\n","n_sample_in_img = img_size-n_time  # 1枚の画像中のサンプル数\n","dataloader = DataLoader(fmnist_data, batch_size=len(fmnist_data), shuffle=False)\n","dataiter = iter(dataloader)  # イテレータ\n","train_imgsr, labels = dataiter.next()  # データを取り出す\n","train_imgs = train_imgsr.reshape(-1, img_size, img_size) # サイズを整える\n","n_sample = len(train_imgs) * n_sample_in_img  # サンプル数\n","input_data = np.zeros((n_sample, n_time, n_in))  # 入力\n","correct_data = np.zeros((n_sample, n_out))  # 正解\n","for i in range(len(train_imgs)):\n","  for j in range(n_sample_in_img):\n","    sample_id = i*n_sample_in_img + j\n","    input_data[sample_id] = train_imgs[i, j:j+n_time]\n","    correct_data[sample_id] = train_imgs[i, j+n_time]\n","input_data = torch.tensor(input_data, dtype=torch.float)  # テンソルに変換\n","correct_data = torch.tensor(correct_data, dtype=torch.float)\n","dataset = torch.utils.data.TensorDataset(input_data, correct_data)  # データセットの作成\n","train_loader = DataLoader(dataset, batch_size=128, shuffle=True)  # DataLoaderの設定\n","device = torch.device(cuda if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d8pnaugFDnLN"},"source":["### テスト用のデータの作成\n","\n","再びDataLoaderを用い、今度はtrain=Falseにして作る\n","- 今度はsqueezeを使ってみる"]},{"cell_type":"code","metadata":{"id":"xISsKRTAp7QG"},"source":["n_disp = 10  # 生成し表示する画像の数\n","disp_data = FashionMNIST(root=\"mydata\",\n","                        train=False,download=True,\n","                        transform=transforms.ToTensor())\n","disp_loader = DataLoader(disp_data, batch_size=n_disp, shuffle=False)\n","dataiter = iter(disp_loader)  # イテレータ\n","disp_imgsr, labels = dataiter.next()  # データを取り出す\n","disp_imgs = disp_imgsr.squeeze().float()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mPcV-CfISe98"},"source":["### 画像生成用関数の定義\n","\n","オリジナルの画像`disp_imgs`と、この画像の上半分をもとに下半分を生成した`gen_imgs`を並べて表示する\n","- はじめに画像の上半分を履歴として次の行を生成し、さらにその行を含んで新たな履歴として次の行を生成する、という処理を繰り返す"]},{"cell_type":"code","metadata":{"id":"duSKxL1HSe9-"},"source":["genimgflag = 0\n","def generate_images():\n","  # オリジナル画像の表示(最初の1回のみ)\n","  global genimgflag\n","  if genimgflag == 0:\n","    print(\"Original:\")\n","    plt.figure(figsize=(20, 2))\n","    for i in range(n_disp):\n","      ax = plt.subplot(1, n_disp, i+1)\n","      plt.imshow(disp_imgs[i], cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n","      ax.get_xaxis().set_visible(False)  # 軸を非表示に\n","      ax.get_yaxis().set_visible(False)\n","    plt.show()\n","    genimgflag = 1\n","  # 下半分を生成した画像の表示\n","  print(\"Generated:\")\n","  model.eval()\n","  with torch.no_grad():\n","    gen_imgs = disp_imgs.clone()\n","    plt.figure(figsize=(20, 2))\n","    for i in range(n_disp):\n","      for j in range(n_sample_in_img):\n","        x = gen_imgs[i, j:j+n_time].reshape(1, n_time, img_size)\n","        x = x.to(device)  # GPU対応\n","        gen_imgs[i, j+n_time] = model(x)[0]\n","      ax = plt.subplot(1, n_disp, i+1)\n","      plt.imshow(gen_imgs[i].detach(), cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n","      ax.get_xaxis().set_visible(False)  # 軸を非表示に\n","      ax.get_yaxis().set_visible(False)\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wn1OMA_bSe-C"},"source":["### モデルの構築\n","`nn.Module`モジュールを継承してクラスを構成\n","\n","- LSTMは`nn.LSTM`を利用する\n","- 中身は RNNと変わらないので目新しさは特にない\n","- 今回はレイヤ数、つまりLSTMのスタック数は1とするため、指定は省略している"]},{"cell_type":"code","metadata":{"id":"v8EBDfYoSe-D"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","class LSTMN(nn.Module):\n","  def __init__(self, input_size, hidden_size, n_output):\n","    super(LSTMN, self).__init__()\n","    self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, n_output)  # 全結合層\n","  def forward(self, x):\n","    y_lstm, (h, c) = self.lstm(x, None)  # hは次の時刻に渡される値、 cは記憶セル\n","    y = self.fc(y_lstm[:, -1, :])  # yは最後の時刻の出力, 実際にはhも同じ\n","    return y\n","model = LSTMN(n_in, n_mid, n_out).to(device)\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Bik1vR6qfy4"},"source":["LSTNの隠れ層のネットワークは先ほどの図(再掲する)であるが、`y, (h, c) = LSNM(x, None)`と記述すると、記憶セルがc、$x_i$の入力がx、$y$全体がy、$y$の最後がhである。つまり、`h=y[:, -1, :]`となる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/lstmfig.png\" width=500>\n","\n","これらのどの戻り値を使うべきかは、LSTMで解きたいタスクによる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/lstmio.png\" width=600>\n","\n","その前の絵の情報(many)から次の行(one)を得たいので、 many to one モデルとなる\n","- 従って、LSTMの最後の隠れ層の出力hを使う\n","- hか、yの最後を使う"]},{"cell_type":"markdown","metadata":{"id":"zz9lTWFiSe-H"},"source":["### 学習\n","\n","モデルを訓練する\n","\n","- **学習には40分程度必要となるので注意すること**\n","\n","- `loss_fnc = nn.MSELoss()`は、各要素間の平均二乗誤差(L2ノルムの2乗)を算出する\n","\n","- DataLoaderを用いてミニバッチを取り出して訓練と評価を行う\n","\n","- 学習中はエポックごとに画像生成用関数generage_imagesにより生成画像が表示される"]},{"cell_type":"code","metadata":{"id":"M9pubtiZSe-I"},"source":["from torch import optim\n","loss_fnc = nn.MSELoss()\n","# 最適化アルゴリズム\n","optimizer = optim.Adam(model.parameters())  # 学習率は0.01\n","# 損失のログ\n","record_loss_train = []\n","# 学習\n","for i in range(40):  # 40エポック学習 待ち遠しい場合は30エポックなどでも大丈夫\n","  model.train()  # 訓練モード\n","  loss_train = 0\n","  for j, (x, t) in enumerate(train_loader):  # ミニバッチ（x, t）を取り出す\n","    x, t = x.to(device), t.to(device)  # GPU対応\n","    y = model(x)\n","    loss = loss_fnc(y, t)\n","    loss_train += loss.item()\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  loss_train /= j+1\n","  record_loss_train.append(loss_train)\n","  print(\"Epoch:\", i, \"Loss_Train:\", loss_train)\n","  generate_images()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ndr3dBdKSe-M"},"source":["### 誤差の推移の確認\n","\n","誤差の推移をグラフにより確認する"]},{"cell_type":"code","metadata":{"id":"Nd2eUpmUSe-M"},"source":["import matplotlib.pyplot as plt\n","plt.plot(range(len(record_loss_train)), record_loss_train, label=\"Train\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Error\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OGQUZFWx3LUo"},"source":["なお、ノード数が256の場合と400の場合では、次のような差がある\n","- 256ノードの時\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/lstm256.png\" width=400>\n","\n","- 400ノードの時\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/lstm400.png\" width=400>\n","\n","y軸の差に注目、30エポックでは400ノードの方が精度がよく、さらに向上できる見込みがある(学習不足=underfittingともいえる状態)\n","- 1エポックあたりの所要時間は1割ほど増えている"]},{"cell_type":"markdown","metadata":{"id":"Z08nMvstY3wb"},"source":["# GRU"]},{"cell_type":"markdown","metadata":{"id":"yyunfBvCZgCd"},"source":["## GRUの構造\n","\n","GRU(Gated Recurrent Unit: ゲート付き回帰型ユニット)は2014年に提案された機構であり、以下のような特徴をもつ\n","\n","- LSTMに比してシンプルな構造で計算量が少ない\n","- 記憶セルと出力ゲートが存在しない\n","  - 内部状態数はGRUの方が出力ゲートがない分少ない\n","- 入力ゲートと忘却ゲート統合し更新ゲート(Update gate)を構成する\n","- 値をゼロにリセットするリセットゲート(Reset gate)が備わる\n","\n","一部信号モデリングなどで性能がLSTMを上回ることがあるが、GRUが言語学習で失敗することがあるなど、LSTMはGRUよりも厳密に強力であることが示されている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/gru.png\" width=500>\n","\n","図において、$\\oplus$は要素同士の和、$(1-)$は1から引く演算、$\\otimes$は要素同士の積、$\\sigma$はシグモイド関数を表す\n","\n","リセットゲート\n","- 新しい記憶を構成するためにどの程度過去の情報を利用するのかを決定するパラメタと考えることができる\n","- さらに、その調整には今の情報が利用される\n","\n","更新ゲート\n","\n","出力($Y=Y_t$)が新しい記憶($N$)と過去の情報($P=y_{t-1}$)で決定されているが、$Y=(1-\\alpha)P+\\alpha N$と読み取れる通り、出力を新しい記憶、過去の情報どちらに重きをおいて構成するかを与える\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CeYcTdowZzMK"},"source":[" ## GRUによる株価予測"]},{"cell_type":"markdown","metadata":{"id":"w6w1PqRrsM4W"},"source":["先ほどはサインのグラフを扱ったが、実用性がよくわからないので、株価予測をGRUで行う\n","- Yahoo FinanceのWebページ情報をスクレイピングする、フリーで株価情報が取れる素晴らしいサイト\n","\n","なお、次の点に注意しなければならない\n"," - 今回は日経平均株価を予測する\n"," - 銘柄ごとも取得できるが、Googleからのアクセスは流石にブロックされている様子なので、皆さんで工夫して、銘柄ごとの値を予測するようにしてみると良い\n","   - 日経平均株価情報もブロックされる可能性があるので注意すること\n"," - 実際に株価予測をして儲けるのであれば、きちんとお金を払ってAPIを用いて、ほぼリアルタイムな情報を入手し、APIで売買できるようにする必要があるであろう\n"," - 例えば野球やサッカーの点数を予測できるか？\n","   - 過去の点数履歴だけで予測するのはかなり困難であり、相手の情報や、野球なら、投手、打順、各選手の最近の成績、球場など、様々な情報を特徴量として取り込むべきであろう\n","   - そういう問題は別途ポアソン過程としてモデル化した方が興味深い結果が得られる\n","   - つまり、何をどのように解析したいかを知り、それに必要な情報をそろえるのは、AIではなく、人間であるということ\n","   - AIにとって都合の良い情報を上手くそろえていれば、あとはAIに任せばよい\n","   - その程度か？といわれるとその程度だが、データが大量にある場合は、AI利用のメリットが大きくなる"]},{"cell_type":"code","metadata":{"id":"PqYXkhgAj3vc"},"source":["from bs4 import BeautifulSoup\n","import numpy as np\n","import pandas as pd\n","import urllib.request\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XjaL5F8PlIgV"},"source":["## 株価の取得\n","まずは株価サイトからデータを取ってくる\n","- ここでは、BeautifulSoupを用いる\n","  - WebスクレイパーであるBeautifulSoup自体は本筋からずれるため、別途学ぶためのシートを準備する\n","- スクレイピングすることで、webからデータを取得できる\n","  - より強力には、Selenimumや、Firefox marionetteを利用することになる\n","  - この授業の自動採点システム、閲覧状況自動取得システムは、Firefox marionetteが利用されている\n","  - オンラインチケット獲得には重要なツールとなりつつある\n","- Yahoo Financeで取得するデータの範囲は次の項目を指定しなおす\n","  - なお、これは仕様ではなく、解析結果であるのでいつ変更となってもおかしくはない\n","  - Googleからの取得もいつブロックされてもおかしくない\n","  - pを順番に増やしながら次々と画面を更新してデータを取得し、つなげていく\n","\n","| | |\n","|:--|:--|\n","|sy|取得開始年|\n","|sm|取得開始月|\n","|sd|取得開始日|\n","|ey|取得終了年|\n","|em|取得終了月|\n","|ed|取得終了日|\n","|p|取得頁|\n","\n"]},{"cell_type":"code","metadata":{"id":"-ZvEwm2TlOKQ"},"source":["def getstockfromweb():\n","  page_num = 20 # 取得するページ数\n","  tstock = []\n","  for i in range(page_num):\n","    # Yahoo Financeのページを利用\n","    url = \"https://finance.yahoo.co.jp/quote/998407.O/history?from=20170101&to=20191231&timeFrame=d&page=\" + str(i+2)\n","    html = urllib.request.urlopen(url)\n","    soup = BeautifulSoup(html, \"lxml\")\n","    estock = [value.get_text() for value in soup.find_all(\"td\")[0:100]]\n","     #<td></td>に欲しい数値が文字で入っているのでその部分を抽出し、get_textで文字のみさらに抽出する\n","    tstock.extend(estock) # appendではなく一つの大きな配列にするためextendを使う\n","    time.sleep(0.1) # どんどんデータをとると、サーバが察知してデータが取れなくなる\n","  tstock = np.array(tstock) # NumPyへ変換\n","  stock = tstock.reshape(-1, 5)\n","  stock = pd.DataFrame(stock, columns=['date', 'open', 'max', 'min', 'close'], index=stock[:,0])\n","  stock = stock.drop('date',axis=1).apply(lambda x: x.str.replace(',','')).apply(lambda x: x.astype(np.float32))\n","  return stock\n","#  return stock.apply(lambda x: x.str.replace(',','')).astype(np.float32) # 文字を数字に変換\n","# この関数の実行を確認する場合は、次のコードセルを作成して実行するとよい\n","# stock = getstockfromweb()\n","# stock"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dwZzeECTyatA"},"source":["次に、情報が取得できなかった場合、次の方法で各自取得して、次の関数を実行するとよい\n","\n","取得方法は様々あるが、知られているのが株式投資メモ( https://kabuoji3.com/stock/ )であり、ここからならばスクレイピングでも銘柄別で取得できるが、Googleはブロックされている\n","- 各自銘柄コードと年度を入力して個別株価データを入手し、CSVデータをダウンロードする(数字4桁_年度.csv)というデータが取得できる\n","- これを、ファイル名をstockdata.csvに変更する\n","- 左のフォルダメニューを開き、stockdata.csvをドラッグしてファイルをコラボラトリに入れる\n","- 次の関数は、stockdata.csvを読んで解析する"]},{"cell_type":"code","metadata":{"id":"Qeg7qCAABFoP"},"source":["def getstockdata():\n","  path = 'stockdata.csv'\n","  with codecs.open(path, \"r\", \"Shift-JIS\", \"ignore\") as f:\n","    stock = pd.read_table(f, delimiter=\",\", header=None, names=['date', 'open', 'max', 'min', 'close', 'total', 'adjustment'])\n","    stock = stock.drop(stock.index[[0,1]])[['open', 'max', 'min', 'close', 'total', 'adjustment']].apply(lambda x: x.astype(np.float32))\n","  return stock"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ePI9nBZrCBd1"},"source":["いつもの通りの前準備だが、新たに`torch.manual_seed`が呼び出されている\n","- これは、実験の再現性を高めるため、同じ乱数を生成させる\n","- 研究用途などで利用されるテクニック\n","  - False=0で同一系列の乱数を生成し、True=1で一般的な乱数となる\n"]},{"cell_type":"code","metadata":{"id":"d4ZfhlZKAdyd"},"source":["import numpy as np\n","import pandas as pd\n","import codecs\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","torch.manual_seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jCM07aQ8rCdP"},"source":["whichdataをTrueにするかFalseにするかで、webスクレイピングによる情報取得か、ダウンロードしたデータを利用するのかを切り替えることができる\n","\n","どちらも共通して、dfというpandas DataFrame形式に保存される"]},{"cell_type":"code","metadata":{"id":"YeYaMS30vBwR"},"source":["whichdata = False # webスクレイピングを利用する、Falseでダウンロードデータを利用する\n","if whichdata==True:\n","  dfp = getstockfromweb()\n","  print(dfp.dtypes)\n","  print(dfp)\n","  df = dfp.reset_index(drop=True).drop(columns=['open', 'max', 'min'])\n","else:\n","  import os\n","  if not os.path.exists('stockdata.csv'):\n","      #!wget \"https://drive.google.com/uc?export=download&id=1OsqF2vQ94ZF8gA0IEjhp0rJM-2lnyfUw\" -O stockdata.csv\n","      !wget https://keio.box.com/shared/static/xml20yn9im6xiytxe5z25wbja242g61k -O stockdata.csv\n","  dfp = getstockdata()\n","  print(dfp.dtypes)\n","  print(dfp)\n","  df = dfp.reset_index(drop=True).drop(columns=['open','max','min','total','adjustment'])\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vODbsorPrPyS"},"source":["学習用データを作成する\n","- pandasからnumpyに変換するにはvaluesを使う\n","- 直接金額を扱ってもよいが、株価予測の場合、銘柄間の変動予測や銘柄間の相関性も扱うことが多いことから、金額ではなく割合で評価した方が将来的に応用できやすいであろう\n","  - データ全体から最大値、最低値を取得し、その割合をもって学習させる\n","  - この方法では、突発的な価格上昇や下落には対応できない\n","  - 普通にmin, max標準化を行う\n","    - 正規分布で正規化すると、外れ値が大きな値となり、外れ値に引きずられた結果となる\n"]},{"cell_type":"code","metadata":{"id":"8LksaLYEH7XV"},"source":["#訓練データとテストデータに分割\n","test_size = 0.3\n","sp = df['close'].values # pandasからnumpyへ変換\n","total_len = len(sp)\n","test_len = int(len(sp)*test_size)\n","train_len = total_len - test_len\n","print(\"total_len:\", total_len, \" train_len:\", train_len, \"test_len:\", test_len)\n","train = sp[0:train_len]\n","test = sp[train_len:total_len]\n","x_max, x_min = max(sp), min(sp)\n","train_norm = (train - x_min) / (x_max - x_min)\n","test_norm = (test - x_min) / (x_max - x_min)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBmSDzmVsPWU"},"source":["テータを分割する\n","- DataLoaderに食べさせるデータを作る\n","- n_timesのブロックを入力とし、次のデータを教師とするデータを作成する\n","- 訓練用とテスト用の両方作成する"]},{"cell_type":"code","metadata":{"id":"FK0ar11-MFdW"},"source":["#時系列データに分割\n","n_time = 6\n","x_train, y_train, x_test, y_test= [], [], [], []\n","for i in range(train_len-n_time):\n","  x_train.append(train_norm[i:i+n_time].reshape(-1,1))\n","  y_train.append(train_norm[i+n_time])\n","for i in range(test_len-n_time):\n","  x_test.append(test_norm[i:i+n_time])\n","  y_test.append(test_norm[i+n_time])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjC7o9Fhsi9O"},"source":["作成したデータをTensorDatasetとしてDataLoaderに渡す\n","- この時torchテンソルに変換する必要がある"]},{"cell_type":"code","metadata":{"id":"zrHxEdYjTGb6"},"source":["epochs = 50\n","batch_size = 32\n","train_input_data = torch.tensor(x_train, dtype=torch.float)  # テンソルに変換\n","train_correct_data = torch.tensor(y_train, dtype=torch.float)\n","train_dataset = torch.utils.data.TensorDataset(train_input_data, train_correct_data)  # trainデータセットの作成\n","train_loader = DataLoader(train_dataset, batch_size=batch_size)\n","\n","test_input_data = torch.tensor(x_test, dtype=torch.float)  # テンソルに変換\n","test_correct_data = torch.tensor(y_test, dtype=torch.float)\n","test_dataset = torch.utils.data.TensorDataset(test_input_data, test_correct_data)  # testデータセットの作成\n","test_loader = DataLoader(test_dataset, batch_size=len(x_test))\n","\n","device = torch.device(cuda if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z7EhIiqMufGb"},"source":["GRUを指定する\n","\n","RNN, LSTM, GRUは、基本的に名前だけ変えればよいのがわかるであろう"]},{"cell_type":"code","metadata":{"id":"ecJKx83LLkGa"},"source":["class GRUN(nn.Module):\n","  def __init__(self, input_size, hidden_size, output_size):\n","    super(GRUN, self).__init__()\n","    self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, output_size)\n","  def forward(self, x):\n","    x = x.to(device)\n","    y_gru, h = self.gru(x, None)\n","    y = self.fc(y_gru[:, -1, :])\n","    return y\n","model = GRUN(1, 100, 1).to(device)\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CBRcrTu-us8O"},"source":["損失関数に平均二乗誤差、最適化にはADAMを利用する\n","- これらも定番"]},{"cell_type":"code","metadata":{"id":"tJg4tNZVLm5H"},"source":["loss_func = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","record_loss_train = []\n","for i in range(epochs):\n","  for j, (x, t) in enumerate(train_loader):\n","    x, t = x.to(device), t.reshape(-1,1).to(device)\n","    y = model(x)\n","    loss = loss_func(y, t)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  loss /= j+1\n","  record_loss_train.append(loss)\n","  print(f'epoch: {i:3} loss: {loss.item():10.8f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9bbqwpZvbGt"},"source":["学習した結果を用いて、実際に推定を行う\n","- 本来は、違う年度で行うのが正しいであろうが、Fasion-MNISTも同様に、このあたりは授業で扱い方を学ぶという観点から、若干おおらかになっている\n","\n","途中、`in_true = list(sp_norm.reshape(-1).astype(np.float32))`といった記述があるが、極めて重要な記述である\n","- CPUはFloat64つまり、64bit CPUを搭載したパソコン(64bit PCなどともいうが)が普通に流通しており、このCPUで表現できるデータとして保存している\n","- GPUはFloat32つまり、32bitで構成されている\n","  - これは、画像では32bitあれば、24bitフルカラー+$\\alpha$が表現できるため十分である\n","  - 機械学習用途でも、ビット幅は学習精度にほとんど影響を与えず、Float32(FP32)の他、Float16(FP16)もよく利用されている\n","    - 中にはINT8, INT4, INT2といった特殊な表現も研究されている\n","  - 以上のように、変数の表現を簡略化して計算性能を挙げているという見方もできる\n","\n","つまり、GPUではFloat32を使ってデータをつけつけ、また内部も表現されている\n","- このGPUにCPUが扱えるFloat64をそのまま入れるとエラーになる\n","  - 実際に`.astype(np.float32))`を削除して試してみると良い\n","  - なぞなRUNTIME ERRORとなり、原因究明すらも難しい状態にるかもしれないが、それでも型を調べて何が違うのかを追いかけると、簡単に誤りにたどり着くことができる\n","    - きちんとFloat32かFloat64かは区別できるようになっている\n","\n","したがって、Float64をそのままGPUに入れるとエラーになる\n","- つまり、GPUを使う前提であれば、FP32にするのが得策である\n","- CPUは汎用性をうたっており、この点はどうでもよく、FP16、FP32、FP64すべて問題なく動作できる\n"]},{"cell_type":"code","metadata":{"id":"cE9pOV8GDdET"},"source":["sp_norm = sp/x_max\n","in_true = list(sp_norm.reshape(-1).astype(np.float32)) # ここの意味を理解する\n","pred = []\n","model.eval()\n","for i in range(n_time):\n","  pred.append(0) # 最初は予測できないので0を加える\n","with torch.no_grad():\n","    for i in range(len(sp)-n_time):\n","      x = torch.tensor(in_true[i:i+n_time])  # 直近の時系列を取り出す\n","      x = x.reshape(1, -1, 1)  # (バッチサイズ, 時系列の数, 入力の数)\n","      y = model(x)\n","      pred.append(y[0].item())  # 予測結果をpredictedに追加する\n","plt.plot(range(len(sp)), sp, label=\"Correct\")\n","pred = np.array(pred)\n","pred = pred * x_max\n","plt.plot(range(len(pred)), pred, label=\"Predicted\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["流石に知っているデータは、当然のごとく再現する"],"metadata":{"id":"KqEIeANpNZHd"}},{"cell_type":"code","metadata":{"id":"D4UClJT_Psm3"},"source":["test_norm = test/x_max\n","in_true = list(test_norm.reshape(-1).astype(np.float32)) # ここの意味を理解する\n","pred = []\n","model.eval()\n","for i in range(n_time):\n","  pred.append(0) # 最初は予測できないので0を加える\n","print(pred)\n","with torch.no_grad():\n","  for j, (x, t) in enumerate(test_loader):\n","    x = x.reshape(len(x),6,1)\n","    x, t = x.to(device), t.reshape(-1,1).to(device)\n","    y = model(x)\n","    y = y.to('cpu').detach().ravel().numpy().copy().tolist()\n","    print(len(y))\n","    pred = pred + y  # 予測結果をpredictedに追加する\n","plt.plot(range(len(test)), test, label=\"Correct\")\n","pred = np.array(pred)\n","pred = pred * x_max + test[n_time]-pred[n_time]*x_max\n","plt.plot(range(len(pred)), pred, label=\"Predicted\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["まぁ、そんなに当たるもんではないが、良い線か？\n","- 初期値はチートしている"],"metadata":{"id":"AcTm4Qs4Lfvq"}},{"cell_type":"markdown","metadata":{"id":"Puhdp3tf5QA7"},"source":["なお、\n","- 翌日予測が値を下げるようであれば、今のうちに売る\n","- 翌日予測が値を上げるようであれば、今のうちに買う\n","\n","という操作の他、\n","- その時の手数料も勘案して、利益が上がると確定できるときに売る\n","- 予測毎の確度を得て、その確度に応じて売る量を決める\n","- 経済的情勢などを特徴量に加える\n","\n","などの追加ができるであろう"]},{"cell_type":"markdown","metadata":{"id":"MkpqtNWG-zJS"},"source":["# 課題1 (RNN)\n","\n","上記株価予想を、さらにRNNおよびLSTMを用いて評価し、3つの結果を比較しなさい\n","- 結果は比較するだけでよいが、考察があるとなおよい\n","- 但し「定量的な評価」で比較すること"]},{"cell_type":"markdown","source":["# 課題2(RNNの効果)\n","\n","一般的な全結合網を用いたNNとGRUを用いて、以下の2つについてシンプルに評価しなさい\n","\n","(1) 一様乱数や円周率など周期性のない値で構成した数列を推定する  \n","(2) 循環小数など周期性のある値を推定する  \n","(3) 異なる周期性のある2つの数列をm:nで連続して結合した数列を推定する  \n","(4) 異なる周期性のある2つの数列を足し合わせた数列を推定する"],"metadata":{"id":"FdqkIGUuTtax"}}]}