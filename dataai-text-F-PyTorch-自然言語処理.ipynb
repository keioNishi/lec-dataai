{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataai-text-F-PyTorch-自然言語処理.ipynb","private_outputs":true,"provenance":[{"file_id":"1F4ifdHNnrAUsDv2pj0EXDImHsM_x_E9M","timestamp":1628197853609}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ymc95iQm0xTt"},"source":["#@title Data-AI（必ず自分の名前・学籍番号を入力すること） { run: \"auto\", display-mode: \"form\" }\n","\n","import urllib.request as ur\n","import urllib.parse as up\n","Name = '\\u5927\\u548C \\u8A00\\u8449' #@param {type:\"string\"}\n","EName = 'Yamato Kotoha' #@param {type:\"string\"}\n","StudentID = '87654321' #@param {type:\"string\"}\n","Addrp = !cat /sys/class/net/eth0/address\n","Addr = Addrp[0]\n","url = 'https://class.west.sd.keio.ac.jp/classroll.php'\n","params = {'class':'dataai','name':Name,'ename':EName,'id':StudentID,'addr':Addr,\n","           'page':'dataai-text-F','token':'35672359'}\n","data = up.urlencode(params).encode('utf-8')\n","#headers = {'itmes','application/x-www-form-urlencoded'}\n","req = ur.Request(url, data=data)\n","res = ur.urlopen(req)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gU-Arpc9zElH"},"source":["---\n",">「ある人は十銭をもって一円の十分の一と解釈する。ある人は十銭をもって一銭の十倍と解釈する。同じ言葉が人によって高くも低くもなる。」 \\\n",">（夏目漱石）\n","---"]},{"cell_type":"markdown","metadata":{"id":"bMVPaUY5-hVV"},"source":["# 自然言語処理（Natural Language Processing）\n","\n","プログラミング言語は厳格な文法により「プロセス」を与えることで、その手順通りに処理を行わせることができる\n","\n","一方で、我々が用いる言語は「自然言語」と呼ばれるが、言葉の曖昧性や意味が明確定義されていない多様な言語である\n","\n","計算機がこのような自然言語を扱うことは従来困難であったが、DNNの発展により、扱うことが可能となった"]},{"cell_type":"markdown","metadata":{"id":"wimU5555RaL8"},"source":["## 機械可読辞書とコーパス\n","\n","DNNで扱うためには、教師データとしての大量のデータが必要である\n","\n"," NLPにおいては、大量の「我々が普段扱う言語を電子データ化した情報」が必要となる\n","- 従来はこのような情報の入手が困難であった\n","- 現在は、SNSやWebの情報などあらゆる言語情報が電子化されており、これらを用いた情報セットを構築できるようになった\n","\n","この情報セットをコーパス(Corpus)と呼び、言語の使い方を記録・蓄積した文章文章集合一般のことを指す。特に計算機が理解できる辞書として利用できる場合、機械可読辞書(Machine-Readable Dictionary)と呼ぶ\n"]},{"cell_type":"markdown","metadata":{"id":"eQmOSAg8Rct8"},"source":["## 形態素解析(Morphological Analysis)\n","\n","コーパスがあっても直接処理するのは困難である\n","- 単純なデータの羅列であり、これを起点として解析するのは困難である\n","- そこで、自然言語のテキストデータから、対象言語の文法や辞書と呼ばれる単語の品詞等の情報に基づいて形態素(Morpheme)と呼ばれる意味を持つ最小単位語句に分割する(形態素解析)\n","  - 形態素の品詞等を判別する作業であるが、品詞を問わず分割だけ行うこともしばしば行われ、この分割作業を特に「分かち書き」と呼ぶ\n","\n","例えば、「じょうしがくるまでまつ」を形態素解析するとする\n","もし、単純な辞書(言葉としてあり得る単語群だけで構成されている)場合、次のような分割が想定される(実際にはごく一部でありさらに大量の分類が考えられる)\n","- じょ うし が くる ま でま つ (序 牛が来る 間 デマ 津)\n","- じょ うし が くる まで まつ (序 牛が来るまで待つ)\n","- じょ うし が くるま で まつ (序 牛が車で待つ)\n","- じょ うし が くるま でま つ (序 牛が車デマ津)\n","- じょう し が くる まで まつ (上/穣 死が来るまで待つ)\n","- じょう しが くるま でま つ (上 死が車 デマ 津)\n","- じょうし が くる ま で ま つ (上司が来る間で間 津)\n","- じょうし が くる ま で まつ (上司が来る間で待つ)\n","- じょうし が くる ま でま つ (上司が来る間 デマ 津)\n","- じょうし が くる まで まつ (上司が来るまで待つ)\n","- じょうし が くるま で まつ (上司が車で待つ)\n","\n","出来の悪い日本語変換システムの様であるが、形態素解析の難しさを説明するには十分であろう\n","- 機械学習で自然言語を扱おうと思ったら、扱うために文章を分かち書きすることすらも実は困難で、追加で機械学習が必要というやるせなさ\n","- 英語は分かち書きが文法として含まれており極めて合理的に機械学習させることができる\n","  - 機械学習に向いている言語と向いていない言語がある\n","  - 日本語は向いていない、少なくとも上記の例でも英語ならば、My boss is waiting in the car.などと分かち書きされているので何も混乱なく解析できる\n","\n","日本語の授業で自然言語処理を扱うのは、本当にエグイ\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AKeVjC9QRfsj"},"source":["## 構文解析（係り受け解析）\n","\n","形態素解析の結果からわかるように、「これはあり得ない」「この可能性は極めて少ない」という分類がある\n","\n","これらをどのように省くか、その手法をいくつか挙げる\n","\n","まず構文解析\n","- 係り受け解析とも呼ばれる\n","- 形態素解析で得られた単語間の関係性を解析する\n","- 各品詞を辞書から得て、その品詞の並びが自然かどうかを見る\n","\n","「じょ うし が くる ま でま つ (序 牛が来る 間 デマ 津)」は、(人名?)(一般名詞)(助詞)(動詞-連体形)(名詞)(名詞)(名詞)と最後が名詞の連続になり不自然というのがわかる"]},{"cell_type":"markdown","metadata":{"id":"pWIyvbxOSn_d"},"source":["## 意味解析\n","\n","構文解析を施した文章から正しく意味内容を解釈する処理\n","\n","構文解析で自然であった複数の可能性について、さらに意味的に自然かどうかを判定する\n","\n","先ほどの例では、候補に入っていないが、例えば、\n","\n","- 上司が車で待つ\n","- 城址が車で待つ\n","\n","というのは、解釈上異なり、意味的に城址は車で待つことはできないとわかる。\n","\n","計算機は意味そのものは理解できなくとも、ある一つの単語に存在する意味の意味と、その複数の意味について前後など他の単語間の繋がりが自然かを踏まえて適切な選択をしなければならない\n"]},{"cell_type":"markdown","metadata":{"id":"q0bCPJ-dVWeQ"},"source":["## その他の解析\n","\n","### 文脈解析\n","\n","複数の文に対して形態素解析と意味解析を行い、文を超えたつながりについて分析する\n","- じょうし が くる まで まつ (上司が来るまで待つ)\n","- じょうし が くるま で まつ (上司が車で待つ)\n","\n","これらは、単独ではどちらが正しいかは判断できず、前後の話の流れから選択する必要がある\n","- 文脈は、文章中に現れる語の関係や文章の背景に隠れた知識などといった複雑な情報が必要となり、意味解析以上に困難な処理となる\n","\n","### 照応解析\n","\n","代名詞や指示語などといった照応詞の指示内容の推定や、ゼロ代名詞と呼ばれる省略された名詞句を補完する処理\n","\n","### 談話解析\n","\n","実際の会話は、他の会話を会話文に入れるなど、複数文によって構成される\n","- 関連した一連の文を対象にして、文のまとまり、文章の構造、意味などを解析する処理"]},{"cell_type":"markdown","metadata":{"id":"gER684L5VyC5"},"source":["## Embedding(埋め込み)\n","\n","自然言語を計算可能な形に変換することをEmbeddingと呼ぶ\n","- シンプルには分かち書きした言葉それぞれにユニークな番号を振ること\n","- 単語や文章等をベクトル表現に変換する操作のことを指す場合が多い\n","\n","Embeddingにより、\n","- 数量表現になりコンピュータが処理できるようになる \\\n","機械学習アルゴリズムは、一般に文字列型を直接処理できない\n","  - 逆伝搬などは関数による数的表現ができなければ計算すらできない\n","- 変換方法次第で精度の向上が見込める \\\n","単に計算可能な形にするだけでなく、ベクトルの表現方法を工夫することで単語や文章の特徴をベクトル表現に組み込むことができる\n","  - 例えば、近い意味の単語同士を近いベクトルとなるように変換するなど\n"]},{"cell_type":"markdown","metadata":{"id":"-LKvgyp1XV7L"},"source":["## 実は自然言語処理は簡単、英語などの言語ならね\n","\n","日本語はともかく、英語などでは古くから自然言語処理が研究されてきた\n","\n","DNNによる自然言語解析ができるようになったため、単純なEmbeddingでも、DNNの方でうまく関連をつけてくれるようになり、高い精度を要求しないのであれば、複雑な形態素解析を行う必要がない\n","\n","ただ、英語ではつまらないので、とにかくこの授業は「日本語解析」にこだわる\n","- 精度が悪かろうが、時間が掛かろうが、こだわる\n","- なぜって？機械学習を学ぶことは、結局デーをどのように理解し、どのようにDNNに食べさせるかの方が重要だから、それを学びたいから"]},{"cell_type":"markdown","metadata":{"id":"taUm8ZqntcJJ"},"source":["# 記事の分類\n","\n","自然言語処理(Natural Language Processing:NLP)の基本として記事分類を扱う\n","\n","高度な処理が必要となるため、機械学習そのものよりもデータ処理、真にデータサイエンスについて理解を深めるという観点で学ぶこと"]},{"cell_type":"markdown","metadata":{"id":"JxhwLLycuelt"},"source":["## データセットの準備\n","\n","まずデータセットを準備する\n","- 今回用いるのは、日本語による自然言語処理でよく利用されるデータセットである「livedoorニュースコーパス」を用いて、ニュース記事のタイトルから、そのニュースの分類を行うことを考える \\\n","- オリジナルはhttps://www.rondhuit.com/download.html\n","にあるldcc-20140209.tar.gzを利用する\n","\n","各行の動作をしっかりと追いかけて理解するとよい\n","- カテゴリ名をディレクトリから取得\n","- そこからさらにカテゴリ内のファイルを取得\n","\n","一例を見てみると次のようなファイル内容になっている\n","\n","> http://news.livedoor.com/article/detail/6301422/ \\\n","> 2012-02-22T10:00:00+0900 \\\n","> 驚くほど長寿命な無線式！3年半も電池交換が不要なマウス\n","無線式マウスは、ケーブルがなくて使いやすい反面、電池の持ちが気になる人もいるだろう。そうした人に打ってつけのマウスがエレコムから登場する。 \\\n","> 2月下旬より発売されるIR LEDマウス「M-IR03DRシリーズ」は、赤外線LEDを使用することで消費電力を小さくし、電池使用期間「約3.5年間」を実現したワイヤレス省電力マウスだ。長文などを一気に閲覧できる「高速スクロール」機能を搭載した。\n","ボディカラーは、レッドとシルバー、ブラックの3色。\n","\n","- 1行目がURL、2行目が記事の日付、3行目にタイトルが入っているためこれを取得する\n","- linecacheを用いて任意の行を取得することもできるが、linecacheは全データを読み切ってメモリに保存するため今回の目的としては合致しない(しかしがら、両方試してもそれほど差がなかった) \\\n","title = linecache.getline(text_name, 3)"]},{"cell_type":"code","metadata":{"id":"FVnLS6Mehh-M"},"source":["cuda = \"cuda:0\"\n","import os\n","if not os.path.exists('text/topic-news/LICENSE.txt'):\n","  # ファイルが暗号化されているが、これはgoogle driveによるウィルス誤検出を回避するためである。\n","  #!wget \"https://drive.google.com/uc?export=download&id=15EvNnKB6Y6-jGpo1q6N5BZ8SqMI-xzze\" -O ldcc-20140209.zip\n","  !wget https://keio.box.com/shared/static/agjdm4m93o5lay6k0uy9wfadqi79hwpm -O ldcc-20140209.zip\n","if not os.path.exists('text'):\n","  !unzip -P dataai ldcc-20140209.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ujJRygNPM3L1"},"source":["from glob import glob\n","import pandas as pd\n","import linecache\n","# カテゴリを配列で取得\n","categories = [name for name in os.listdir(\"text\") if os.path.isdir(\"text/\" + name)]\n","print(categories)\n","datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n","for cat in categories:\n","  path = \"text/\" + cat + \"/*.txt\"\n","  files = glob(path)\n","  for text_name in files:\n","    with open(text_name, encoding=\"utf-8\") as f:\n","      line = f.readline()\n","      line = f.readline()\n","      title = f.readline()\n","    s = pd.Series([title, cat], index=datasets.columns)\n","    datasets = datasets.append(s, ignore_index=True)\n","datasets.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FvvbiumA8PVR"},"source":["pandas.sampleでデータをシャッフルする必要があるならば、次のようにするとよいが、ここではDataLoaderでシャッフルされるため必要ない\n","```\n","datasets = datasets.sample(frac=1).reset_index(drop=True)\n","datasets.head()\n","```\n","- pandas.sampleのfracは全データを再度サンプリングしなおしており、デフォルトでreplace=Falseなため、重複を許していない\n","- reset_indexで0から始まる行番号を振りなおしている"]},{"cell_type":"markdown","metadata":{"id":"8I5UptzJBsI3"},"source":["分かち書きをするため、MeCabライブラリを利用する\n","- MeCabのすごさはすぐにわかるので、まずはインストールして試してみよう"]},{"cell_type":"code","metadata":{"id":"ODvB30dGhXyy"},"source":["!apt install libmecab-dev mecab mecab-ipadic-utf8\n","!pip install mecab-python3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxDMBqSiivy3"},"source":["mecabインストール時に、/usr/local/etc/mecabrcではなく/etc/mecabrcに配置され、 \\\n","\n","error message: [ifs] no such file or directory: /usr/local/etc/mecabrc \\\n","\n","というエラーになるが、これを回避するため、シンボリックリンクを貼る"]},{"cell_type":"code","metadata":{"id":"rV8vd_axit37"},"source":["!ln -s /etc/mecabrc /usr/local/etc/mecabrc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YFVc1IVlm0F9"},"source":["専用の分かち書きを行うための関数の定義を行う"]},{"cell_type":"code","metadata":{"id":"bgF3F_mkg8Uw"},"source":["import MeCab\n","import re\n","\n","tagger = MeCab.Tagger(\"-Owakati\")\n","\n","def make_wakati(sentence):\n","  # MeCabで分かち書きを行う\n","  sentence = tagger.parse(sentence)\n","  # 半角全角英数字などは削除する\n","  sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n","  # 記号なども削除する\n","  sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n","  # スペース区切で形態素の配列に変換する\n","  wakati = sentence.split(\" \")\n","  # 空要素を削除する\n","  wakati = list(filter((\"\").__ne__, wakati))\n","  return wakati"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JEsi7WYuDwmD"},"source":["コマンドライン実行可能なのMeCabも入るので実際に試してみよう\n","- 日本語の形態素解析エンジンの中では最もよく使用されている\n","- これがMeCabである、いろいろ試してみるとよい"]},{"cell_type":"code","metadata":{"id":"wviQFEZyDhek"},"source":["!echo すもももももももものうち | mecab"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqwNjTdUDvoz"},"source":["## 形態素解析(Morphological Analysis)\n","\n","自然言語処理分野で主に事前処理として用いられ、対象言語の文法や単語の品詞情報をもとに文章を形態素(単語が意味を持つ最小の単位)に分解する解析のこと\n","- 文章を形態素解析することで文字列同士・集合同士の類似度計算が可能となる\n","- 文書検索分野では文字列を形態素解析し名詞のみを検索対象とするなどしている\n","- MeCabがすごいことはわかるが、一方で形態要素解析は完ぺきではないことも理解する\n","  - 一意にとれない文章が存在する \\\n","「にわにはにわにわとりがいる」という文章を解析する場合、「庭には二羽、鶏がいる」と「庭にハニワ、二羽、鳥がいる」の二通りの分解がある。つまり、意図しない結果になる場合がある。\n","  - 辞書が異なると解析結果も異なる \\\n","辞書を持っており、その辞書の内容から単語の品詞情報を取得する。辞書には単語の品詞情報が含まれているが、異なる辞書間で単語の種類や品詞情報が共通化されているわけではないため、利用する辞書によって分解が異なる。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8b3eJl3weVh8"},"source":["### MeCabの特徴\n","\n","MeCabの特徴は次の通り\n","\n","1. 辞書やコーパス(テキストや発話を大規模に集めてデータベース化した言語資料)に依存しない汎用的な設計である\n","\n","1. 解析モデルとしてbi-gramマルコフモデルを利用\n","\n","まずはN-gramの概要\n","- 文書を文字単位の記号列と考え隣接したN個の記号毎の出現頻度(度数と呼ぶ)を集計する。隣接した1個の記号からなる記号列(つまり1文字)毎の度数をuni-gram、2個の記号をbi-gram、3個の記号ならをtri-gram,…と呼ぶ\n","- N-gramを利用すると文法情報を用いずに分解できるため言語に依存しない文書の分割が可能となる。さらに言語学的に意味を持たない記号列についても集計が可能となる\n","\n","マルコフ連鎖\n","- 確率過程の一種であるマルコフ過程のうち、とりうる状態が離散的な過程であり、特に時間が離散的である場合をさす。未来の挙動が過去の挙動と無関係で現在の値だけで決定される（マルコフ性）系列である\n","\n","bi-gramマルコフモデル\n","- あるタイミングの単語の生起確率は直前の1単語にのみ依存すると仮定したモデルで、単純マルコフ過程となる。なお、N-gramに拡張した場合あるタイミングの単語の生起確率は直前のN-1単語にのみ依存すると定義しN-1重マルコフ過程に従うことを表す\n","- ある単語列$W=w_1,w_2,…w_n$が与えられたとき、単語列を$W$コーパス内の単語の生起確率を$C$とすると，同時生起確率$P(W)$は以下の式で定義される．\n","$P(W)=∏^n_{i=1}P(w_i|w_i−1)=∏_n^{i=1}(\\frac{C(w_i,w_i−1)}{C(w_i−1)})$\n","- 例えば「私はAIが嫌い」という単語列の同時生起確率Pを表す式は、BOSを文章開始、EOSを文章の終わりを示す符号とすると以下のようになる．\n","$P(私は授業が嫌い)=P(私|BOS)P(は|私)P(AI|は)P(が|AI)P(嫌い|が)P(EOS|嫌い)$\n","  - BOSやEOSの生起確率は、文章には必ず開始と終了があるため1となる。また、各単語の生起確率はコーパス内での各単語の度数/全単語数で計算する"]},{"cell_type":"markdown","metadata":{"id":"Mdq3DGF1ihs9"},"source":["コスト推定はコーパスから学習し、その学習モデルとして、条件付き確率場(Conditional Random Fields:CRF)を用いる\n","\n","- CRFは系列ラベリングの一手法で、系列データが与えられると対応する系列ラベルを出力することができる\n","- MeCabの入力の系列データは単語分割済みの文字列配列(例えば慶應)で、出力は品詞情報などを保持したオブジェクトの配列(例えば固有名詞)\n","- ある関数の引数について、定められた条件に合致するかどうかを1か0で返す関数(普通のif構文)を組成関数と呼び、t番目の単語($x_t$)と、その対象となる一つ前の単語($y_t$)、さらにその一つ前の単語($y_{t-1}$)にのみ依存すると仮定する\n","\n","CRFの計算式\n","\n","組成関数を$\\phi$、確率の総和を1にするための正規化項を$Z$とすると、  \n","$P(y|x)=\\frac{1}{Z(x,\\alpha)}\\exp(\\alpha^T\\phi(x,y))$  \n","$Z(x,\\alpha)=\\sum_y \\exp(\\alpha^T\\phi(x,y))$  \n","$\\alpha^T\\phi(x,y)=\\sum_{t,i}\\alpha_i\\phi_i(x_t,y_{t-1},y_t)$"]},{"cell_type":"markdown","metadata":{"id":"SSSL7a82e90q"},"source":["3. 高い解析精度があり、他のChaSenやKAKASIに比べ高速\n","3. 辞書引きアルゴリズムおよびデータ構造に高速なTRIE構造であるDouble-Arrayを用いている\n","  - 再入可能なライブラリ\n","  - 各種スクリプト言語をバインディング(perl/ruby/python/java/C#)\n","3. 解探索アルゴリズムにViterbi(ビタビ)を利用\n","  - 観測された事象系列を結果として生じる隠された状態の最も尤もらしい並び（ビタビ経路）を探す動的計画法アルゴリズムの一種で、隠れマルコフモデルに基づく\n","    - 隠れた状態への最適経路は、一つ前の隠れた状態までの最短経路と無関係に決まる\n","  - 隠れた状態までの最短経路のコストの計算量は、各隠れた状態にいたる経路の総数の加算回数となり、計算量は隠れた状態数に比例する\n","3. 連接表は2次元テーブルで実装される\n","3. 品詞の階層は無制限多階層である\n","3. 制約付き解析やN-best解を与えることができる"]},{"cell_type":"markdown","metadata":{"id":"sAVWm19Nlb8M"},"source":["### ビタビアルゴリズム\n","\n","例えば最短経路を探す場合、次のような道路の最短経路を探すことを考えれば、その計算コストはあっという間に増えてしまう\n","- そこで川に掛けられた橋に注目し、橋までの最短距離を段階的に（川ごとに）求める\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/viterbi1.gif\" width=400>\n","\n","まず、橋から橋への最短ルートを地図から読み取りその距離を求める。例として次の図が得られる\n","- 第１段階はＡ川の橋a1,a2,a3を渡るときで、それぞれスタート地点から一本の道しかなく、その距離を橋の名称と一緒に赤色で記述する\n","- 第２段階はＢ川を渡るとき。橋b1へは３本の道があるが、その中で最短の道を太線で表記し、その距離を橋の名称と一緒に赤色で記述する。この時、3回の加算計算でよく、この操作を、b2, b3に対しても行う\n","- これらの処理をゴールまで行うと、ゴールから太線に沿ってスタート地点まで、分岐することなく遡ることができ、最短経路となる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/viterbi2.gif\" width=500>\n","\n","この場合、結果は次の図のようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/viterbi3.gif\" width=400>\n"]},{"cell_type":"markdown","metadata":{"id":"z4vBeDw6qarn"},"source":["### MeCabの取り込み\n","\n","定義したmake_wakatiを試してみる"]},{"cell_type":"code","metadata":{"id":"VN53KePMkAqi"},"source":["# テスト\n","test = \"「データシステムの知能化とデザイン」という授業は色々な意味でやばい授業と聞いている\"\n","print(make_wakati(test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bAK13AWSmsZ6"},"source":["## 文章のデータ化\n","\n","文章を言葉ではなく、データとして扱えるようにする\n","- 文章を形態素解析する\n","- 全ての単語にIDを割り振って、IDの配列にする\n","- 配列の長さを揃える\n","\n","以上の手順を踏む\n","\n","まずは、必要な関数を揃える"]},{"cell_type":"code","metadata":{"id":"nVrPZcRuj-_T"},"source":["# 単語ID辞書を作成する\n","word2index = {}\n","# パディング(padding)用の文字とIDを指定する。ここでは0(後述)\n","word2index.update({\"<pad>\":0})\n","for title in datasets[\"title\"]: # タイトルを一つ取り出す\n","  wakati = make_wakati(title) # 取り出したタイトルを分かち書きする\n","  for word in wakati: # 分かち書きごとに繰り返す\n","    if word in word2index: continue # すでにあった単語は無視\n","    word2index[word] = len(word2index) # 新しい単語は番号をつけて保存\n","print(\"vocab size : \", len(word2index))\n","\n","# 文章を単語IDの系列データ(つまり配列)に変換\n","def sentence2index(sentence):\n","  wakati = make_wakati(sentence)\n","  return [word2index[w] for w in wakati]\n","\n","# カテゴリも同様に辞書を作成する(重複を無くす)\n","cat2index = {}\n","for cat in categories:\n","  if cat in cat2index: continue\n","  cat2index[cat] = len(cat2index)\n","\n","# カテゴリ番号を返す\n","def category2index(cat):\n","  return [cat2index[cat]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vGbJhE-q-W2T"},"source":["一番長い(単語数の多い)に合わせてインデックスの配列を準備する\n","- この時、それよりも短いタイトルは全てpaddingつまり0埋めを行う\n","- 0である必要は実はない\n","- 後ろに0を入れるなら title.append(0)とするが、LSTMでは後ろに0を入れると次の値を求めるのが不安定になる。0だと学習がうまくいかない。後ろを1にすることもできるが、学習が遅くなる(できなくはない)\n","  - そもそも後ろpaddingならばコメントのようにpad_sequenceを使って一発で終わる\n","- 素直に、前にパディングを入れるとよい。\n","  - `word2index.update({\"<pad>\":0})`としているため0を埋める"]},{"cell_type":"code","metadata":{"id":"-dgnCaTpqKDm"},"source":["import random\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","device = torch.device(cuda if torch.cuda.is_available() else \"cpu\")\n","\n","index_datasets_title_tmp = []\n","index_datasets_category = []\n","\n","# 系列の長さの最大値を取得。この長さに他の系列の長さをあわせる\n","max_len = 0\n","# pandasのdatasetsからtitleとcategoryを順番にセットで取り出す\n","for title, category in zip(datasets[\"title\"], datasets[\"category\"]):\n","  index_title = sentence2index(title)\n","  index_category = category2index(category)\n","  index_datasets_title_tmp.append(index_title)\n","  index_datasets_category.append(index_category)\n","  if max_len < len(index_title):\n","    max_len = len(index_title)\n","\n","# 系列の長さを揃えるために短い系列にパディングを追加\n","index_datasets_title = []\n","for title in index_datasets_title_tmp:\n","  for i in range(max_len - len(title)):\n","    title.insert(0, 0) # 前パディング\n","#    title.append(1) # 後ろパディング(学習が遅くなる)、pad_sequenceを使うべき\n","  index_datasets_title.append(title)\n","\n","# tensorのlistである必要があるため、  index_datasets_title_tmp.append(torch.tensor(index_title))としておく\n","#index_datasets_title = nn.utils.rnn.pad_sequence(index_datasets_title_tmp, batch_first=True, padding_value=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_t6q9len0VE8"},"source":["## DataLoaderの準備\n","\n","- タイトルとカテゴリーをセットにしてデータを作成\n","- 20%をランダムに抜きだして学習に仕様しない確認用データとする\n","\n","ナイーブに、分割後のデータに含まれる記事分類の比率が元の比率と異なってもよいならば、TensorDatasetを作成した後、次のようにシンプルにやればよい\n","```\n","n_samples = len(title_cat_datasets)\n","train_size = int(n_samples*0.8)\n","test_size = n_samples - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(title_cat_datasets, [train_size, test_size])\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size, shuffle=True)\n","```\n","実際にそういうコードをよく見かける\n","\n","ここでは、すでに扱ったが、層化分類、つまり比率を守るように分類する\n","- PyTorchにはそのような機能が残念ながら存在しない\n","- scikit-learnのtrain_test_splitの機能を併用して実現する\n","- この関数は、indexつまり、何番目のデータであるかの配列を与えるため、`torch.utils.data.Subset`を用いてデータセットを作成する\n","- ついでに応用が効きやすいようにtransformerも使う\n"]},{"cell_type":"code","metadata":{"id":"RgilOSak7N7N"},"source":["from sklearn.model_selection import train_test_split\n","import torchvision.transforms as transforms\n","\n","batch_size = 100\n","\n","transformer = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","title_data = torch.tensor(index_datasets_title)\n","cat_data = torch.tensor(index_datasets_category)\n","alldataset = torch.utils.data.TensorDataset(title_data, cat_data)\n","# データセットをtrainとvalidationに分割\n","train_indices, test_indices = train_test_split(list(range(len(title_data))), test_size=0.2, stratify=cat_data)\n","train_dataset = torch.utils.data.Subset(alldataset, train_indices)\n","test_dataset = torch.utils.data.Subset(alldataset, test_indices)\n","# DataLoaderを作成\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U4K8gv-QuOfv"},"source":["\n","\n","これらのどの戻り値を使うべきかは、LSTMで解きたいタスクによる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/lstmio.png\" width=600>\n","\n","今回は文章(many)を１つのカテゴリに分類(one)したいので、今回もmany to oneモデルとなる"]},{"cell_type":"markdown","metadata":{"id":"2NrgdRnIjtyW"},"source":["## モデルの構成\n","\n","単語のベクトルは本来はword2vecで学習済みモデルがあればその方が良い結果となる\n","- word2vecは別の機会に\n","- なお、word2vecを利用するのは背景知識を利用する、つまり、与えられたデータセット以外のデータを利用することになるためアンフェアともいえる\n","\n","ここではPyTorchのtorch.nn.Embeddingを利用する\n","- 単語を狙った次元で表現する。例えば、5次元に「単語」という言葉を埋め込むと次のようになる\n","```\n","tensor([[-0.5962, -1.2342,  1.1888, -1.1408, -0.3594]], grad_fn=<EmbeddingBackward>)\n","```\n","- 文章の場合これが2次元配列となる。例えば、5次元に「単語の羅列です」を埋め込むと「単語」「の」「羅列」「です」という4つの言葉に分解され、それぞれが5次元のコードになるため次のような系列長x埋め込み次元=4x5次元の内容となる\n","```\n","tensor([[-0.5962, -1.2342,  1.1888, -1.1408, -0.3594],\n","        [ 0.8564,  1.8212, -0.6291,  0.4318,  1.5869],\n","        [ 0.2528, -0.3460,  0.0923, -0.7709, -0.6723],\n","        [ 1.7714,  0.0655, -0.6220, -0.3896, -0.5604]],\n","       grad_fn=<EmbeddingBackward>)\n","torch.Size([4]) -> torch.Size([4, 5])\n","```\n","\n","- paddingする場合、padding文字に対してコードが埋め込まれるのは不本意\n","  - `padding_idx=埋め込みコードの番号`とし、コードを生成せず0とするように指定できる\n","\n","- さらにミニバッチ化した場合、バッチ数x系列長x埋め込み次元になる\n","  - LSTMなどのRNNでbatch_first=Trueとした時の入力で要求される形と等しい"]},{"cell_type":"code","metadata":{"id":"wI91OOW2qN6c"},"source":["class LSTMCF(nn.Module):\n","  def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n","    super(LSTMCF, self).__init__()\n","    self.hidden_dim = hidden_dim\n","    # <pad>の単語IDが0なので、padding_idx=0とする\n","    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","    # batch_first=Trueが大事！\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","    self.fc = nn.Linear(hidden_dim, tagset_size)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, sentence):\n","    embeds = self.word_embeddings(sentence)\n","    #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n","    y, (lstm_out, c) = self.lstm(embeds, None)\n","    # lstm_out[0].size() = (1 × batch_size × hidden_dim)\n","    tag_space = self.fc(lstm_out[0]) # テンソルの最初の要素数が1のためlstm_outでもよい\n","    # さらに言えば、tag_space = self.fc(y[:, -1, :])も同じ\n","    # tag_space.size() = (1 × batch_size × tagset_size)\n","\n","    # (batch_size × tagset_size)にするためにsqueeze()する\n","    tag_scores = self.softmax(tag_space.squeeze())\n","    # tag_scores.size() = (batch_size × tagset_size)\n","\n","    return tag_scores\n","\n","EMBEDDING_DIM = 200 # 単語の埋め込み次元数\n","HIDDEN_DIM = 128 # 隠れ層の次元数\n","VOCAB_SIZE = len(word2index) # データ全体の単号数\n","TAG_SIZE = len(categories) # 分類先のカテゴリ数\n","model = LSTMCF(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n","loss_function = nn.NLLLoss() # LogSoftmaxの場合はNLLossを利用\n","optimizer = optim.Adam(model.parameters(), lr=0.001) # 最適化 lrは適切に設定すること"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trur36WFpOUF"},"source":["## 学習\n","1分程度で終わる\n","- 過学習にならないように注意する"]},{"cell_type":"code","metadata":{"id":"j9Dt-GLgqUfy"},"source":["losses = []\n","for epoch in range(30):\n","  all_loss = 0\n","  for j, (title_batch, category_batch) in enumerate (train_loader):\n","    batch_loss = 0\n","    model.zero_grad() # モデルの勾配の情報をリセット\n","    title_batch = title_batch.to(device)\n","    category_batch = category_batch.to(device)\n","    out = model(title_batch)\n","    batch_loss = loss_function(out, category_batch.squeeze())\n","    batch_loss.backward()\n","    optimizer.step()\n","\n","    all_loss += batch_loss.item()\n","  losses.append(all_loss)\n","  print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n","  if all_loss < 0.1: break\n","print(\"done.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J5UNnoE1pnMk"},"source":["## 結果\n","\n","学習が素早く進むことからわかるように、問題としてはとてもシンプルである"]},{"cell_type":"code","metadata":{"id":"tH0aT53OqlnJ"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.plot(losses)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjVCeZtIhiFV"},"source":["### 評価用データで確認\n","\n","およそ6割から7割程度の正答率となり、それほど高くない\n","- 一方で学習に用いたデータであれば9割以上正解しているため、過学習ともいえるが、どちらかというと単語空間と比較してデータセットが少ない問題とも取れる\n","\n","- torch.maxとしているのは、結果がLogSoftmaxで生成しており、記事が9種類であるため要素数は9となる\n","  - LogSoftmaxはSoftmaxのように0から1の値をとらないが、いずれにしても一番大きな値を予測結果として与える\n","  - 例えば次のような結果である場合、最初の要素が該当する記事が最も近しいと判断される\n","```\n","tensor([[ -0.5003,  -3.5191,  -8.0818,  -2.5900,  -8.1883,  -8.2956, -11.2307, -11.2474,  -1.2442]], grad_fn=<LogSoftmaxBackward>\n","```\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"gNjyZiw2JJDM"},"source":["type(test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOoazg-1qewp"},"source":["a = 0\n","t = 0\n","testiter = iter(test_loader)\n","with torch.no_grad():\n","  for (title_test, category_test) in testiter:\n","    title_tensor = title_test.to(device)\n","    category_tensor = category_test.to(device)\n","    out = model(title_tensor.squeeze())\n","    _, predicts = torch.max(out, 1)\n","    for j, ans in enumerate(category_tensor):\n","      t += 1\n","      if predicts[j].item() == ans.item():\n","        a += 1\n","print(\"predict : \", a / t, \" Total : \", t)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1b0LQFTvgs1"},"source":["### カテゴリ別の評価\n","\n","各カテゴリごとにF値を求める"]},{"cell_type":"code","metadata":{"id":"MlqvctwBn7hj"},"source":["import collections\n","# IDをカテゴリに戻す用\n","testiter = iter(test_loader)\n","# answer -> 正解ラベル、predict->LSTMの予測結果、exact->正解してたらO,間違っていたらX\n","predict_df = pd.DataFrame(columns=[\"answer\", \"predict\", \"exact\"])\n","\n","# 予測して結果を上のDFに格納\n","with torch.no_grad():\n","  for (title_test, category_test) in testiter:\n","    title_tensor = title_test.to(device)\n","    category_tensor = category_test.to(device)\n","    out = model(title_tensor.squeeze())\n","    _, predict = torch.max(out, 1)\n","    predict = predict.to('cpu')\n","    for num, (title, category) in enumerate(zip(title_test, category_test)):\n","      categ = category[0].numpy().copy().tolist()\n","      pred = predict[num].numpy().copy().tolist()\n","      exact = \"O\" if pred == categ else \"X\"\n","      s = pd.Series([categ, pred, exact], index=predict_df.columns)\n","      predict_df = predict_df.append(s, ignore_index=True)\n","\n","# Fスコア格納用のDF\n","fscore_df = pd.DataFrame(columns=[\"category\", \"all\", \"precison\", \"recall\", \"fscore\"])\n","\n","# 分類器が答えた各カテゴリの件数\n","prediction_count = collections.Counter(predict_df[\"predict\"])\n","print(prediction_count)\n","# 各カテゴリの総件数\n","answer_count = collections.Counter(predict_df[\"answer\"])\n","\n","def icat2index(val):\n","  keys = [k for k, v in cat2index.items() if v == val]\n","  if keys:\n","    return keys[0]\n","  return None\n","\n","# Fスコア求める\n","for i in range(9):\n","  all_count = answer_count[i]\n","  precision = len(predict_df.query('predict == ' + str(i) + ' and exact == \"O\"')) / prediction_count[i]\n","  recall = len(predict_df.query('answer == ' + str(i) + ' and exact == \"O\"')) / all_count\n","  fscore = 2*precision*recall / (precision + recall)\n","  s = pd.Series([icat2index(i), all_count, round(precision, 2), round(recall, 2), round(fscore, 2)], index=fscore_df.columns)\n","  fscore_df = fscore_df.append(s, ignore_index=True)\n","print(fscore_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VmWK2fnuvqWn"},"source":["カテゴリにより正答率にかなりバラ次があることがわかる。smaxはよく当たるが、peachyは当たらない様子\n","\n","になみに、次の通りらしいが、よく利用される（本当によく見る）ニュース記事分類データとしてどうなのか？とも思うところがある\n","\n","- peachy: Peachy (毎日をハッピーに生きる女性のためのニュースサイト) \n","- it-life-hack: ITライフハック\n","- MOVIE ENTER: movie-enter\n","- topic-news:トピックニュース\n","- spoarts-watch: Sports Watch\n","- livedoor-homme: livedoor HOMME　(男性向けライフスタイルWebマガジン)\n","- kaden-channel: 家電チャンネル\n","- dokujo-tsushin: 独女通信（独身女性向けのコラム）\n","\n","peachyとdokujo-tsushinとどのように見分けるのか逆に気になる"]},{"cell_type":"markdown","metadata":{"id":"81EiiwzKLjN0"},"source":["# Seq2Seqによる自動翻訳\n"]},{"cell_type":"markdown","metadata":{"id":"cZqvJA5quOl-"},"source":["## Seq2Se1による自動翻訳\n","\n","単語を数値化する手法として、今回もnn.Embeddingを引き続き利用する\n","\n","RNNについては既に説明済みであるため省略するが、次のイメージで翻訳作業が進む\n","  - なお、Encoder RNNは複数記述されているが、何度も説明するようにこれらは同一モデルであり、同一モデルを複数回利用することに注意する\n","  - 説明では展開された図(これをアンロールと呼ぶ)がよく利用される\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/seq2seq_6.gif\" width=600>\n"]},{"cell_type":"markdown","metadata":{"id":"nnUYr-rxhNdK"},"source":["## 自動翻訳\n","\n","自動翻訳を考える。単純にネットワークの入力にある文章、ネットワークの出力に翻訳した文章を与え学習させればよいと考えるであろう。実際には、文章と翻訳した文章は長さが異なるため単純に処理できない\n","- 例えば、`I want to learn Artificial Intelligence.`を`私は人口知能を学びたい。`と翻訳するとする。\n","  - 学習の都合からすれば、Iを「私」、wantを「たい」といった対応をとって学習させたいであろうから、日本語は分かち書きが必要となる\n","- 分かち書きを行い、`I want to learn Artificial Intelligence.`を`私 は 人口知能 を 学び たい。`とする。これをそのまま食べさせてもよいが、次のような問題がある\n","  - そもそも、翻訳させたいのはこの文章だけではなく、様々な文章がある。その長さも異なる。つまり、入力ノードの数は固定ではない\n","  - 翻訳された言語がもつ長さも変化し、入力ノードの数も異なる\n","  - 記事分類では、paddingを行ったが、そもそも、記事分類では文章としての意味はなく、単語の並びでよかった\n","- 文章という単語の順番が問われる並びとして扱うにはどうするか？"]},{"cell_type":"markdown","metadata":{"id":"cpjtIubShQcs"},"source":["## Seq2Seq\n","\n","Seq2Seqは、シーケンスつまり並びを入力とし、並びを出力するために考案された手法である\n","\n","まず、技術的なブレークスルーは次の通りである\n","- EncoderとDecoderにより構成され、AutoEncoderに似ているが中身は異なり、並びを重視するためRNNを利用する\n","- 並びに加えて始まりと終わりも重視するため、文章の開始を意味するStart of String(SOS)と文章の終わりを意味するEnd of string(EOS)をスペシャルキャラクタとして導入し、SOS 文章 EOSとして表現する\n","  - つまり入力と出力で長さが変化してもよい\n","\n","Seq2Seqを用いて翻訳するイメージは次の通り\n","  - contextが潜在空間表現となる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/seq2seq_4.gif\" width=600>"]},{"cell_type":"markdown","metadata":{"id":"1YL-0rycwsBu"},"source":["### Attention\n","\n","察しの良い人は気づいているかもしれないが、ばらばらの単語で構成される文章がcontextとして簡単に潜在空間で表現できるのだろうか？という疑問はぬぐい切れない\n","- 実際、contextを用いるだけでは、長文の扱いが難しくなり、これがモデル設計上の障害となる\n","\n","その解決策としてAttentionが提案され、機械翻訳精度が向上した\n","- Attentionとは、入力系列の中から必要な要素に注目する手法のこと\n","\n","Attentionは、「ここに注意しろ！」と重要事項をマークする機構であり、例では「étudiant」(仏語で「学生」)に注目させることで精度向上を狙う"]},{"cell_type":"markdown","metadata":{"id":"V2Qwbs27zZTa"},"source":["#### Attentionの特徴その1\n","\n","Attentionではあるcontextを注目させるために、Encoderはcontextとしてまとめた状態(最後の潜在空間ベクトル)だけでなく、各単語処理における全context(全潜在空間ベクトル)を渡す\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/seq2seq_7.gif\" width=600>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ucje5TQ6zXya"},"source":["#### Attentionの特徴その2\n","\n","注目できるようにするために、出力を生成する前に次のような処理を施す\n","- Encoderの全潜在空間ベクトルを見る\n","  - 各潜在空間ベクトルは各入力系列の要素(ここでは単語)に強く影響を受けた値となる\n","- 各潜在空間ベクトルにスコアとしての重みを与える\n","  - 実際の計算方法は後述\n","- 各潜在空間ベクトルにSoftMaxを通した重みを乗算する\n","  - 重みの大きなベクトルは増幅され、小さなベクトルは縮小される\n","  - この処理をDecoder各ステップで行う\n","\n","ここまでの処理をアニメ化してみると次のようになる\n","- $h_1$, $h_2$, $h_3$の全ベクトルを受け取る\n","- 最初は潜在空間ベクトルの初期入力値$h_{init}$とENDトークンを用いて潜在空間ベクトルh4を入手する\n","  - この時出力は破棄する(出力は使わない!)\n","- 受け取った全潜在空間ベクトルと$h_4$に対して重みを算出、SoftMaxを施した値を掛けてcontext$C_4$を作成\n","- $h_4$と$C_4$を結合して全結合層に入れ、その結果を新たな次のステップへの入力(ここではENDであった)とする\n","\n","この処理を繰り返す\n","  - 実際にはさらにteacher forcingというテクニックを利用する(後述)\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/attention_tensor_dance.gif\" width=800>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9nb9WF05HKVg"},"source":["結果的に、次のようにたとえ長さが異なったとしても、それぞれどこにどの程度注目して単語を導き出すべきかを適切に判断できるようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/seq2seq_9.gif\" width=400>\n","\n","Attentionは、最初の主力単語と最初の入力系列の単語とを対応させず、各単語毎の対応が訓練時に学習できるようになる\n","\n","仏語から英語に変換する場合、次のような対応となり、かつ言語における語順の差も吸収されていることがわかる\n","- 仏語はzone économique européenneと、形容詞が牛鹿に来るため英語と語順が逆になっているがそれも含めて正しく表現できている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/attention_sentence-1.png\" width=400>"]},{"cell_type":"markdown","metadata":{"id":"phb5VfRuL1Rx"},"source":["### 準備処理とEncoder\n","\n","PyTorchのチュートリアルに優れた例があるためこれを利用する\n","- 例は上記のSeq2Seqの説明をそのまま実装している\n","- チュートリアルは仏語と英語の翻訳であったが、これではつまらないし、仏語はわからないため、日本語にチャレンジする\n","  - ただし、ちょっとだけチートする\n","  - 日本語を実現しているコードは見当たらないので丁度良い\n","  - 時間がある人、チャレンジしたい人はMeCabを利用するとよい\n","- 実際のモデルとして、シーケンスつまり順番を問題とするためRNNを用いる。ここでは、比較的処理速度が速いGRUを利用する\n","\n","まずはデータをダウンロードする\n","- fr.txt: 普通によくある仏語と英語を翻訳するためのテキスト\n","- jp.txt: 本格的に日本語にチャレンジしたい人向け、MeCabの力を借りる必要があるので、発展問題的に利用\n","- jp-k.txt: 今回実際に利用する「ハック済」テキストで、要するに先にカタカナ変換してある\n","  - MeCabを使った方が正確であるが、お手軽に済ませるためkakasiを利用した"]},{"cell_type":"code","metadata":{"id":"3ZyVoreUEvEY"},"source":["import os\n","if not os.path.exists('fr.txt'):\n","  !wget \"https://drive.google.com/uc?export=download&id=15VFFwii1jbFXsfWmrd_9MErrOLitF_WD\" -O fr.txt\n","if not os.path.exists('jp.txt'):\n","  !wget \"https://drive.google.com/uc?export=download&id=1boWJ1CkOxoxN2qIlJjt9KZ-g2I_HuxM5\" -O jp.txt\n","if not os.path.exists('jp-k.txt'):\n","  !wget \"https://drive.google.com/uc?export=download&id=1-MNyU0oG-EiGqYa5whvcoJIitDuS4GCi\" -O jp-k.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s3CaX77BNPcc"},"source":["各種ライブラリを読み込む"]},{"cell_type":"code","metadata":{"id":"9be7yXdqz21f"},"source":["from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(cuda if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uVItV_1ez21g"},"source":["#### データの読み込み\n","\n","- ファイルからデータを読み込む\n","  - データとして、タブで隔てられ、スペースで単語毎に区切られたデータを利用する\n","  - I am cold.[TAB]J'ai froid.\n","  - I am cold.[TAB]Kaze wo Hiita.\n","\n","- 新しい単語を見つけるたびに新しい番号を与え、これをword2indexとしてwordからindexへの変換関数(実際は連想配列)とする\n","  - これは記事分類の例と同じ\n","\n","- その逆引きを行うindex2wordも作成する\n","- さらにレアな単語は学習の邪魔になるため置き換えを行うが、そのために必要な単語の出現数を管理するword2countも作成する\n","\n","以上を管理するヘルパークラスLangを設計する#"]},{"cell_type":"code","metadata":{"id":"oSqAFMmXz21i"},"source":["SOS_token = 0\n","EOS_token = 1\n","class Lang:\n","  def __init__(self, name):\n","    self.name = name\n","    self.word2index = {}\n","    self.word2count = {}\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","    self.n_words = 2  # Count SOS and EOS\n","  def addSentence(self, sentence):\n","    for word in sentence.split(' '):\n","      self.addWord(word)\n","  def addWord(self, word):\n","    if word not in self.word2index:\n","      self.word2index[word] = self.n_words\n","      self.word2count[word] = 1\n","      self.index2word[self.n_words] = word\n","      self.n_words += 1\n","    else:\n","      self.word2count[word] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"msVdjxXaz21j"},"source":["単純化するためにUnicode文字(例えば仏語のアクセントなど)をアスキー文字(普通のアルファベット)に変え、総て小文字とし、さらに各種記号を単語と同様に一つの記号にする\n","- この機構をすり抜けるためにjp-k.txtではハックを行っている\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"E8IqGp-Wz21j"},"source":["def unicodeToAscii(s):\n","  return ''.join(\n","    c for c in unicodedata.normalize('NFD', s)\n","    if unicodedata.category(c) != 'Mn'\n","  )\n","\n","def normalizeString(s):\n","  s = unicodeToAscii(s.lower().strip())\n","  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","  return s"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CbTsoxtzz21k"},"source":["データファイルから行ごと読み込み、さらに行をペアに分割する\n","- 行は全て英語[TAB]他の言語、となっており、この2つのセットをペアと呼ぶ\n","- 他の言語から英語へ翻訳する場合は、reverseフラグを用いることでペアを逆にすることができる\n"]},{"cell_type":"code","metadata":{"id":"Yv5j34aAz21l"},"source":["def readLangs(lang1, lang2, reverse=False):\n","  print(\"Reading lines...\")\n","  # ファイルを読んで行に分割\n","  lines = open('jp-k.txt', encoding='utf-8').read().strip().split('\\n')\n","  # 各行をタブで分割\n","  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","  # reverseフラグが立っていたら反転する\n","  if reverse:\n","    pairs = [list(reversed(p)) for p in pairs]\n","    input_lang = Lang(lang2)\n","    output_lang = Lang(lang1)\n","  else:\n","    input_lang = Lang(lang1)\n","    output_lang = Lang(lang2)\n","  return input_lang, output_lang, pairs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BDLU3CTGz21l"},"source":["長い文章が含まれるため、短く単純な文章に短縮してデータセットを構築する\n","- ここでは最大長を 10 単語とする\n","- 英語文章の特徴である省略形を画一化しておく\n","  - 実際には日本語についても同様の処理が必要であるが、今回は対応していない"]},{"cell_type":"code","metadata":{"id":"ytafSHepz21l"},"source":["MAX_LENGTH = 20\n","eng_prefixes = (\n","  \"i am \", \"i m \",\n","  \"he is\", \"he s \",\n","  \"she is\", \"she s \",\n","  \"you are\", \"you re \",\n","  \"we are\", \"we re \",\n","  \"they are\", \"they re \"\n",")\n","def filterPair(p):\n","  if(len(p[0].split(' ')) < MAX_LENGTH and\n","    len(p[1].split(' ')) < MAX_LENGTH and\n","    p[1].startswith(eng_prefixes)):\n","    return True\n","  else:\n","    return False\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BkbMx150z21m"},"source":["#### データセットの作成\n","- まず、テキストファイルを読んで行に分割し、これをペアに分割する(readLangs)\n","- テキストの文字をアスキーに変換し長さを限定する(filterPairs)\n","- ペアの文章から単語リストを作成する(addSentencesメソッド)"]},{"cell_type":"code","metadata":{"id":"uTuZuV0kz21m"},"source":["def prepareData(lang1, lang2, reverse=False):\n","  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","  print(\"Read %s sentence pairs\" % len(pairs))\n","  pairs = filterPairs(pairs)\n","  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","  print(\"Counting words...\")\n","  for pair in pairs:\n","    input_lang.addSentence(pair[0])\n","    output_lang.addSentence(pair[1])\n","  print(\"Counted words:\")\n","  print(input_lang.name, input_lang.n_words)\n","  print(output_lang.name, output_lang.n_words)\n","  return input_lang, output_lang, pairs\n","input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n","print(random.choice(pairs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WGX-o66Cz21m"},"source":["### Encoder\n","\n","- 特に工夫なく、まずEmbeddingを行い、GRUにかける\n","- 潜在空間ベクトルの初期値を0にするためのinitHiddenメソッドも準備しておく"]},{"cell_type":"code","metadata":{"id":"Pq2QzTgTz21n"},"source":["class EncoderRNN(nn.Module):\n","  def __init__(self, input_size, hidden_size):\n","    super(EncoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.embedding = nn.Embedding(input_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size)\n","  def forward(self, input, hidden):\n","    embedded = self.embedding(input).view(1, 1, -1)\n","    output = embedded\n","    output, hidden = self.gru(output, hidden)\n","    return output, hidden\n","  def initHidden(self):\n","    return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ohlV3jnlz21n"},"source":["### Attentionを用いたDecoder\n","\n","Encoderの出力ベクトルを取り翻訳を作成する\n","- 実際には単語のシーケンスを出力する\n","\n","ここでは、Attentionを用いたDecodeを構成する\n","- 既に説明した通りであるが、dropout層も加えてより実践的な構成となっている\n","- 先にも述べたが、AttentionはDecoderに対してEncoderの全潜在空間ベクトルを提供し、かつ、Encoderの出力の異なる部分に注目させる"]},{"cell_type":"markdown","metadata":{"id":"aqTlCFYjhYU9"},"source":["#### 重みの計算\n","\n","最初に attention重みのセットを計算する\n","- `embedded = self.embedding(input)`としてまずはEmbeddingする\n","  - 繰り返しになるがword2vecを使った方がよくなる可能性がある\n","- `embedded = self.dropout(embedded)\n","`としてDropoutする\n","  - 文章表現の多様性を受け入れるため、過学習を避ける\n","  - Dropoutを10%程度行う\n","- `attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)`として重みを計算する\n","  - `[0]`は、`[[1, 2, 3]]`を`[1, 2, 3]`とするイメージ、batchなので仕方がない\n","  - `torch.cat`でテンソルをくっつける\n","    - `torch.cat`は興味深い動作をするので確認するとよい\n","    - dimは、`torch.size`で示されるテンソルの型について何番目の要素を連結するか(つまりその他の要素は完全に一致していなければならない)を指定する\n","```\n","i1 = torch.randn(1, 2, 3)\n","i2 = torch.randn(2, 2, 3)\n","i3 = torch.randn(3, 2, 3)\n","ilist = [i1, i2, i3]\n","o1 = torch.cat(ilist, dim=0) # OK! 0行目だけが違う\n","o2 = torch.cat(ilist, dim=1) # NG!\n","```\n","  - ここではbatchなので、batchサイズが100であれば、100個についてそれぞれでくっつけていることに注意すること"]},{"cell_type":"markdown","metadata":{"id":"6gskk-5O-lv5"},"source":["#### 重みを掛け合わせる\n","\n","torch.bmmを用いて、attn_weightsとencoder_outputsの行列積を計算する\n","\n","- 単純に行列の積を計算するが、実際にはバッチになっており複数の行列積を同時に行う必要がある\n","- `torch.bmm`は過去に1度登場しているが、バッチで行列積を計算する\n","  - テンソルごとを掛け算するため、unsqueeze(0)している\n","    - 例えば、`[1, 2]`が、`[[1, 2]]`となるイメージ\n","  - (0)はdimつまりどの次元で新しいテンソルを挿入するかを表す\n","    - dim=1とすると、先の例では`[[1],[2]]`となる\n","  - その他のPyTorchにおける行列積の計算について、巻末にまとめておく\n"]},{"cell_type":"markdown","metadata":{"id":"vYf0e6_WboWv"},"source":["#### 重みを結合する\n","\n","torch.catを用いて、embeddedとattn_appliedを結合する\n","- 先ほどと同様に`[0]`としており、`dim=1`である"]},{"cell_type":"markdown","metadata":{"id":"wqUIiyw2hdqA"},"source":["#### 全結合層で次元削減する\n","\n","結合したので要素数が増えており、これをhidden_sizeつまり潜在空間ベクトルのサイズまで縮約する\n","- 全結合層なので活性化関数(Activation Function)を指定、ここではReLUを用いるため、`output = F.relu(output)`とする"]},{"cell_type":"markdown","metadata":{"id":"ZaIwL6WHhf1W"},"source":["#### 再帰ニューラルネットワークを利用する\n","\n","ここでは`output, hidden = self.gru(output, hidden)`とあるようにGRUを利用\n","- EncoderとDecoder両方で利用することから、性能のわりにコストが小さいのが良い"]},{"cell_type":"markdown","metadata":{"id":"WOsGqirlhibz"},"source":["#### SoftMaxを計算する\n","\n","`output = F.log_softmax(self.out(output[0]), dim=1)`としてsoftmaxを計算する\n","- logをとるのはあまり値が発散しないようにするため\n","\n","なお、Attentionには様々な拡張アプローチがあり、たとえば相対位置を使用することで長さ制限を回避するAttentionがある\n","  - 距離を比例にせずにlogにするようなイメージ"]},{"cell_type":"code","metadata":{"id":"Jmx7zVC5z21o"},"source":["class AttnDecoderRNN(nn.Module):\n","  def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","    super(AttnDecoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.dropout_p = dropout_p\n","    self.max_length = max_length\n","    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","    self.dropout = nn.Dropout(self.dropout_p)\n","    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","    self.out = nn.Linear(self.hidden_size, self.output_size)\n","  def forward(self, input, hidden, encoder_outputs):\n","    embedded = self.embedding(input).view(1, 1, -1)\n","    embedded = self.dropout(embedded)\n","    attn_weights = F.softmax(\n","      self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","    attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","      encoder_outputs.unsqueeze(0))\n","    output = torch.cat((embedded[0], attn_applied[0]), 1)\n","    output = self.attn_combine(output).unsqueeze(0)\n","    output = F.relu(output)\n","    output, hidden = self.gru(output, hidden)\n","    output = F.log_softmax(self.out(output[0]), dim=1)\n","    return output, hidden, attn_weights\n","  def initHidden(self):\n","    return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJxBewYaz21p"},"source":["## 訓練(Training)"]},{"cell_type":"markdown","metadata":{"id":"eL0NTDYbhnZN"},"source":["### 訓練データの準備\n","\n","訓練用に、各ペアについて入力tensor(入力センテンスの単語のインデックス)とターゲットtensor(ターゲット・センテンスの単語のインデックス)を作成する\n","- 両方のシーケンスに EOS トークンを追加しておく"]},{"cell_type":"code","metadata":{"id":"6XeDYnwJz21p"},"source":["def indexesFromSentence(lang, sentence):\n","  return [lang.word2index[word] for word in sentence.split(' ')]\n","def tensorFromSentence(lang, sentence):\n","  indexes = indexesFromSentence(lang, sentence)\n","  indexes.append(EOS_token)\n","  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","def tensorsFromPair(pair):\n","  input_tensor = tensorFromSentence(input_lang, pair[0])\n","  target_tensor = tensorFromSentence(output_lang, pair[1])\n","  return (input_tensor, target_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XYgjDjtMz21p"},"source":["### モデルを訓練する\n","\n","入力センテンスをEncoderに入力し総ての出力と最新のhidden_state(隠れ状態)を追跡する\n","\n","Decoderはその最初の入力として <SOS> トークンが、そしてその最初の隠れ状態としてEncoderの最後の隠れ状態が与えられる"]},{"cell_type":"markdown","metadata":{"id":"VFS4rtVfiSQj"},"source":["### Teacher forcing\n","\n","ここでさらに新しい概念に触れる\n","\n","まず、先にも述べた次の構成が考えられる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/attention_tensor_dance.gif\" width=800>\n","\n","これは書き換えれば、次のようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/teacherforcing1.png\" width=600>\n","\n","つまり、Encoder前の出力をそのまま次の入力として使って学習を行う\n","\n","この方法は連鎖的に誤差が大きくなり、学習が不安定になる、収束が遅いなどの問題が発生する\n","\n","そこで、次の入力としてDecoderの推測結果を利用する代わりに、実際のターゲット出力、つまり教師データをそのまま次の入力として利用する\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/teacherforcing2.png\" width=600>\n","\n","この手法をteacher forcingと呼ぶ\n","- 速く収束させることができる一方で、訓練されたネットワークが入力に引っ張られ過ぎ、学習過程や結果が不安定になる可能性がある\n","- また、teacher-forced ネットワークの出力を観察するとわかるが、汎化性能が乏しくなる\n","  - 例えば、最初の 2, 3 単語から意味を類推することはできるが、結局翻訳センテンスを作成するという目的からは離れており、翻訳という観点で適切に学習できない\n","\n","そこで、Scheduled Samplingを用いる\n","- Schedule Samplingは次の図のように、ターゲット$y_t$を入力とするか、生成された$w_t$を入力とするか確率的にサンプルする手法\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/scheduled-sampling.png\" width=600>\n"," \n","- PyTorch autogradは設計自由度が高く、単純な if ステートメントで \"teacher forcing\" を使用するか否かをランダムに選択することができる\n","  - teacher_forcing_ratioで利用割合を調整でき、現状50%としている"]},{"cell_type":"markdown","metadata":{"id":"Fy3ImuuHRSIL"},"source":["目新しい命令`torch.topk`が含まれている\n","- テンソルの与えられた次元(dim)にある値全ての中から大きい順にk個の値を返す\n","- topk(1)は、単純に最も大きい値を返すことになる\n","- torch.max()でも代用できるが、大値とその位置を示すインデックス（=argmax）がタプルで戻るため、[0]などをつける必要がある"]},{"cell_type":"code","metadata":{"id":"9iX-qHe9z21q"},"source":["teacher_forcing_ratio = 0.5\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","  # 初期化\n","  encoder_hidden = encoder.initHidden()\n","  encoder_optimizer.zero_grad()\n","  decoder_optimizer.zero_grad()\n","  input_length = input_tensor.size(0)\n","  target_length = target_tensor.size(0)\n","  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","  loss = 0\n","\n","  for ei in range(input_length):\n","    encoder_output, encoder_hidden = encoder(\n","      input_tensor[ei], encoder_hidden)\n","    encoder_outputs[ei] = encoder_output[0, 0]\n","  decoder_input = torch.tensor([[SOS_token]], device=device)\n","  decoder_hidden = encoder_hidden\n","  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","  if use_teacher_forcing: # Teacher forcing: ターゲットを次の入力に入れる\n","    for di in range(target_length):\n","      decoder_output, decoder_hidden, decoder_attention = decoder(\n","        decoder_input, decoder_hidden, encoder_outputs)\n","      loss += criterion(decoder_output, target_tensor[di])\n","      decoder_input = target_tensor[di]  # Teacher forcing\n","  else: # teacher forcingなし: 自身の予測値を次の入力に入れる\n","    for di in range(target_length):\n","      decoder_output, decoder_hidden, decoder_attention = decoder(\n","        decoder_input, decoder_hidden, encoder_outputs)\n","      topv, topi = decoder_output.topk(1)\n","      decoder_input = topi.squeeze().detach()  # detach from history as input\n","      loss += criterion(decoder_output, target_tensor[di])\n","      if decoder_input.item() == EOS_token:\n","        break\n","  loss.backward()\n","  encoder_optimizer.step()\n","  decoder_optimizer.step()\n","  return loss.item() / target_length"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_LJSF_9ez21q"},"source":["#### 経過時間計算ルーチン\n","\n","現在時刻と進捗%が与えられたときに経過時間と残りの見積もり時間をプリントするヘルパー関数を定義する\n","- 経過時間と予定終了時間を求める小さいが強力なルーチン\n","- 引数として全エポック数と現在実行のエポック数などを与えると経過時間と終了予定時間を表示する\n","\n"]},{"cell_type":"code","metadata":{"id":"ubGRWfRlz21q"},"source":["import time\n","import math\n","def asMinutes(s):\n","  m = math.floor(s / 60)\n","  s -= m * 60\n","  return '%dm %ds' % (m, s)\n","def timeSince(since, percent):\n","  now = time.time()\n","  s = now - since\n","  es = s / (percent)\n","  rs = es - s\n","  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3FvOEu2hz21q"},"source":["#### 訓練プロセス\n","\n","- タイマーを開始\n","- 各種初期化を行う\n","- イテレータを設定\n","  - optimizer と criterion を初期化\n","  - 訓練ペアのセットを作成\n","  - を準備\n","  - 一定間隔で進捗 (サンプルの %, ここまでの時間, 見積もり時間) と平均損失を表示する\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8wFMpVLhPl6o"},"source":["## 学習(Training)\n","\n","流石に40分程度学習に必要となる\n","\n","まず初期化する"]},{"cell_type":"code","metadata":{"id":"sn8Wip2CPhKL"},"source":["hidden_size = 300 # 256\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","n_iters = 100000\n","print_every = 2000\n","plot_every=5000\n","learning_rate=0.01\n","start = time.time()\n","plot_losses = []\n","print_loss_total = 0\n","plot_loss_total = 0\n","\n","encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n","criterion = nn.NLLLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vV2HgiVBPmou"},"source":["学習を行う\n","- この部分を再度実行すると追加学習が可能である"]},{"cell_type":"code","metadata":{"id":"S_f2VzaNz21s"},"source":["for iter in range(1, n_iters + 1):\n","  training_pair = training_pairs[iter - 1]\n","  input_tensor = training_pair[0]\n","  target_tensor = training_pair[1]\n","  loss = train(input_tensor, target_tensor, encoder,\n","    decoder, encoder_optimizer, decoder_optimizer, criterion)\n","  print_loss_total += loss\n","  plot_loss_total += loss\n","  if iter % print_every == 0:\n","    print_loss_avg = print_loss_total / print_every\n","    print_loss_total = 0\n","    print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","      iter, iter / n_iters * 100, print_loss_avg))\n","  if iter % plot_every == 0:\n","    plot_loss_avg = plot_loss_total / plot_every\n","    plot_losses.append(plot_loss_avg)\n","    plot_loss_total = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2bPZdnFBz21r"},"source":["#### 結果のプロット\n","\n","訓練の間に保存した損失値の配列 plot_losses を使用する"]},{"cell_type":"code","metadata":{"id":"GS5aSFHQz21r"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import numpy as np\n","fig, ax = plt.subplots()\n","loc = ticker.MultipleLocator(base=0.2)\n","ax.yaxis.set_major_locator(loc)\n","plt.plot(plot_losses)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9j-iUtBSz21r"},"source":["## 評価(Evaluation)\n","\n","評価は殆ど訓練と同じ手順を踏む\n","\n","ターゲットとなる文章がないため、各ステップのデコーダの予測結果を自身に戻して予測する\n","- 単語を予測するたびに、その出力文字列を追加し、EOFトークンが予測された時点で終了する\n","- Decoderのattention出力について、後ほど注目度合いを見るために保存しておく"]},{"cell_type":"code","metadata":{"id":"ABGlDxWkz21r"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","  with torch.no_grad():\n","    input_tensor = tensorFromSentence(input_lang, sentence)\n","    input_length = input_tensor.size()[0]\n","    encoder_hidden = encoder.initHidden()\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    for ei in range(input_length):\n","      encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","      encoder_outputs[ei] += encoder_output[0, 0] # Encoderの出力をすべて蓄える\n","    decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","    decoder_hidden = encoder_hidden\n","    decoded_words = []\n","    decoder_attentions = torch.zeros(max_length, max_length)\n","    for di in range(max_length):\n","      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","      decoder_attentions[di] = decoder_attention.data\n","      topv, topi = decoder_output.data.topk(1)\n","      if topi.item() == EOS_token: # EOFが予測されたので終了\n","        decoded_words.append('<EOS>')\n","        break\n","      else:\n","        decoded_words.append(output_lang.index2word[topi.item()]) # 得られた文字IDから文字に変換して加える\n","      decoder_input = topi.squeeze().detach() # デコーダの出力を次の入力へ\n","  return decoded_words, decoder_attentions[:di + 1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PrQlqqToz21s"},"source":["訓練セットからランダムな文章を選び出し、これを翻訳させる\n","- 実際にデータセットにある文章であるため、フェアではない"]},{"cell_type":"code","metadata":{"id":"vFc7v_bIz21s"},"source":["def evaluateRandomly(encoder, decoder, n=10):\n","  for i in range(n):\n","    pair = random.choice(pairs)\n","    print('>', pair[0])\n","    print('=', pair[1])\n","    output_words, attentions = evaluate(encoder, decoder, pair[0])\n","    output_sentence = ' '.join(output_words)\n","    print('<', output_sentence)\n","    print('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3ouIkNgz21s"},"source":["evaluateRandomly(encoder, decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ZAqOsZuz21s"},"source":["## Attentionの可視化\n","\n","attentionの良い点の一つとして、理解しやすい注目度合いの出力を得ることができる点にある\n","- 入力シーケンスの特定のEncoder出力における重みであるため、各ステップでどこに注目するのかを見ることができる\n","- 列を入力ステップ、行を出力ステップとする行列としてattentionを見るには、単に`plt.matshow(attentions)`とすればよい\n"]},{"cell_type":"code","metadata":{"id":"upIH52ukz21s"},"source":["output_words, attentions = evaluate(encoder, decoder, \"watashi hao furo ni itsutte irunda .\")\n","plt.matshow(attentions.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpsqA1Dtz21s"},"source":["より分かりやすく表示するため、軸とラベルなどを設定する"]},{"cell_type":"code","metadata":{"id":"gVjSlTj4z21t"},"source":["def showAttention(input_sentence, output_words, attentions):\n","  # Set up figure with colorbar\n","  fig = plt.figure()\n","  ax = fig.add_subplot(111)\n","  cax = ax.matshow(attentions.numpy(), cmap='bone')\n","  fig.colorbar(cax)\n","  # Set up axes\n","  ax.set_xticklabels([''] + input_sentence.split(' ') +\n","                     ['<EOS>'], rotation=90)\n","  ax.set_yticklabels([''] + output_words)\n","  # Show label at every tick\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","  plt.show()\n","\n","\n","def evaluateAndShowAttention(input_sentence):\n","  output_words, attentions = evaluate(encoder, decoder, input_sentence)\n","  print('input =', input_sentence)\n","  print('output =', ' '.join(output_words))\n","  showAttention(input_sentence, output_words, attentions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICzsjZ3qdp0z"},"source":["evaluateAndShowAttention(\"ame ha kirai .\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Ri_E2q4cO1O"},"source":["# word2vec"]},{"cell_type":"markdown","metadata":{"id":"t8G-HllycLGP"},"source":["## word2vecとは？\n","\n","単語のEmbeddingは重要だが、ランダムなIDを与えるのはまずいのではないか？\n","- そのように感じるのはもっともである\n","- では意味が近い言葉に近いIDを与えることなどできるのだろうか？\n","\n","word2vecはそれを可能とする、初歩的な一つの方法である"]},{"cell_type":"markdown","metadata":{"id":"48hupqSqcPtc"},"source":["## どのようなモデルなのか？\n","\n","word2vecはSkip-Gramと呼ばれるNNモデルを利用する\n","- Skip-Gram は２層のニューラルネットワークであり隠れ層は一つのみ\n","- 隣接する層のユニットは全結合している\n","\n","Skip-Gram のアーキテクチャは図に示す通り\n","- ニューラルネットワークはあるタスクで学習させる\n","  - 例えば入力となる言葉に対して近い場所にある言葉を教師データとして与え、相関を学習させる\n","- 実際には学習したタスクに対してニューラルネットワークを使わない\n","- 目的は潜在空間表現を使うことにある\n","  - 潜在空間ベクトルを単語ベクトル(図の$W_{V\\times N}$)と呼び、これを単語のIDとすることを目的とする\n","\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v1.png\" width=400>"]},{"cell_type":"markdown","metadata":{"id":"z9pDSzqqccVi"},"source":["### Skip-Gram が行うタスク\n","\n","Skip-gramでは、ある単語を入力した時、その周辺にどのような単語が現れやすいかを予測するモデルを構築する\n","- 学習は教師あり学習で行い、入力としてある単語を、出力としてその周辺語を与える\n","  - これらの単語は訓練データ内に現れる単語\n","- これらの単語を与え、ネットワークにある単語に対するその周辺語の確率を学習させる\n","\n","例えば、\"I want to eat an apple everyday.\"という文章があった場合、eatに注目した場合の周辺単語は、周辺語として何単語まで考えるのかという指標であるウィンドウサイズ$C$を定めると次の単語が該当する\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v2.png\" width=400>\n","\n","周辺語の数を1つとした時の入出力のイメージは次の通り\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v3.png\" width=400>\n","\n","このネットワークの学習が進めば、近しい場所にあった単語ほど、高い値が出力されるようになるであろう\n","\n"]},{"cell_type":"markdown","metadata":{"id":"toHIXCuHc-Rv"},"source":["### One-hotベクトル表現\n","\n","では、さらに具体的に入力と出力にはどのように単語を与えるべきか？\n","- 単語はもとより可変長\n","- そもそも、単語を数字で表現するために行っているのに、数字にならないとNNに入力することすらできない\n","- その数字(ID)のとり方で学習結果に差が出ては本末転倒\n","\n","まさにその通りで、これを解決するのがOne-hotベクトル表現である\n","- 例えばあるコーパスで単語が3種類あれば、それぞれを(1, 0, 0), (0, 1, 0), (0, 0, 1)と表現する\n","- あるコーパスで単語が10万種類あれば、10万要素あり1つだけ1となるベクトルを全ての単語に充てる\n","  - そんな非現実的なと思うかもしれないが、計算機の性能はこれを可能としてしまったのだから仕方がない\n"]},{"cell_type":"markdown","metadata":{"id":"5PtkrOOJj1R-"},"source":["### word2vecにおけるSkip-Gramの利用\n","\n","10万の単語をOne-hotベクトルで表現し入力としたとき、利用するNNの隠れ層は1つで例えばここに100個の潜在空間ベクトルを与えるとすると、10万の単語を100個の要素(数字)で表現することになる\n","- つまり10万個の要素が100個に縮約されたことになる\n","単語そのものを表現させるため、\n","- Skip-Gramでは隠れ層に活性化関数を設定せず、隠れ層の出力は単なる入力語の単語ベクトルになる\n","\n","つまり、Skip-Gram では単語の重みベクトル同士の内積を計算していると見なすことができる\n","- この内積値が出力層のユニットに入力される\n","- 出力層ではSoftmaxを用いて正規化する\n","  - 確率として扱えるようにするため\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v7.png\" width=400>\n","\n","word2vecでは、ある単語とその単語に対して実際に現れる周辺語の内積が大きくなるように重みを調整するよう学習させているといえる\n"]},{"cell_type":"markdown","metadata":{"id":"fIXyI0fYtdsB"},"source":["## 実際に扱ってみよう\n","\n","word2vecは膨大なデータが必要となるため、ここでは学習済みモデルを利用する\n","- 一般に精度の良い(実用に耐えうる)word2vecモデルはwikipediaの日本語記事の全情報を学習させている\n","- 医療用語など、限定的な範囲で行う場合は、専門のコーパスを用いて学習させた方が効率も精度もよくなる\n","\n","学習済みモデルのダウンロードを行うが、これだけで相当時間がかかる"]},{"cell_type":"code","metadata":{"id":"nUEICvi0ZhTm"},"source":["# Google Driveは巨大ファイルの読み込みを拒否するので、これを解決するためPythonスクリプトでゴリ押しする！知識は力\n","import requests\n","\n","def download_file_from_google_drive(id, destination):\n","    URL = \"https://docs.google.com/uc?export=download\"\n","\n","    session = requests.Session()\n","\n","    response = session.get(URL, params = { 'id' : id }, stream = True)\n","    token = get_confirm_token(response)\n","\n","    if token:\n","        params = { 'id' : id, 'confirm' : token }\n","        response = session.get(URL, params = params, stream = True)\n","\n","    save_response_content(response, destination)    \n","\n","def get_confirm_token(response):\n","    for key, value in response.cookies.items():\n","        if key.startswith('download_warning'):\n","            return value\n","\n","    return None\n","\n","def save_response_content(response, destination):\n","    CHUNK_SIZE = 32768\n","\n","    with open(destination, \"wb\") as f:\n","        for chunk in response.iter_content(CHUNK_SIZE):\n","            if chunk: # filter out keep-alive new chunks\n","                f.write(chunk)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kESO_T_0Zn6e"},"source":["import os\n","if not os.path.exists('wikipedia-jp-model.vec.gz'):\n","  #file_id = '1-KdCOXj-JPo8GTRDo_Pe4G7bClR4QJ8D'\n","  #destination = 'wikipedia-jp-model.vec.gz'\n","  #download_file_from_google_drive(file_id, destination)\n","  !wget https://keio.box.com/shared/static/jwek6ig84jtdi5vv01l3i4nsec3r1w9i -O wikipedia-jp-model.vec.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yyza0hC0zlm5"},"source":["ファイルサイズを確認する\n","- `-rw-r--r-- 1 root root 208284461 MON DAY HH:MM wikipedia-jp-model.vec.gz` であれば成功している"]},{"cell_type":"code","metadata":{"id":"uPXpjjfjzn3c"},"source":["!ls -laF wikipedia-jp-model.vec.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x85WW_DTuQoI"},"source":["この学習済みモデルを読み込む\n","- これには、さらに時間がかかることに注意する\n","- なお、gensim v4から仕様が変更されており、gensim v3で作成された辞書の読み込みに失敗する可能性がある"]},{"cell_type":"code","metadata":{"id":"wrKqXBFrYNM-"},"source":["import gensim\n","\n","# 学習済モデルのパス\n","model_path = 'wikipedia-jp-model.vec.gz'\n","# ロードに10分くらいかかる\n","model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_o3iZAUBl91J"},"source":["登録数を表示させる\n","- このあたりの仕様もgensim version2から変更となっており、不安定になる可能性がある"]},{"cell_type":"code","metadata":{"id":"e-XmCshzl9Hr"},"source":["# 登録している単語の数\n","print(len(model.index2word)) # 2000000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QxlsQRAKmCPq"},"source":["単語ベクトルの要素数を見る\n","- 潜在空間ベクトルは1次元であるがその要素数を調べる"]},{"cell_type":"code","metadata":{"id":"mmVM4FKnZn3a"},"source":["# ひとつの単語ベクトルの次元\n","model['猫'].shape # (300,)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pO5EqujLaF8f"},"source":["### 類似語句"]},{"cell_type":"code","metadata":{"id":"Nh0z2aipZsQG"},"source":["from pprint import pprint\n","pprint(model.most_similar('猫', topn=10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CeIiZmytaElp"},"source":["### 類似度"]},{"cell_type":"code","metadata":{"id":"Ru5gnYXEZwMf"},"source":["print(model.similarity('猫', '犬'))\n","print(model.similarity('猫', '人'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgmjqO8SaCVX"},"source":["### 演算"]},{"cell_type":"code","metadata":{"id":"Dw6WWquJZyAa"},"source":["# 単語ベクトルの演算\n","new_vec = model['王様'] - model['男'] + model['女']\n","\n","# 計算したベクトルに類似した単語\n","pprint(model.similar_by_vector(new_vec))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pRV-JURH6hgW"},"source":["```\n","[('王様', 0.8442699909210205),\n"," ('眠れる', 0.49847692251205444),\n"," ('アンジェリカ', 0.49543219804763794),\n"," ('王女', 0.4931080937385559),\n"," ('女王', 0.4830546975135803),\n"," ('魔法使い', 0.4824972152709961),\n"," ('女', 0.4674217104911804),\n"," ('ラプンツェル', 0.46472886204719543),\n"," ('わがまま', 0.4578608274459839),\n"," ('Princess', 0.4573516547679901)]\n","```\n","一応上位に欲しい単語が来ているということで"]},{"cell_type":"code","metadata":{"id":"x4Xpr_pj4i2p"},"source":["model.most_similar(positive=['王様', '女'], negative=['男'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6IWbeAS76nrJ"},"source":["```\n","[('アンジェリカ', 0.4904819428920746),\n"," ('眠れる', 0.4884800910949707),\n"," ('王女', 0.47573140263557434),\n"," ('女王', 0.4754377007484436),\n"," ('魔法使い', 0.46319156885147095),\n"," ('Princess', 0.44991517066955566),\n"," ('アンジェリク', 0.4491198658943176),\n"," ('ラプンツェル', 0.4474671483039856),\n"," ('Princesse', 0.44471073150634766),\n"," ('わがまま', 0.4431554079055786)]\n"," ```\n","結果は異なるが、こちらでも同じことができる\n","- こちらの方が正しいやりかた"]},{"cell_type":"code","metadata":{"id":"hjb2w9SiZ4i3"},"source":["model.most_similar(positive=['姪', '男性'], negative=['女性'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Qc5_7Zz6w0l"},"source":["```\n","[('甥', 0.7565308809280396),\n"," ('従兄', 0.722212553024292),\n"," ('従弟', 0.7090373635292053),\n"," ('叔父', 0.7060897350311279),\n"," ('義兄', 0.7008171081542969),\n"," ('叔母', 0.6915437579154968),\n"," ('伯父', 0.6811779737472534),\n"," ('従兄弟', 0.679537832736969),\n"," ('妹', 0.6782128810882568),\n"," ('従妹', 0.677395224571228)]\n","```\n","ポピュラーな用語はうまくいきやすい"]},{"cell_type":"code","metadata":{"id":"cGsSjXkixrTs"},"source":["model.most_similar(positive=['早稲田大学', '資本'], negative=['酒'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NhHkhGSV6zuE"},"source":["```\n","[('経済学部', 0.5606974363327026),\n"," ('明治大学', 0.5386397838592529),\n"," ('中央大学', 0.5302853584289551),\n"," ('一橋大学', 0.5300091505050659),\n"," ('法政大学', 0.5128098726272583),\n"," ('慶應義塾', 0.5110232830047607),\n"," ('商学部', 0.5074077248573303),\n"," ('立教大学', 0.504696786403656),\n"," ('武蔵大学', 0.49976053833961487),\n"," ('法学部', 0.4984593689441681)]\n","```\n","狙い通り慶應が出てくる"]},{"cell_type":"code","metadata":{"id":"_xuO1FK24xgW"},"source":["model.most_similar(positive=['川', 'カラス'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BKfFWuOu616G"},"source":["```\n","[('カワガラス', 0.6054568290710449),\n"," ('支流', 0.597814679145813),\n"," ('河口', 0.5874642729759216),\n"," ('カワセミ', 0.5752502679824829),\n"," ('ソバト', 0.570602297782898),\n"," ('エレシル', 0.5686533451080322),\n"," ('河畔', 0.5675989389419556),\n"," ('川下', 0.558063805103302),\n"," ('イラティ', 0.5519154667854309),\n"," ('流域', 0.550096333026886)]\n","```\n","カワガラスが出てくる、すばらしい"]},{"cell_type":"code","metadata":{"id":"oA2s3svp42fT"},"source":["model.most_similar(positive=['斑点', 'カラス'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HwA9NPGh658P"},"source":["```\n","[('斑紋', 0.6671698093414307),\n"," ('ホシガラス', 0.6339893937110901),\n"," ('黒い', 0.6281156539916992),\n"," ('黒く', 0.6249645948410034),\n"," ('白い', 0.6217936277389526),\n"," ('ガビチョウ', 0.6172393560409546),\n"," ('ヒメシジミ', 0.6087360978126526),\n"," ('ジャノメチョウ', 0.6007215976715088),\n"," ('ヒドリガモ', 0.6006507277488708),\n"," ('アオゲラ', 0.6004684567451477)]\n"," ```\n","その通り、斑点があるカラスがホシガラス"]},{"cell_type":"code","metadata":{"id":"7pv5uzPF47m8"},"source":["model.most_similar(positive=['東京', 'イギリス'], negative=['日本'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PRb9nwKU68mY"},"source":["```\n","[('ロンドン', 0.5689326524734497),\n"," ('キングストン・アポン・テムズ', 0.5191486477851868),\n"," ('ブライトン', 0.508252739906311),\n"," ('グラスゴー', 0.5033514499664307),\n"," ('バーミンガム', 0.4930422008037567),\n"," ('キングストン', 0.49192169308662415),\n"," ('リバプール', 0.4866297245025635),\n"," ('リヴァプール', 0.48628073930740356),\n"," ('サウサンプトン', 0.48453256487846375),\n"," ('コヴェントリー', 0.4837542772293091)]\n","```\n","うんうん！"]},{"cell_type":"code","metadata":{"id":"O7GXJG1X5KmJ"},"source":["model.most_similar(positive=['東京', 'フランス'], negative=['日本'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6mQSoj9_6-Tv"},"source":["```\n","[('パリ', 0.6384395360946655),\n"," ('トゥールーズ', 0.5746783018112183),\n"," ('リヨン', 0.5595680475234985),\n"," ('トゥールコワン', 0.5443729162216187),\n"," ('マルセイユ', 0.5376759767532349),\n"," ('ブリュッセル', 0.5282273292541504),\n"," ('ストラスブール', 0.5218859314918518),\n"," ('ボルドー', 0.5210402011871338),\n"," ('エーヌ', 0.5198503732681274),\n"," ('フレンヌ', 0.5132049322128296)]\n","```\n","ですよねー"]},{"cell_type":"code","metadata":{"id":"HqEMrCKu5cu3"},"source":["model.most_similar(positive=['年寄り'], negative=['若者'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S0H2jPPo6_gl"},"source":["```\n","[('引っ込む', 0.2480604350566864),\n"," ('薬代', 0.24139989912509918),\n"," ('とおす', 0.23622915148735046),\n"," ('ねだる', 0.22946041822433472),\n"," ('こまめ', 0.2268124222755432),\n"," ('たまっ', 0.22511205077171326),\n"," ('知恵者', 0.22372162342071533),\n"," ('なにしろ', 0.22168254852294922),\n"," ('伏せっ', 0.21967372298240662),\n"," ('お節介', 0.21965301036834717)]\n"," ```\n","身につまされるものがある"]},{"cell_type":"code","metadata":{"id":"9e9QosHZ6L8d"},"source":["model.most_similar(positive=['金持ち'], negative=['財産'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ru3LDhU7EdY"},"source":["```\n","[('今時', 0.3461727797985077),\n"," ('ドジ', 0.33415573835372925),\n"," ('つまんない', 0.32548433542251587),\n"," ('気取っ', 0.3221811354160309),\n"," ('安物', 0.3214784562587738),\n"," ('からかわ', 0.31971123814582825),\n"," ('大嫌い', 0.3196238875389099),\n"," ('ちょっと', 0.3168352246284485),\n"," ('みたい', 0.304302841424942),\n"," ('女の子', 0.30388158559799194)]\n","```\n","きわどいところを攻めてくるのはさすがだ"]},{"cell_type":"markdown","metadata":{"id":"6xowrwknU962"},"source":["# まとめ\n","\n","今回は、自動翻訳の基本について扱ったが、大量の優れた学習データと、さらに多いノード数を持つ構造を利用できれば、翻訳性能を向上を果たすこともできることがわかるであろう\n","- 結局、最後はデータなのである\n","\n","応用として、例えば、最近よく見る自動レスポンスチャットのように、ある質問に対する回答を導き出すこともできる\n","- Amazon Alexaや、Goole アシスタントのようなことも、なんとなくイメージできるようになったであろう"]},{"cell_type":"markdown","metadata":{"id":"bVJVHvPAz21t"},"source":["# 課題\n","\n","次のいずれかにトライしてください\n","\n","- より多くの層、より多くの隠れユニットとし、処理時間と結果を比較する\n","  - もっともシンプルで取り組みやすい内容です\n","\n","- 次に示すような、シンプルなDecoderを用いて比較評価する\n","  - 下記に限らず、Decoderを工夫してみよう\n","```\n","# シンプルなDecoderの例\n","class DecoderRNN(nn.Module):\n","  def __init__(self, hidden_size, output_size):\n","    super(DecoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.embedding = nn.Embedding(output_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size)\n","    self.out = nn.Linear(hidden_size, output_size)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","  def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","```\n","\n","- 異なるデータセットを試す\n","  - 英語にしたいので英語は意味がなく、日本語の他、フランス語もよくありますので、それ以外の言葉で試してしましょう\n","  - できれば、その言葉が理解できて、翻訳結果についても正しくネイティブとして議論できることが望ましく、そのような観点で精度や改善などの議論も含めること\n","  - 探せば、様々な言語のデータセットがあることがわかります\n","    - ドイツ語などがおすすめです\n","\n","- 日本語の字句解析にMeCabを使う\n","  - さらに精度が上がると思います\n","  - 記事分類で利用しているので無理な課題ではないです\n","\n","- word2vecやGloVeなどの事前訓練された単語埋め込みで置き換える\n","  - もっともエグメです"]},{"cell_type":"markdown","metadata":{"id":"u9yf8rLWOyiX"},"source":["# 閑話休題・PyTorchの掛け算色々\n","\n","良い機会なので、ここにPyTorchにおけるテンソルの掛け算関数を纏めておく。なお、mutmal以外ブロードキャストされないので注意し、されないが故に種類も多いことに注意する\n","\n","- torch.dot\n","  - 1次元のベクトル同士の積を計算し、1次元×1次元専用\n","```\n","torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n","tensor(7)\n","```\n","- torch.mm\n","  - 2次元の行列同士の積を計算し、2次元×2次元専用\n","```\n","mat1 = torch.randn(2, 3)\n","mat2 = torch.randn(3, 3)\n","torch.mm(mat1, mat2)\n","tensor([[ 0.4851,  0.5037, -0.3633],\n","        [-0.0760, -3.6705,  2.4784]])\n","```\n","- torch.mv\n","  - 2次元×1次元の積を計算、2次元×1次元専用\n","```\n","mat = torch.randn(2, 3)\n","vec = torch.randn(3)\n","torch.mv(mat, vec)\n","tensor([ 1.0404, -0.6361])\n","```\n","- torch.bmm\n","  - バッチごとに2次元×2次元の行列積を計算\n","  - 従って、結果は3次元×3次元となる\n","  - 2次元x2次元のバッチにしか利用できない\n","  - 遅いという話もあるが改善されているので普通に使える\n","```\n","batch1 = torch.randn(10, 3, 4)\n","batch2 = torch.randn(10, 4, 5)\n","res = torch.bmm(batch1, batch2)\n","res.size()\n","torch.Size([10, 3, 5])\n","```\n","- torch.matmul\n","  - 一般に積を計算、掛けるテンソルと掛けられるテンソルにより様々な計算を行う万能選手、ブロードキャストも行う\n","  - 万能すぎて動作が複雑、最適化も謎\n","  - n x m次元のnとmの組み合わせで動作が色々と変化するやばい関数、説明が煩雑なので次のように纏める\n","\n","## ヤバイ torch.matmul\n","\n","テンソルの積(n x m)を計算するが、nとmの次元の違いで動作が変化する\n","- なお、普通に行列の掛け算で説明できる場合は省略する\n","\n","以下、簡単に説明する\n","- 2次元×1次元の拡張\n","```\n","t1 = torch.tensor([[1,2],[3,4]])\n","t2 = torch.tensor([[1],[2]])\n","print(t1,t2)\n","torch.matmul(t1, t2)\n","```\n","を計算しても、\n","```\n","t1 = torch.tensor([[1,2],[3,4]])\n","t2 = torch.tensor([1,2])\n","print(t1,t2)\n","torch.matmul(t1, t2)\n","```\n","を計算しても、`tensor([[ 5],[11]])`になる\n","\n","- 次元追加\n","  - 例えば\n","```\n","t1 = torch.randn(2, 3, 4)\n","t2 = torch.randn(4, 1)\n","torch.matmul(t1, t2).size()\n","```\n","は、\n","```\n","t1 = torch.randn(2, 3, 4)\n","t2 = torch.randn(1, 4, 1)\n","torch.matmul(t1, t2).size()\n","```\n","に等しく、`torch.Size([2, 3, 1])`となる\n","  - なお、3次元x2次元でなく、2次元x3次元でもよい\n","  - 4次元x3次元でも同じ\n","- 無限次元追加\n"," - 同様に、\n","```\n","t1 = torch.randn(2, 2, 2, 2, 3, 4)\n","t2 = torch.randn(4, 1)\n","torch.matmul(t1, t2).size()\n","```\n","は\n","```\n","t1 = torch.randn(2, 2, 2, 2, 3, 4)\n","t2 = torch.randn(1, 1, 1, 1, 4, 1)\n","torch.matmul(t1, t2).size()\n","```\n","に等しく、`torch.Size([2, 2, 2, 2, 3, 1])`となる\n","  - なお、先の例と同様次元が逆でも同じ\n","\n","- バッチなど行列以外の次元はブロードキャストされる\n","  - そのため、行列以外の次元はブロードキャストできなければならない\n"," - 例えばtr1が(j×1×n×m)のテンソルで、t2が(k×m×p)のテンソルである場合、返り値は(j×k×n×p)のテンソルになる\n"]},{"cell_type":"markdown","metadata":{"id":"0ESJ4O6ucB5S"},"source":["# 結び\n","\n","お疲れさまでした。以上で授業はおわりとなります\n","\n","今や、ネットサーフィンすれば、様々なリッチなAIコンテンツが楽しめるようになりましたが、それらの多くは、一台200万といったマシンを何日も費やして学習させるリッチなコンテンツです\n","\n","これと同じ環境を準備することは、企業ならともかく、個人や大学では容易ではありません\n","\n","授業自体は、Google Colaboratoryという環境のおかげもありますが、それでも、リッチなコンテンツというわけにはいかず、できるだけシンプルかつ、調べたらどこにでも出てくるありふれた内容を取り扱い、基本を学べるような構成としました\n","\n","授業のはじめに一覧として示したDLで議論される内容のおよそ半分について基本コードを示しましたが、授業の内容は、その一部でしかありません。これは例えば、例えば、物理の世界に入る人が、$F=ma$を理解した程度です\n","\n","日々発展し続ける分野でもあり、世界中で多くの人が学んでいます。その中で、皆さんはようやくPyTorchを用いたDL設計者の第一歩に立てたと思います\n","\n","一歩を踏み出した皆さんを讃えたいと思います\n","\n","とはいえ、日進月歩、とにかく新しい提案がどんどんでてきますが、これは陳腐化も速いということです\n","\n","LightGBMも、今やTabNetの登場で、目的によっては立場が危うくなっているように、新しい情報に対するアンテナもしっかり広げておくことが必要です\n","\n","みんなが興味が持つことほど、変化が激しく、厳しい世界ですが、その変化の中にいることほど面白いことはありません。\n","\n","その上で、是非改めて考えてほしいのが、様々なAIリッチコンテンツが出回るようになりましたが、それだけ、AIやDLの技術は、素晴らしいということを物がっています\n","\n","ですが、それを作るのも使うのも、人間であり皆さんであるということです\n","\n","DeepFakeなど倫理的問題も発生しています。戦争に利用されるのも時間の問題といえます\n","\n","逆に、インターネットもそうでしたが、倫理的問題に及ぶぐらいの影響力をもっている技術だから注目される、ということも事実です\n","\n","戦争まで話を進めなくとも、面白いからといっても、FakeObamaなどのDeepFakeと利用すると問題ですが、DeepAnimeやNEUTRINO(東北きりたん)として利用すると社会還元は可能です\n","\n","どの様に使うのかも含めて、学んだ皆さんが道を示す、そうあって欲しいと思います"]}]}