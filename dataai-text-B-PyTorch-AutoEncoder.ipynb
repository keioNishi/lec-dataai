{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataai-text-B-PyTorch-AutoEncoder.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_yORUFW_Pjct"},"source":["---\n",">「人生は選択の連続ですが、一番重要な選択は、あなたの心の内でおこなわれる選択です。」\\\n",">ジョセフ・マーフィー　\n","---"]},{"cell_type":"markdown","metadata":{"id":"Wpf4mKrktNxq"},"source":["# AutoEncoder\n","\n","AutoEncoderは、入力と出力からなるNNであるが、各層のノード数が、途中少なくなるように構成されている\n","\n","- 入力と出力を同じデータで学習させる、つまり、入力と出力が同じデータとなるように学習が進む\n","\n","- それは簡単にできるであろうと思うが、途中の層は**ノード数が少ない**ことに注目する\n","\n","  - この隠れ層が、入力毎とに出力する値(ウエイトではない)が持つ空間(潜在空間:Latent Space)は、学習に使ったデータを**圧縮した**情報を持つといえる\n","\n","図において、特に圧縮された特徴表現を有する隠れ層が表現する変数空間$z$を潜在変数および潜在空間と呼び、そこに至る圧縮ネットワークをエンコーダ、その後ろの展開ネットワークをデコーダと呼ぶ\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/autoencoder.jpg\" width=400>\n","\n","例えば、顔を生成することができるStyleGANは、潜在空間を操作することでいくらでも新しい顔を作ることができる\n","\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/image78.gif\" width=300>\n","\n","(話がそれますが)情報匿名化に応用しようというのが研究テーマの一つ\n","- AutoEncoderにより情報を圧縮し、**情報が圧縮された潜在空間で情報匿名化演算を行う情報匿名化層**を導入し、効率的にかつ、人間の感覚にち近い形で情報を匿名化するアイデアである\n","- 例えば、顔画像を匿名化する時に、目を隠すのは不自然であるが、潜在空間上で数学的に安全性が示された**近しい顔**に変換することで、自然な匿名化された顔画像が得られるであろう\n","- 実際にStyleGANで生成した顔画像(この画像は本人の顔から見つけた潜在空間での値の間を直線的に移動させただけ)からわかるように、人間にとって違和感なく**データの中間をとる**ことができる\n","\n","話としては、分かっていただけたかもしれないが、ここに至るには、まだまだ途中過程がある\n","\n","まず、AutoEncoderを使ってシンプルに異常検知を実装してみる\n","- AutoEncoderで学習させる\n","  - これは全て正解データとする\n","- その後、テストデータとして実際のデータを入力する\n","  - このデータには、異常も含まれている\n","\n","この学習済みモデルを利用すると、異常検知ができる可能性がある\n","\n","- 結果を用いる方針\n","  - すると、正解データは**入力と出力の対応の取れた潜在空間で表現できるはずなので**出力が入力と等しくでてくる\n","  - 一方で、異常データは、そうではないため、出力が入力とは違う形になる\n","  - さらには、画像などでは**異常個所の誤差が正常箇所よりも大きくなる、また異常の程度で誤差も大きくなる**ように表現できるのではないか？\n","- 潜在変数を用いる方針\n","  - 正解データは、**潜在変数が近しいところに集まる**と考えられる\n","  - 一方で、異常データは外れるため、その差を使って異常を発見する\n","\n","という発想である\n","\n","まずは、最初の実装として天気情報を用いて異常気象の日を特定してみよう\n"]},{"cell_type":"markdown","metadata":{"id":"HBMIAS8-ANyw"},"source":["## 時系列データの予測と異常検知\n","\n","気象庁で公開されているオープンデータを利用する\n","- 過去6年間のデータを取得\n","- そのうちの5年間のデータを利用\n","- AutoEncoderで学習し入力と出力が近くなるようにする\n","- 作成したモデルで異常値を検出\n","\n","隠れ層に全結合ネットワークを3層設けて、この学習結果を基準とし、大きく外れた値を抽出する"]},{"cell_type":"markdown","metadata":{"id":"QE2cszzKB5wB"},"source":["### 気象データの入手\n","\n","以下の手順で気象データを入手する\n","\n","- http://www.data.jma.go.jp/gmd/risk/obsdl/ にアクセスする\n","- 「地点を選ぶ」で、好きな地域を選ぶ。ここでは、神奈川県を選択するが、出身地や行ってみたい都道府県を選択すると良い\n","- 赤丸のある地域のデータが入手できる\n","  - 青丸に「日吉」があるが、残念ながらウィンドウ右の観測項目に降水量データしかない\n","  - 例えば、横浜を選択すると温度計アイコンが得られる\n","- 次に、「項目を選ぶ」で、日別値、日平均気温を選択する\n","- 「期間を選ぶ」の連続した期間で表示するを選択し、さらに、例えば、2013年1月1日から、2018年12月31日までを選択する\n","- 「CSVファイルをダウンロード」をクリックする\n","- ダウンロードしたdata.csvをいつも通り、左のフォルダアイコンを選択し、フォルダの中に入れる\n","\n","なお、上記のダウンロードしたデータをそのまま使うには、次のwgetを実行するとよい。\n"]},{"cell_type":"code","metadata":{"id":"Vp_EfG6gB471"},"source":["cuda = \"cuda:0\"\n","import os\n","if not os.path.exists('weatherdata.csv'):\n","    #!wget \"https://drive.google.com/uc?export=download&id=1Om5-a4XKohM9q9fc07GDovci93R0qf-H\" -O weatherdata.csv\n","    !wget https://keio.box.com/shared/static/8ox7nahkgs9go0tber0hfipepgogrzmv  -O weatherdata.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TKJvbXn0FNPu"},"source":["このデータは、例のようにweatherdata.csvとして保存されるが、開いてもエラーになる\n","  - これは、テーブルの形式がラベルが振られてデータが始まるという一般的な形ではないためである\n","\n","従って、データは整形するので、この時点で、読めなくても問題ない"]},{"cell_type":"code","metadata":{"id":"Dp-gdAzC_z_g"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OQITj6fBGSVh"},"source":["まずは、csvファイルをブラウザでダウンロードし、中身を確認する\n","  - すると、0行目、1行目、2行目、4行目は不要\n","  - 3行目はラベルに利用でき、5行目からデータが始まる\n","  - windows用のデータであるため、漢字コードはshift-jis\n","\n","これらの情報を基に、pandasの機能を使ってファイルを読み込む\n","- pandasのcsvロードでは、最初の行が**ラベル**、次の行以降にデータが入っていることを期待しており、これに合わせる\n","- その中に平均気温というラベルのデータを確認する\n","   - なお2191個のデータが含まれている"]},{"cell_type":"code","metadata":{"id":"drIS_a26GURB"},"source":["data = pd.read_csv(\"weatherdata.csv\", skiprows=[0, 1, 2, 4], encoding='shift-jis')\n","temp_data = data['平均気温(℃)']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zsOInrWhH4Oq"},"source":["このデータを訓練用と、テスト用に分割するが、年境界でさだめるのがよい\n","- 最後の1年分をテストデータとするため、その境界を探す\n","  - 単純におおよそ、365*5あたりを見ると良いので、data[1820:1830]とでもしてデータを確認する"]},{"cell_type":"code","metadata":{"id":"EYW-GKJ_HeLh"},"source":["data[1820:1830]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5m2N9xsHH6NF"},"source":["すると、1826行目から新しい年が始まるとわかる\n","  - ここを境界としてtrain_xとtest_xを分ける\n","  - **1825までを選ぶ場合は、1足して1826であることに注意**する\n","  - また、NumPy形式に変換しておく\n","  - 5年と1年の日数のデータ数があることがわかる"]},{"cell_type":"code","metadata":{"id":"Oln8Y1iTHpSp"},"source":["train_x = np.array(temp_data[:1826])\n","test_x = np.array(temp_data[1826:])\n","print(len(train_x), len(test_x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ktx9XdmSJmOy"},"source":["### データの作成\n","\n","windows_size = 180としてデータ幅を180個とする\n","- また、トレーニング用の180日分のデータが複数入るリストを宣言する"]},{"cell_type":"code","metadata":{"id":"FTfeykthJj7W"},"source":["window_size = 180\n","tmp = []\n","train_X = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6y_FT7QGKEXx"},"source":["順番にwindow_size分切り出してtmpに足していく。ここでは、for分を使って順に切り出して、appendでtmpに新しい配列要素として加えている。\n","\n","最後に、train_Xにtmpをnumpyの配列で保存する。"]},{"cell_type":"code","metadata":{"id":"iz4PH0ZuKFCN"},"source":["for i in range(0, len(train_x) - window_size):\n","  tmp.append(train_x[i:i+window_size])\n","train_X = np.array(tmp)\n","pd.DataFrame(train_X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dX6bRTgSLLD7"},"source":["RNNの時と同様であるが、100日づつ切り出し、それぞれ1日ずれたデータとした\n","\n","ここから、ランダムにサンプリングして、トレーニング用のデータセットとする"]},{"cell_type":"markdown","metadata":{"id":"AiHc4LbaVO5L"},"source":["### モデルの定義\n","\n","データ幅が180日分であるので、入力は180、そこから128ノードを持つ隠れ層fc1、さらに64ノードを持つ隠れ層fc2、さらに、128ノードを持つ隠れ層fc3、最後に元に戻すために180ノードをもつ出力層fc4を構成する\n","- つまり、途中64ノードまで次元が削減されている\n","- 圧縮としては大きすぎだが、あくまでも例である\n","- xからfc1、fc2までの演算がEncoder、fc2からfc3、fc4までの演算がDecoderである\n","  - fcは全結合層であり、PyTorchにおけるLinearである"]},{"cell_type":"code","metadata":{"id":"ZTqwgbahVQkF"},"source":["class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.fc1 = nn.Linear(180, 128)\n","    self.fc2 = nn.Linear(128, 64)\n","    self.fc3 = nn.Linear(64, 128)\n","    self.fc4 = nn.Linear(128, 180)\n","    \n","  def forward(self, x):\n","    x = F.relu(self.fc1(x))\n","    x = self.fc2(x)\n","    x = F.relu(self.fc3(x))\n","    x = self.fc4(x)\n","    return x\n","model = Net()\n","model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4L4BaZ6TWk9V"},"source":["### 訓練\n","\n","損失関数(criterion)と最適化手法(Optimizer)を指定する\n","\n","また、今回は、学習データから100個ランダムにデータを取得して学習するという処理を1000回繰り返す\n","\n","- ランダムにデータを取り出す(1)\n","- 取り出したデータをinput_x配列に加える(2)\n","- numpyのarrayから、さらにPyTorchのテンソルに変換する (3)\n","- Optimizerの初期化を行う (4)\n","  - 最初に勾配を0にする\n","- input_xから、出力outputを計算する (5)\n","- 誤差をoutput(出力)と、入力(input_x)の差から求める (6)\n","- lossを後方伝搬させる (7)\n","- パラメタを更新する (8)\n","- 試行1回あたりのロスを累積してエポック全体のロスを求める (9)\n","- 100回に1回total_lossを表示する (10)\n","\n"]},{"cell_type":"code","metadata":{"id":"0vun8t6zbtS7"},"source":["criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","for epoch in range(4000):\n","  total_loss = 0\n","  input_x = []\n","  \n","  for i in range(100):\n","    index = np.random.randint(0, len(train_X)) #(1)\n","    input_x.append(train_X[index]) #(2)\n","  input_x = torch.tensor(np.array(input_x, dtype=\"float32\")) #(3)\n","  optimizer.zero_grad() #(4)\n","  output = model(input_x) #(5)\n","  loss = criterion(output, input_x) #(6)\n","  loss.backward() #(7)\n","  optimizer.step() #(8)\n","  total_loss += loss.item() #(9)\n","  if (epoch+1) % 200 == 0: #(10)\n","    print(epoch+1, total_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKk-nQpfc4-l"},"source":["学習率を調整して、このロスの値が小さくなるようにする。"]},{"cell_type":"markdown","metadata":{"id":"L7rneMjKpV9Z"},"source":["### 結果表示\n","\n","トレーニングに使った入力値と出力値をグラフで比較する。\n","\n","- 入力データを表示する。numpyの配列に変換しておく。\n","- 出力データを表示する。"]},{"cell_type":"code","metadata":{"id":"08wi0ZnGo8yy"},"source":["plt.plot(input_x.data[0].numpy(), label='input')\n","plt.plot(output.data[0].numpy(), label='output')\n","plt.legend(loc=\"upper left\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8pDAqysdqWPN"},"source":["### 異常値検出\n","\n","テストデータを用いてoutputを求め比較する"]},{"cell_type":"code","metadata":{"id":"DUbBulSzpLWG"},"source":["input_x = []\n","test_X = []\n","input_x.append(test_x[0:180])\n","input_x.append(test_x[180:360])\n","test_X = np.array(input_x, dtype=\"float32\")\n","input_test = torch.tensor(test_X, requires_grad = False)\n","model.eval()\n","with torch.no_grad():\n","  output = model(input_test)\n","pd.DataFrame(test_X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qmI6SFONrW4-"},"source":["plt.plot(test_X.flatten(), label=\"original\")\n","plt.plot(output.data.numpy().flatten(), label=\"predicted\")\n","plt.legend(loc=\"upper right\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aCHmftJksa-E"},"source":["予測値を求めて、二乗誤差を計算、正規化する"]},{"cell_type":"code","metadata":{"id":"i6uIufLXrnMS"},"source":["test = test_X.flatten()\n","predict = output.data.numpy().flatten()\n","total_score = []\n","for i in range(0, 360):\n","  diff = test[i] - predict[i]\n","  score = pow(diff, 2)\n","  total_score.append(score)\n","total_score = np.array(total_score)\n","max_score = np.max(total_score)\n","total_score = total_score / max_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DEmux_aVspx_"},"source":["どの程度の誤差があるかをグラフで表示する\n","  - 例えば、閾値を0.5とすると、その日は異常値であるとわかる。"]},{"cell_type":"code","metadata":{"id":"w3jPmEjysoPk"},"source":["plt.plot(total_score)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lEFZ8kQftM_C"},"source":["ここまでは、なんら従来と変わらないであろう"]},{"cell_type":"markdown","metadata":{"id":"DxVvUhXmDPaW"},"source":["# MNISTによるAutoEncoder\n","\n","このあと、CVAEと呼ばれる発展版を学ぶため、比較のため、MNISTでもAEを実装しておく\n","\n","また、潜在空間について理解を深める\n","\n","セルの実行でエラーが出た時は、ランタイムを再起動して最初からやり直す必要があるかもしれないので注意すること\n","- リセットではない\n","- 例えばパラメタを変更する、記述を修正するなどして、再度試す場合は注意すること"]},{"cell_type":"markdown","metadata":{"id":"UU7t_eROHTRd"},"source":["今回はfrom importを多く用いて、記述性を挙げている\n","- コード記述上は、こちらの方が短く済む\n","- 但し、一度しか使わない内容について用いるのは考えるべきところ"]},{"cell_type":"code","metadata":{"id":"pXG0MaY-tdw4"},"source":["import os\n","import numpy as np\n","import torch\n","import torchvision\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","from torchvision.utils import save_image\n","import matplotlib.pyplot as plt\n","# GPU存在のチェック\n","device = torch.device(cuda if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","#num_epochs = 100\n","num_epochs = 20\n","batch_size = 128\n","learning_rate = 0.001\n","if not os.path.exists('mydata'):\n","  os.mkdir('mydata')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI3iEvxBtgMB"},"source":["データ変換関数で正規化を行う\n","- MNISTはToTensor()により[0, 1]の値として得られる\n","  - コメントアウトしているが、外すことで[-1, 1]の範囲に変換する\n","  - コメントアウトを外す場合、`def to_img(x):`についてもコメントを外して[0, 1]の値に変換しなおす必要がある\n","    - コメントアウトを忘れると画像が白飛びする\n","  - 変換しなくても学習は進み、その方がロスは小さくなる傾向にある"]},{"cell_type":"code","metadata":{"id":"Mjlgf3UBtg4J"},"source":["img_transform = transforms.Compose([\n","  transforms.ToTensor(),\n","#  transforms.Normalize((0.5), (0.5))\n","])\n","train_dataset = MNIST('mydata', download=True, transform=img_transform)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOHj4mg2tiQ5"},"source":["AutoEncoderモデルを定義する\n","- 内部空間$z$を利用するため、Encoder と Decoder を独立して定義し、後でDecoderのみ利用できるようにする\n","- EncoderとDecoderで$w$や$b$などのパラメータは独立させて個別に学習させる\n","\n","EncoderとDecoderは完全に対象な形としている\n","- これが必須というわけではないが、AutoEncoderの思想では対象が望ましいであろう\n","\n","全結合網で784次元から $\\rightarrow$ 128 $\\rightarrow$ 64 $\\rightarrow$ 12 $\\rightarrow$ 2次元まで圧縮している\n","- 2次元では平面上に描画できるため視覚化しやすい\n","- Decoderは対称に構築している\n","\n","最終段はいろいろ選んで遊んでみると良いであろう\n","- `transforms.Normalize((0.5), (0.5))`する場合は入力画像を[-1, 1]に標準化していることから、出力の範囲が [-1, 1]である活性化関数tanhを利用する\n","  - とはいえ、実はどちらもそれほど変わらない\n","- 実はLeRU最強であり、実験では最も素早くロスが減少した\n"]},{"cell_type":"code","metadata":{"id":"ivZOH729tm-j"},"source":["class AE(nn.Module):\n","  def __init__(self):\n","    super(AE, self).__init__()\n","    self.encoder = nn.Sequential(\n","      nn.Linear(28 * 28, 128),\n","      nn.ReLU(True),\n","      nn.Linear(128, 64),\n","      nn.ReLU(True),\n","      nn.Linear(64, 12),\n","      nn.ReLU(True),\n","      nn.Linear(12, 2))\n","    self.decoder = nn.Sequential(\n","      nn.Linear(2, 12),\n","      nn.ReLU(True),\n","      nn.Linear(12, 64),\n","      nn.ReLU(True),\n","      nn.Linear(64, 128),\n","      nn.ReLU(True),\n","      nn.Linear(128, 28 * 28),\n","#      nn.Tanh() # (*)\n","#      nn.Sigmoid() # (*)\n","      nn.ReLU(True) # (*)\n","    )\n","  def forward(self, x):\n","    x = self.encoder(x)\n","    x = self.decoder(x)\n","    return x\n","model = AE().to(device)\n","model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvlFSvzEtpQ_"},"source":["変換したテンソルを元の画像[0,1]に戻す関数を定義する\n","- `#  transforms.Normalize((0.5), (0.5))`と対であり、正規化しない場合は`(*)`の行をコメントアウトする"]},{"cell_type":"code","metadata":{"id":"lQr6rev_tqlX"},"source":["def to_img(x):\n","#  x = 0.5 * (x + 1) # (*)\n","#  x = x.clamp(0, 1) # (*)\n","  x = x.view(x.size(0), 1, 28, 28)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uBjDkApstq7k"},"source":["訓練ループで定期的に生成画像を出力している\n","- 現在エポック数は20であるが、過学習にはならず、じわじわと減少していく\n","  - 時間に余裕があるならば、思い切って200などにするとよいであろう\n","- 損失関数は入力と出力の間の平均二乗誤差としている\n","  - 画像として出力と入力の画素値が一致するように学習がすすむ\n","最後に、学習したネットワークをモデルとして保存している\n","- 工夫として最もロスが小さかったモデルのみ覚えるという技も使える\n","  - ロスを求めて、ロスの最小値を管理し、それよりも小さい場合のみ保存するという手法\n","  - さらに、GPU用とCPU用を保存している\n","  - 推奨として、GPU用モデルはGPUで利用し、CPUで利用する場合はCPU用に変更して保存したほうがよい\n","    - ここでは、両方保存している\n","    - CPUが選択されるとGPUもCPUモデルが保存される\n","- 特に保存する必要はないが、こういうこともできるということで"]},{"cell_type":"code","metadata":{"id":"xRbcqmvettve"},"source":["criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(),\n","    lr=learning_rate, weight_decay=1e-5)\n","loss_list = []\n","model.train()\n","for epoch in range(num_epochs):\n","  for data in train_loader:\n","    img = data[0]\n","    x = img.view(img.size(0), -1).to(device)\n","    xhat = model(x)\n","    # 出力画像（再構成画像）と入力画像の間でlossを計算\n","    loss = criterion(xhat, x)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    # logging\n","    loss_list.append(loss.data.item())\n","  print('epoch [{}/{}], loss: {:.4f}'.format(\n","    epoch + 1, num_epochs, loss.data.item()))\n","    # 10エポックごとに再構成された画像（xhat）を描画する\n","  if epoch % 5 == 0:\n","    pic = to_img(xhat.cpu().data)\n","    save_image(pic, 'mydata/image_{}.png'.format(epoch))\n","\n","np.save('mydata/loss_list.npy', np.array(loss_list))\n","torch.save(model.state_dict(), 'mydata/autoencodergpu.pth')\n","torch.save(model.to('cpu').state_dict(), 'mydata/autoencodercpu.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aWtEAS92tuiL"},"source":["実験結果としてまずは学習曲線を示す\n","- 細かいことだが、横軸はiterationである\n","- エポック毎に表示する場合はepoch、ミニバッチである場合はiterationとする"]},{"cell_type":"code","metadata":{"id":"vRHbfECQtxJL"},"source":["loss_list = np.load('{}/loss_list.npy'.format('mydata'))\n","plt.plot(loss_list)\n","plt.xlabel('iteration')\n","plt.ylabel('loss')\n","plt.grid()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F04at8R2twg7"},"source":["学習途中で保存した画像を確認する\n","- 学習が進むにつれ、明瞭な画像が得られていることが確認できるであろう\n","- 入力画像も保存し、対応させるようにすると興味深いであろう\n","- さらに学習を進めていくと精細さは向上するが、全体的にくっきりとした画像を得るのは困難である\n","  - 敵対的生成ネットワーク(Generative Adversarial Networks:GAN)はこの点を加速化できるが、学習の安定化が難しい\n","  - 先に示した顔画像が明瞭なのは、GANを利用しているためである"]},{"cell_type":"code","metadata":{"id":"WDkWjFint0eg"},"source":["from IPython.display import Image\n","Image('mydata/image_0.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3iLQO3Et4ZG"},"source":["Image('mydata/image_10.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTe_pQ0TVi2L"},"source":["Image('mydata/image_15.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rG93PG2Ht5sx"},"source":["潜在空間の可視化\n","\n","- model2に学習済みモデルを読み直す\n","  - 特に必要ないが、こういうこともできるということで\n","  - `(*)`ではGPUモデルを読み出すようになっているが、実行環境に応じて切り替える必要がある\n","- テストデータ10000画像をEncoderだけを用いて$z$つまり\n","潜在空間にマッピングする\n","- $z$内での各画像の分布するか可視化する\n","- モデル定義において、EncoderとDecoderを別個に定義しているため`model.encoder()`とすることでエンコーダのみ呼び出すことができる"]},{"cell_type":"code","metadata":{"id":"6De8Z9iyt70S"},"source":["test_dataset = MNIST('mydata', download=True, train=False, transform=img_transform)\n","test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False)\n","model2 = AE().to(device) # 784次元ベクトルを2次元ベクトルへ圧縮\n","model2.eval()\n","model2.load_state_dict(torch.load('mydata/autoencodergpu.pth')) # (*)\n","data = iter(test_loader).next()\n","img = data[0]\n","x = img.view(img.size(0), -1)\n","x = x.to(device)\n","with torch.no_grad():\n","  z = model2.encoder(x)\n","z = z.data.cpu().numpy()\n","z.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ou3REUQlt8y2"},"source":["zは (10000, 2) であることがわかる\n","- つまり784次元の画像が2次元データに圧縮されている\n","\n","この概念を説明するのが多様性仮説であり、今回スイスロールを展開する関数を学習したと説明できる\n","- ただし、乱数を固定していないので、毎回異なるイメージが作成できる\n","  - するとスイスロールの展開方法・関数は乱数個、つまり無限に存在することになり、これも変な話ではないか？ということになる"]},{"cell_type":"code","metadata":{"id":"44jM8H9Xt-Rc"},"source":["import pylab\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 10))\n","plt.scatter(z[:, 0], z[:, 1], marker='.', c=data[1].numpy(), cmap=pylab.cm.jet)\n","plt.colorbar()\n","plt.grid()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Em2ddDWt_dH"},"source":["各数字のデータがクラスタになって**混ざらずに(実は一部重なってはいるが)**ばらついて分布している\n","- つまり、2次元の潜在空間上でも各数字を分離できていることを意味する\n","  \n","- 潜在空間の分布が±20程度の範囲に拡散している\n","  - これはAutoEncoderであるためで、VAEであればN(0, I)内に収まる\n","\n","さらに時間時間がかさむが、もう少しファンシーな表示を行う"]},{"cell_type":"code","metadata":{"id":"UFckEEc1TbJr"},"source":["from random import random\n","colors = [\"red\", \"green\", \"blue\", \"orange\", \"purple\", \"brown\", \"fuchsia\", \"grey\", \"olive\", \"lightblue\"]\n","plt.figure(figsize=(10,10))\n","points = z[:1000]\n","for p, l in zip(points, data[1]):\n","  plt.scatter(p[0], p[1], marker=\"${}$\".format(l), c=colors[l])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hrh7wzlfeKQx"},"source":["さて、可視化はできたが、密集する場所が存在し、密集地域での分布がわかりにくい\n","- これは、多次元を無理やり2次元に落とし込めた際に、空間の曲げ方が**密度が一定になるように次元削減する・曲げる**という制約項もなく、成り行きで次元圧縮しているためである\n","- 実際には拡大すれば分離されていることがわかる"]},{"cell_type":"markdown","metadata":{"id":"oXUmLpqqe-er"},"source":["# (参考)t-SNE\n","\n","さて、本授業の範囲外であるが、単純に次元削減したい場合は、t-SNEが利用できる\n","  - 興味がある場合は調べると良いであろう\n","  - 2次元/3次元程度に圧縮する場合は有効であるが、複雑な場合は別の方法を選択したほうがよい\n","  - MNISTはt-SNE向きである\n","- はっきり言えば、2次元3次元の可視化であればt-SNEを利用するべき\n","\n","サンプルコードを示すが、よっぽどきれいに分類できていることがわかる\n","- 似ている文字のグループが近くに存在することもわかる\n","- ただし逆変換を提供しないため、モーフィングなどの処理はできない"]},{"cell_type":"code","metadata":{"id":"mbAv5YtQlAfB"},"source":["from sklearn import random_projection\n","from sklearn.manifold import TSNE\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","\n","digits = datasets.load_digits()\n","\n","X_TSNEprojected = TSNE(n_components=2, random_state=0).fit_transform(digits.data)\n","X_Gprojected    = random_projection.GaussianRandomProjection(n_components=2).fit_transform(digits.data)\n","X_Sprojected    = random_projection.SparseRandomProjection(n_components=2).fit_transform(digits.data)\n","\n","plt.scatter(X_TSNEprojected[:,0], X_TSNEprojected[:,1], c=digits.target,alpha=0.5, cmap='rainbow')\n","plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3xnt1n-nPbN"},"source":["外れるついでに、どんどん道にそれる\n","\n","Google Colaboratoryの真のパワーを見てみよう\n","\n","まず、tensorboardXを導入する\n","- 著名な可視化ツール\n","\n","なお、現状でPyTorch1.1よりtensorboardに正式対応しており、`pip install tensorboard`でほぼ同様の操作が可能となっている\n","\n","今回は、PyTorchとの連携は行わず、単体利用であるが、本来は連携して利用することでさらに威力を発揮する\n","- 次のようにコードを記述する\n","```\n","tf_callback = TensorBoard(log_dir=\"logs\", histogram_freq=1)\n","model.fit(x_train, y_train, epochs=5, callbacks=[tf_callback])\n","model.evaluate(x_test,  y_test, verbose=2)\n","```\n","コールバック関数としてTensorboardを登録し、model.fit、model.evaluateを呼び出すことで、リアルタイムに学習を進めながらグラフ化することができるので便利\n","  - 複数の情報を纏めて表示することもできる\n","- 大規模学習の際には便利"]},{"cell_type":"code","metadata":{"id":"bBJBEogBnPI7"},"source":["!pip install tensorboardX"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PYDJ1FjMpJJj"},"source":["ログファイルの保存場所を指定する\n","- pythonの中から指定するために、SummmaryWriteを導入して指定する"]},{"cell_type":"code","metadata":{"id":"vhTlfvQ9nWbK"},"source":["from tensorboardX import SummaryWriter\n","writer1 = SummaryWriter()\n","writer2 = SummaryWriter(logdir='logs/image')\n","writer3 = SummaryWriter(comment='loss function')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4oHsNu_ipV27"},"source":["PyTorchを導入するが、あくまでもMNISTのデータをとるためと、データを食わせるため"]},{"cell_type":"code","metadata":{"id":"rzzOZP4anguO"},"source":["import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","transform = transforms.Compose([transforms.ToTensor(), \n","                                transforms.Normalize((0.5,), (0.5,))])\n","train_dataset = datasets.MNIST(root='mydata',\n","                               train=True,\n","                               transform=transform,\n","                               download=True) \n","test_dataset = datasets.MNIST(root='mydata',\n","                              train=False,\n","                              transform=transform)\n","batch_size = 1000\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)\n","mages, labels = next(iter(train_loader))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jp2Us8popc3J"},"source":["データを保存する"]},{"cell_type":"code","metadata":{"id":"7V5Ar2RQnpNa"},"source":["images, labels = next(iter(train_loader))\n","mat_img = images.view(-1, 28*28)\n","meta_labels = [str(x) for x in labels.numpy().tolist()]\n","with SummaryWriter(logdir='logs/projector') as w:\n","  w.add_embedding(mat_img, metadata=meta_labels, label_img=images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jgKDn2nRsOcJ"},"source":["さぁ、お楽しみだ\n","- PROJECTORが選択できる(出ない場合はリロードすること)\n","- T-SNEを選んで楽しもう\n","- テレビや動画でこのような画面をよく見るであろう\n","- 何も偉くないのだ\n","  - さも偉そうに見せて、お金を取ってくる、これがコンサルだ、合法詐欺師だ"]},{"cell_type":"code","metadata":{"id":"-4qN-H4Mn2Kp"},"source":["%load_ext tensorboard\n","#TensorBoard起動（表示したいログディレクトリを指定）\n","%tensorboard --logdir=logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DK0rWmLRGU_X"},"source":["# Variational Autoencoder(VAE)\n","\n","AutoEncoderが目指すところは理解できたであろう\n","\n","しかしながら、先ほどの顔のモーフィングのように**連続して移動できる**保証はどこにあるのだろうか？\n","  - 潜在空間を埋め尽くすように、各顔の特徴がマッピングされるとは限らないのではないか？\n","  - その通りで、実際にAutoEncoderは学習させてうまく生成できるが、圧縮できたという以上に使い道が実はそれほどない\n","  - 潜在空間をみても、隙間が多く、その隙間に位置する潜在空間ではどのような文字が生成されるかがわからない\n","    - そもそも文字ではなくなってしまうが\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/aefig.png\" width=300>\n","\n","この図のように、潜在空間をどのようにするか、については制御していない\n","\n","そこで、VAEは潜在変数$z$に確率分布として例えば$z∼N(0,1)$を想定し($N$は多変量ガウス分布)、$z$に無理やりノイズを入れる手法であり、結果として特徴量の連続性を維持したり、潜在変数がスパースになるのを防ぐことを狙う\n","\n","なぜそれでよいのかについて、以下説明する\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/vaefig.png\" width=300>\n","\n","VAEでは、Encoderにおいて平均ベクトル$\\mu$と分散ベクトル$\\sigma$を学習し、これらの平均ベクトル、分散ベクトルから得られる多変量ガウス分布から潜在変数$z$をサンプリングする\n","- つまり、$z∼N(\\mu,\\sigma)$とする\n","- このベクトル$z$が次元圧縮後のベクトルとなる\n","\n","このようなアイデアは常に「学習できること」が重要であり、単純にこのままのモデルでは誤差逆伝播ができない\n","- $\\mu$と$\\sigma$で得られるガウス分布から$z$をサンプリングする点で、逆伝播の演算ができなくなっている\n"]},{"cell_type":"markdown","metadata":{"id":"oHYvGZvtzsMh"},"source":["## Reparametrization Trick\n","\n","逆伝播の演算ができない問題を解決するため、実際のVAEではReparametrization Trickが用いられている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/vaetrick.png\" width=300>\n","\n","$z$をサンプリングで求めずに、\n","$z=\\mu+\\epsilon\\sigma(\\epsilon∼N(0,I))$と近似する\n","\n","実際のネットワーク構造は下記のようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/reptrik.webp\" width=300>\n","\n","$z∼N(\\mu,\\sigma)$を直接扱わず、$\\epsilon∼N(0,I)$にてノイズを発生させ、図に示すように$z=\\mu(X)+\\epsilon \\cdot \\sigma(X)$という形でつなげることで、**確率変数を避けて青い矢印を逆にたどって誤差逆伝播法を適用する**という工夫がなされている\n","  - 黒いパスは逆伝播では利用しない"]},{"cell_type":"markdown","metadata":{"id":"VocrLgV29qpR"},"source":["## Regularization Parameter\n","\n","VAEはAutoEncoderと同様に元の画像を復元するように学習させる\n","- AutoEncoderではReconstraction Error(復元誤差)を単純に用いる\n","\n","VAEではReconstraction Errorだけでなく、Regularization Parameter(正則化項)の学習も行う\n","\n","Regularization Parameterの式は$D_{KL}$をKLダイバージェンスとして次の通り\n","$$\n","RegLoss=−D_{KL}(N(\\mu,\\sigma)|N(0,I))\n","$$\n","- つまり、平均ベクトル$\\mu$と分散ベクトル$\\sigma$がなるべく原点を中心としたベクトルになるように学習させるための項が追加される\n","- この項により、VAEによって次元削減されたベクトルは、原点を中心に連続的に変化するベクトルとなる"]},{"cell_type":"markdown","metadata":{"id":"ZBHzWRgfAUog"},"source":["# Conditional Variational Auto Encoder (CVAE)\n","\n","CVAEは、VAEに対して正解ラベルも付与して学習を行う手法\n","- Encoder、Decoder両方に正解ラベルを付与して学習させている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/cvaefig.png\" width=300>\n","\n","その利点は次の通り\n","- Encoderで次元削減するとき、画像データだけでなくそのラベルを反映させることができる\n","- Decoderでデータ生成するとき、欲しいデータの状態を指定することができる\n","- 全データに正解がある必要はなく、半教師ありで次元削減ができる"]},{"cell_type":"markdown","metadata":{"id":"ZKQ8Uqn9xYwM"},"source":["## 具体的な効果\n","\n","例えば、MNISTを$z$が2次元のVAEで学習させることを考える\n","\n","- 訓練データのデータセットを入れて潜在変数を求めこれを順番に座標系にプロットする\n","- VAEの場合、訓練データのMNISTデータセットが2次元の正規分布に従う円の上に散らばるようになる\n","  - そうなるように確率分布を想定した\n","- すると**同じクラスラベルのデータが近いところに集まっている**ことが確認でき、点で見えているが、点と点の間もそれにふさわしい画像を表す$z$で埋め尽くされているであろうと考えられる\n","  - VAEは正規分布に従う乱数を学習時に取り入れることで、この乱数の乱雑性により似た形状を近くに寄せる効果を与える\n","  - 同じ画像を同じ値で表現せず、敢えて毎回散らして学習させることで、**この画像の表現範囲はこの辺り**と明確に定まらないようにして、あえてぼんやり学習させる\n","  - すると、それぞれのぼんやりの重なりが現れるようになり、連続的に推移できるようになる\n","\n","MNISTをVAEで学習させた例が次の図で、図の点は訓練データを入力した際の$z$の値のプロットを表している\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/vaemnist.png\" width=300>\n","\n","すると、先ほどの顔匿名化と同じことが起こる(というか、顔匿名化はこの技術の応用なのだが)\n","- 例えば、0から7に至る線分上の点、つまり内分点を順番に求めて、デコーダだけ使って画像を得ると、次のようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/vaemnistmove.png\" width=300>\n","\n","実際に得られる出力は次の通り\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/vaemove.gif\" width=100>\n","\n","0から滑らかに、6、2、8、9、4、7のように推移するのがわかる\n","- 4と9の間を通るので、4と9が混ざったような数字が出るのも、その通り\n","\n","さらに$z$の空間に直接格子状に点を作って次々と代入すると、マッピング図が得られ、この上の0から7へ移動させたことが明確となる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/vaemnistmap.webp\" width=500>\n","\n","マップ上で、0から1、1から2、2から3と動かしていくと、数字が滑らかに変化するような動画が得られる\n","- ストップウォッチや時計に利用すると、若干カッコいい？\n","- 芸術家でさえAIを使う時代なのだ\n"]},{"cell_type":"markdown","metadata":{"id":"9qo5KDumV0bM"},"source":["## 多様体仮説\n","\n","そもそも、なぜこういうことができるのか？を根本的に説明することは実はできていないといってよい\n","- なぜか現実世界はそういうスパースな状況に見えて、集まっているのである\n","- 宇宙の大構造のようなイメージか？\n","\n","その説明の一つが次の**多様体仮説**である\n","\n","- 多様な次元をもつデータがあるとしても、そのデータは少ない次元で表現できたとする(学習できた)\n","\n","  - このとき、意味のあるデータ、つまり訓練データにおける本質をとらえたデータは、高次元のデータの中でも局所的に固まっている\n","  - つまり、高次元で情報を見る(例えば、画像でMAEを算出する)よりも、その少ない次元での距離を測る方が類似しているものが見つかるといえる\n","- 例えば、像とハスキー犬と白柴犬の写真があったとする\n","  - 画素でMAE計算すれば、色の近い像とハスキー犬が近いと判断してしまうであろう\n","  - 潜在空間$z$でみれば、ハスキー犬と白柴犬の方が近い\n","    - 同様に動物の特徴、例えば、足の長さや耳の長さ、胴体の形などの近しいものが並んでいくであろう\n","    - そうであるならば、$z$上の距離が、本質をついた差を表現していないか？ということになる\n","\n","次の図は、多様体仮説と同じスイスロール理論について説明した図である\n","- 元の空間ではスパースで、その上での距離に意味はない\n","- ところがスイスロールのクリームの上では連続でその上で距離を測ることに意味がある、という考え方\n","- 実はカーネルトリックなども、このスイスロールの考え方に基づいており、**うまい関数を用いて**このロールを開く変換が構築できれば、距離は簡単に求まる、つまり、線形処理できる、という考え方になる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/swissroll.webp\" width=500>\n"]},{"cell_type":"markdown","metadata":{"id":"M_1L1d20t2cC"},"source":["# CVAEの実装\n","\n","先にTensorBoardを見てしまうと、ビジュアル的にCVAEはしょぼく感じるかもしれないが、気合を入れなおして張り切って学ぼう\n","\n","今回の目標は、「人の癖をくみ取ったフォントの自動生成」である"]},{"cell_type":"code","metadata":{"id":"mHZkJSZCt1zv"},"source":["import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","# ハイパーパラメータ集\n","SEED = 0\n","CLASS_SIZE = 10\n","BATCH_SIZE = 256\n","ZDIM = 16\n","NUM_EPOCHS = 50\n","# GPU存在のチェック\n","DEVICE = torch.device(cuda if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)\n","# シードの設定\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)   \n","torch.cuda.manual_seed(SEED)\n","# データセットとデータローダの準備\n","train_dataset = torchvision.datasets.MNIST(\n","  root='mydata', train=True, transform=transforms.ToTensor(), download=True,\n",")\n","train_loader = torch.utils.data.DataLoader(\n","  dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=0\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaH3lwIGuyQm"},"source":["## モデルの定義と処理記述\n","\n","- AutoEncoderでは無理やり2次元に押し込めた\n","  - さすがにそれは無理があるので、今度は16次元への圧縮\n","  - ただし、そこから\n","- $z$の部分に、mean、lnvarを計算している部分がある\n","  - これが、VAEとCVAEに共通する部分である\n","```\n","self._to_mean = nn.Linear(hidden_units, zdim)\n","self._to_lnvar = nn.Linear(hidden_units, zdim)\n","```\n","および\n","```\n","mean = self._to_mean(h)\n","lnvar = self._to_lnvar(h)\n","```\n","において、先の説明通りの結合が構成されている\n","  - 残りの結合は、外部の記述上に存在する\n","\n","入出力でCVAEならではの記述がされている\n","- `def encode(self, x, labels):`は、imageとlabelを引数とし、$\\sigma$、$\\mu$を返す\n","- `def decode(self, z, labels):`は、`z = mean + std * epsilon`とラベルを入力とし、imageとlabelを返り値としている\n","- これらがCVAEの部分である"]},{"cell_type":"code","metadata":{"id":"lSxC60ZouwVW"},"source":["class CVAE(nn.Module):\n","  def __init__(self, zdim):\n","    super().__init__()\n","    self._zdim = zdim\n","    self._in_units = 28 * 28\n","    hidden_units = 512\n","    self._encoder = nn.Sequential(\n","      nn.Linear(self._in_units + CLASS_SIZE, hidden_units),\n","      nn.ReLU(inplace=True),\n","      nn.Linear(hidden_units, hidden_units),\n","      nn.ReLU(inplace=True),\n","    )\n","    self._to_mean = nn.Linear(hidden_units, zdim)\n","    self._to_lnvar = nn.Linear(hidden_units, zdim)\n","    self._decoder = nn.Sequential(\n","      nn.Linear(zdim + CLASS_SIZE, hidden_units),\n","      nn.ReLU(inplace=True),\n","      nn.Linear(hidden_units, hidden_units),\n","      nn.ReLU(inplace=True),\n","      nn.Linear(hidden_units, self._in_units),\n","      nn.Sigmoid()\n","    )\n","  def encode(self, x, labels):\n","    in_ = torch.empty((x.shape[0], self._in_units + CLASS_SIZE), device=DEVICE)\n","    in_[:, :self._in_units] = x\n","    in_[:, self._in_units:] = labels\n","    h = self._encoder(in_)\n","    mean = self._to_mean(h)\n","    lnvar = self._to_lnvar(h)\n","    return mean, lnvar\n","  def decode(self, z, labels):\n","    in_ = torch.empty((z.shape[0], self._zdim + CLASS_SIZE), device=DEVICE)\n","    in_[:, :self._zdim] = z\n","    in_[:, self._zdim:] = labels\n","    return self._decoder(in_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ltjxto5czNnv"},"source":["PyTorchには、on-hotをワンライナーで構成する関数が準備されているので、今回はそれを利用する\n","\n","モデルの定義を行い、最適化にAdamを指定する"]},{"cell_type":"code","metadata":{"id":"aBJ1XnI5zKTM"},"source":["def to_onehot(label):\n","  return torch.eye(CLASS_SIZE, device=DEVICE, dtype=torch.float32)[label]\n","model = CVAE(ZDIM).to(DEVICE)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ch5ObPE8z0gE"},"source":["実際の処理は次の通り\n","\n","GPUに持っていける(効率の良い)関数とそうでない関数がある\n","- 乱数はもっていけないので、CPU側で計算する\n","- また、ロス計算で`mean`と`lnvar`を利用する\n","\n","ここでは、**バイナリクロスエントロピー(2値交差エントロピー)**が利用されている\n","- MSEはそのまま誤差が求まるが、ここでは、ミニバッチそれぞれの中で異なる乱数値が用いられていることから、それらを踏まえてバラバラに計算する必要がある\n","- そこで、バイナリクロスエントロピーを用いることで、テンソルで個別に計算、つまりベクトルの形で処理を進め、最後にその平均を求めている\n","- 各画素を多クラスと見做している\n","\n","VAEでのロスの計算方法にも注目する\n",">```\n","loss = (-1 * kld + bce).mean()\n","```\n","\n","と記述されている\n","- kldはRegularization Parameterに相当し、平均ベクトルμと分散ベクトルσがなるべく原点を中心としたベクトルになるように学習させるための項である\n","- bceはReconstraction Errorに相当し、画像としての再現度合いを評価する\n","\n","さて、`mean, lnvar = model.encode(x, labels)`によりZDIM(ここでは16次元)の`mean`と`lnvar`が得られる\n","- これを、`std = lnver.exp().sqrt()`として、やはり16次元の$\\sqrt{e^{x_i}}$を計算\n","- `epciron`にやはり16次元の平均0分散1の正規分布の乱数を入れる\n","- `z = mean + std * epsilon`として潜在空間$z$を求める\n","\n","CVAEの図のパスそのものが配列で構成されているイメージ"]},{"cell_type":"code","metadata":{"id":"0vDcmItNuWua"},"source":["model.train()\n","for e in range(NUM_EPOCHS):\n","  train_loss = 0\n","  for i, (images, labels) in enumerate(train_loader):\n","    labels = to_onehot(labels)\n","    x = images.view(-1, 28*28*1).to(DEVICE) # 画像を1次元へ\n","    mean, lnvar = model.encode(x, labels) # ラベルと一緒にエンコーダへ\n","    std = lnvar.exp().sqrt()\n","    epsilon = torch.randn(ZDIM, device=DEVICE) # 乱数を生成\n","    z = mean + std * epsilon # 潜在変数を変換\n","    y = model.decode(z, labels) # デコード\n","    # ロスを計算\n","    kld = 0.5 * (1 + lnvar - mean.pow(2) - lnvar.exp()).sum(axis=1)\n","    bce = F.binary_cross_entropy(y, x, reduction='none').sum(axis=1)\n","    loss = (-1 * kld + bce).mean()\n","    # Update model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    train_loss += loss.item() * x.shape[0]\n","  print(f'epoch: {e + 1} epoch_loss: {train_loss/len(train_dataset)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9HMg4lJONf15"},"source":["## CVAEを用いた実験\n","\n","CVAEの特徴として、正解ラベルも一緒に学習されているため、\n","- zとして適当なランダムの値をいれる\n","  - VAEの特徴により密に原点付近に集まるように分布している\n","- ワンホットにした文字としての数字について、$z$を乱数で与えているため、様々な数字を自動生成する\n","  - GANのGeneratorと同じ感覚\n","  - もっともらしい、(誰も書いていない)嘘の数字をいくらでも作れるようになる\n","\n","次の手順で試してみよう\n","- `getlabel=0`を修正\n","- セルを実行することで25個の数字を作成し表示させる\n","- 様々な数字の上にキャプションがある\n","  - Gen(作成した数字)[ID]であり、このIDは次で利用する"]},{"cell_type":"code","metadata":{"id":"BPMGrcJW9EKb"},"source":["getlabel = 0\n","NUM_GENERATION = 25\n","model.eval()\n","allz = []\n","fig, ax = plt.subplots(5, 5, figsize=(5,6.5))\n","for i in range(NUM_GENERATION):\n","  z = torch.randn(ZDIM, device=DEVICE).unsqueeze(dim=0)\n","  label = torch.tensor([getlabel], device=DEVICE)\n","  with torch.no_grad():\n","    y = model.decode(z, to_onehot(label))\n","  y = y.reshape(28, 28).cpu().detach().numpy()\n","  # Save image\n","  ly = int(i/5)\n","  lx = i%5\n","  ax[ly, lx].imshow(y, cmap='gray')\n","  ax[ly, lx].set_title(f'G({label.cpu().detach().numpy()[0]})[{i}]')\n","  ax[ly, lx].tick_params(\n","    labelbottom=False,\n","    labelleft=False,\n","    bottom=False,\n","    left=False,\n","  )\n","  allz.append(z)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QaxwsXa7RezR"},"source":["気になる形状の数字(フォントといってよいだろう)があれば、そのIDを調べる\n","- 細い、太い、斜め、三角、薄い、など特徴的なフォントを選ぶとわかりやすい\n","\n","このIDがどういう潜在空間を持っているかを調べる\n","- つまり、これがその書体の特徴量であり、ID、固有番号である\n","- ここでは、先に示した通り16次元のベクトルで表現されている"]},{"cell_type":"code","metadata":{"id":"2LyEldVAppXP"},"source":["z = allz[15]\n","z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IwRkvj4RxFb"},"source":["次に、`genseries`関数を定義している\n","- この関数は、潜在空間の値を用いて、その書体で他の数字を生成することができる\n","- 次のセルを実行することで、選択したIDの形を維持した他の数字が表れるであろう"]},{"cell_type":"code","metadata":{"id":"d5_5REgWp3wy"},"source":["def genseries(z):\n","  model.eval()\n","  fig, ax = plt.subplots(2, 5, figsize=(5,2.5))\n","  for label in range(CLASS_SIZE):\n","    with torch.no_grad():\n","      y = model.decode(z, to_onehot(label))\n","    y = y.reshape(28, 28).cpu().detach().numpy()\n","    # Save image\n","    ly = int(label/5)\n","    lx = label%5\n","    ax[ly, lx].imshow(y, cmap='gray')\n","    ax[ly, lx].set_title(f'Gen({label})')\n","    ax[ly, lx].tick_params(\n","      labelbottom=False,\n","      labelleft=False,\n","      bottom=False,\n","      left=False,\n","    )\n","  plt.show()\n","genseries(z)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bavnYaMtUetU"},"source":["## 手書き文字の潜在空間とそれを用いた数字生成\n","\n","さて、次に自分の手書き文字の潜在空間を調べる\n","\n","次の手順で試してみよう\n","- まず「それなりにちゃんとした書体で手書き数字を準備する」\n","  - 紙に書いて写メでもよいし、ペイントブラシなどのアプリで描いてもよい\n","  - そのデータをgifやpngで保存する(ファイル名は英語のほうが問題が少ない)\n","  - そのファイルを左のフォルダの中にドラッグする\n","  - ドラッグしたら、次のセルの中の\n"," ```\n"," my_fig = Image.open(\"mytest.jpg\")\n"," ```\n"," の部分にあるファイル名を、保存したファイル名で書き換える、**さらに**\n"," ```\n"," my_label = 1\n"," ```\n"," を**書いた数字の番号に書き換える**\n","  - セルを実行すると画面に表示される\n","\n","  - さらにその次のセルを実行すると、保存したファイルの潜在空間$z$が表示される"]},{"cell_type":"code","metadata":{"id":"Dv4lKC2NhI1X"},"source":["if not os.path.exists('mytest.jpg'):\n","  #!wget \"https://drive.google.com/uc?export=download&id=1o1xxp0AtkCyjTTLW_oyqSKVHX5lLAJuN\" -O mytest.jpg\n","  !wget https://keio.box.com/shared/static/n2sdt9rvju9b6tcsuer9wogy8770c5is -O mytest.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gh9SJowExkkZ"},"source":["from PIL import Image\n","from PIL import ImageOps\n","my_label = 1\n","from scipy.ndimage import center_of_mass\n","my_fig = Image.open(\"mytest.jpg\")\n","my_img = ImageOps.invert(my_fig.resize((28, 28)).convert(\"L\"))\n","plt.figure(figsize=(0.8, 0.8))\n","plt.tick_params(\n","  labelbottom=False,\n","  labelleft=False,\n","  bottom=False,\n"," left=False,\n",")\n","plt.imshow(my_img, cmap='gray') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vNiKtOqYPRu"},"source":["次のセルを実行すると、保存したファイルの潜在空間zが表示される"]},{"cell_type":"code","metadata":{"id":"eDJpSwW_9FnM"},"source":["my_input = torch.tensor(np.array(my_img)/256)\n","x = my_input.view(1, 28*28).to(DEVICE)\n","label = torch.tensor(np.array(my_label)).clone().to(DEVICE)\n","with torch.no_grad():\n","  mean, _ = model.encode(x, to_onehot(label))\n","z = mean\n","print(f'z = {z}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CeDUrFQhYR6L"},"source":["保存した画像ファイルの潜在空間zが表示されるということは、それをもとに他の数字も作成できるということである\n","- 先ほど作成した関数genseriesを利用して表示する"]},{"cell_type":"code","metadata":{"id":"VCxFgqpjzXyX"},"source":["genseries(z)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1RJC3f-smkBM"},"source":["# 課題B (AE)\n","\n","CVAEの「手書き文字の潜在空間とそれを用いた数字生成」に従って、自分の手書きクセ字で数字を記載、写メるなどして画像を保存し、自分のクセ字をもとにした数字文字を生成しなさい\n","\n","レポートには次の内容をそろえること\n","- 実行可能なノートブック\n","- 自分のクセ字\n","- 生成した数字の一覧(0から9まで)\n","\n","<font color='red'>皆さん個人のクセ字を用いるので、同じ潜在空間表現にはなりえません。</font>"]}]}