{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataai-text-2-ML基礎.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["szGKNZtafCjn","sBlKCx7sKssb","ow0swEcSiVhl","QGh-TD-J0Q4H","9UPP5JNGi9Ty"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5UsQpKOTSihl"},"source":["---\n","> *Epigraph*\\\n","> 申命記4章10節\\\n","> 「（中略）わたしは彼らにわたしのことばを聞かせよう。それによって彼らが地上に生きている日の間、わたしを恐れることを学び、また彼らがその子どもたちに教えることができるように。」\n","---"]},{"cell_type":"markdown","metadata":{"id":"Wpz-7nGobV_4"},"source":["# 機械学習の基礎"]},{"cell_type":"markdown","metadata":{"id":"szGKNZtafCjn"},"source":["## 機械学習とは？\n","\n","機械学習は、明示的にプログラミングを行わず計算機に学習能力を与える手法\n","\n","- コンピュータがデータから学習することで、そのデータに含まれる規則や判断基準などのパターンを抽出する関数を獲得する\n","\n","- 獲得した関数を用いて新たなデータについても予測できる\n","  - 画像認識・音声認識・文書分類・医療診断・スパムメール検知・商品推薦など幅広い分野で応用\n","  - スパムメールでは、迷惑メール(スパム)と、通常のメール(ハム)を識別するが、メールとスパムかハムかの結果や基準があれば未知のメールも識別できる\n","\n","- システムが学習のために使うデータ例のことを訓練セット(training set)と呼ぶ\n","- 個々のデータ例のことを訓練インスタンス(training instance)あるいは標本(sample)サンプルと呼ぶ"]},{"cell_type":"markdown","metadata":{"id":"sBlKCx7sKssb"},"source":["## 機械学習の特徴\n","\n","アルゴリズムを明確に与えるわけではない\n"," - 何かしらのモデルは与えるが、そのモデルにおける特徴量を自動的に調整し続けることができる\n"," - つまり、変化や多様性に対して柔軟\n","\n","従来のアプローチでは複雑になりすぎる問題や既知のアルゴリズムがわかっていない問題でも力を発揮  \n","- これが例えば音声認識や画像認識などの分野で注目されている理由\n","- スパムフイルタの場合、タスク$T$とは新しいメールにスパムのフラグを付けるかどうかを判断することで、経験$E$は訓練データ、性能指標$P$は例えば正しく分類されたメールの割合が該当\n","  - この性能指標のことを精度(accuracy)と呼び、分類のタスクでよく使われる"]},{"cell_type":"markdown","metadata":{"id":"Nj6B1oRzGqEE"},"source":["## 機械学習におけるモデル・パラメータ・入力変数・目的関数・損失関数・コスト関数\n","\n","学習によって獲得される関数（ **モデル** ）は **パラメータ** で表現され、パラメータを決めればその関数の挙動が決まる\n","\n","最も単純な例として直線の関数を考えると、傾き$a$と切点$b$の２つのパラメータで特徴づけられ、$f(x; a, b) = ax + b$と表記できる\n","\n","- ここで$x$ は関数の **入力変数** と呼び、また $；$ の後ろにパラメータを表記する\n","- なお、当然であるが1次式かどうかも含めてパラメータで表現する\n","\n","機械学習の目標は、学習データを使ってこれらのパラメータを決定すること\n","- 学習処理とは**目的関数**を最小化（または最大化）することで学習、つまり望ましい挙動をするようなパラメータを決定する処理のこと\n","\n","目的関数は、モデルの出力値が望ましい場合には小さな（または大きな）値をとり、そうでない場合は大きな（または小さな）値をとるように設計する\n","\n","例えば，学習データとして入力と出力のペアからなるデータセット\n","$D=((x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n))$\n","が与えられたとする\n","- ここで$x_{i}$は$i$番目のサンプルの入力、$y_{i}$は$i$番目のサンプルの出力を表す\n","\n","- これらの点の近くをできる限り通るような直線$f(x; a, b)=ax+b$を求めるとする\n","- このレベルでは機械学習と呼ぶかどうかは議論があるが、与えられたデータセットから最も適切と思われる直線を発見的に探すのであれば、機械学習といえる\n","\n","出力が実数値の場合、パラメータ$\\theta=(a, b)$とおいて、モデルの予測値$f(x_i;\\theta)$と正解$y_i$との二乗誤差を求め、その合計値で「外れ度合い」を評価できる\n","\n","- すなわち、次のような目的関数がよく利用される\\\n","$$L(f(x_i;\\theta), y_i)=\\sum_{i=1}^n (y_i - f(x_i;\\theta))^2$$\n","\n","- この関数を最小化することを考えるが、微分後のことを考え、\n","$$L(f(x_i;\\theta), y_i)=\\frac{1}{2}\\sum_{i=1}^n (y_i - f(x_i;\\theta))^2$$\\\n","とするのが一般的である\n","\n","- 全てのデータで予測と正解が一致する時のみ$0$となり、それ以外は外れ度合いが大きくなるほど大きな正の値をとる\n","\n","このような「外れ度合い」「間違え度合い」を測る関数を、特に **損失関数 (Loss Function)** と呼ぶ\n","\n","もちろん、損失関数は様々な形があり、方法によっても異なる\n","- 例えば、SVM(サポートベクトルマシン)では\n","$$L(f(x_i;\\theta), y_i)=max(0, 1-f(x_i;\\theta)y_i)$$\n","理論的分析や正確さ(accuracy)の定義では\n","$$L(f(x_i;\\theta), y_i)=1 ⟺ f(x_i;\\theta) \\ne y_i$$\n","などが用いられる\n","\n","また、与えられたデータセット全体に対するペナルティ(正則化)の合計値を求めるような目的関数を特に **コスト関数 (Cost Function)**と呼び、損失関数よりもより一般的な意味で用いられる\n","\n","$$MSE(\\theta)=\\frac{1}{N}\\sum^N_{i=1}(f(x_i;\\theta)−y_i)^2$$\n","や、SVMでは、マージンと誤分類数の和から\n","$$SVM(\\theta) = ||\\theta||^2+C\\sum^N_{i=1}\\xi_i$$\n","などが用いられる\n","\n","目的関数は、上記のように損失関数やコスト関数よりもさらに一般的な用語である\n","\n","- 目的関数の引数は$\\theta$であり、目的関数を最小化する最適な$\\theta$を求めることで、データセット$D$を精度良く予測する関数$f(x;\\theta)$が得られる\n","\n","目的関数の最小化問題を解くためには微分と線形代数の知識が必要となる\n","\n","以降、理解に必要な最低限の知識について述べる"]},{"cell_type":"markdown","metadata":{"id":"AKW5zhowYbPx"},"source":["### 標準偏差を利用したスケーリング\n","\n","機械学習アルゴリズムにおける前処理として頻繁にスケーリングが行われる。例えば、スケールが異なる変数 $x_{1}, x_{2}$、$x_1=(100,0.1), x_2=(1000,1)$とする\n","- ここで、縦軸と横軸のスケールが大きく異なっていることに注意する\n","\n","この２点間の距離 $d$ は、\n","\n","$$\n","\\begin{aligned}\n","d&=\\sqrt {\\left( 100-1000\\right) ^{2}+\\left( 0.1-1\\right) ^{2}}\\\\\n","&= \\sqrt {810000.81}\n","\\end{aligned}\n","$$\n","\n","距離$d$において$x_{1}$の影響量が大きく$x_{2}$ は殆ど影響を与えていない\n","\n","すると、$x_{2}$ のデータとしての意味が薄れ、考慮することが困難となる\\\n","そこで、**スケーリング**を行う\n","\n","- **最小値0**，**最大値1**にスケーリング\n","\n"," 最小値 $x_{\\min}$ と最大値 $x_{\\max}$ を求め、全データについて、\n","$$\n","\\widetilde{x} = \\dfrac{x - x_{\\min}}{x_{\\max} - x_{\\min}}\n","$$\n","を求めればスケーリングが行われる\n","  - 計算が単純であるが、外れ値の影響が大きくなる\n","\n","- **平均0**，**標準偏差1** にスケーリング\n","\n"," この方法は、**標準化（正規化）** とよばれ、全てのデータから平均を引くと平均$0$になり，標準偏差で割ると標準偏差は$1$となる\n","$$\n","\\widetilde{x}  = \\dfrac{x - \\bar{x}}{\\sigma}\n","$$\n","としてデータが変換される\n","  - 外れ値に強いスケーリングが行われる"]},{"cell_type":"markdown","metadata":{"id":"5wKz9jM-h9rY"},"source":["# データの扱い"]},{"cell_type":"markdown","metadata":{"id":"AZV6YslWzvJ2"},"source":["## データを扱う上で注意するべき点\n","\n","次の点に注意すること。\n","- データの形式は何か？\n"," - 特徴量はなにか？\n","   - どのように特徴量を抽出するのか？\n"," - 数値データ（量的）\n"," - カテゴリデータ（質的）\n","   - カテゴリデータを数値データへ変換\n","- 欠損値をどうするか？\n","  - 取捨選択・置換・補完\n","- 正規化するかどうか？\n","- 次元（特徴量の数）をどうするか？\n"," - どのように選択するのか？\n","- データの量は十分か\n"," - 最も大事な要素"]},{"cell_type":"markdown","metadata":{"id":"uFw7GaPUcS3-"},"source":["### 外れ値除去\n","\n","時間で変動するデータについて、その値が異常かどうかを判断したいとする\n","- なお、長時間観察した際のデータの平均的な値は一定で、値はランダムに変動するとする\n","- 時間的に変動する場合は、事前にその変動分を取り除く等の前処理を施しておく\n","\n","このデータに対して、外れ値である異常データを検出する手法はいくつかあるが、その一つに値の**頻度**に着目する方法がある\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/1-18.png\">\n","\n","このように変動するデータがある場合、平均で線を引き、それぞれの値における頻度を算出しヒストグラムを作成すると正規分布が現れる場合が多い\n","- 実際にデータが正規分布に従うかどうかを統計的に確認したい場合は、正規性検定などの方法がある\n","\n","正規分布に従う場合、外れ値を定義するためにデータの平均 $\\mu$ と標準偏差 $\\sigma$ を算出し、$\\mu \\pm 3\\sigma$の値に線を引けば**3σ法**と呼ばれる外れ値除去を行うことができる\n","\n","この手法は、外れ値の回数が多い場合や、外れ値が極端な値を持つ場合は、平均や標準偏差の値そのものが、その外れ値の影響を大きく受ける\n","- 結果として、外れ値をうまく除去できなくなるが、例えばデータを大きい順に並べて上位5%，下位5%を取り除くなど、事前処理を施すことで対応することができる\n","\n","このような手法は、データを知り、そのデータにあった事前処理を、必要に応じて施すセンスが必要であり、よく知られた、もしくは知っておくき手法がいくつかある一方で、自ら工夫して適切な前処理を施すことも必要となる\n","\n","これこそが、データサイエンティストが備えるべき技能といえる\n","\n","次に、このような観点でデータの扱いと学習について簡単に述べる"]},{"cell_type":"markdown","metadata":{"id":"WnPatkhohNdJ"},"source":["### 万能な特徴量は存在しない(醜いアヒルの子定理)\n","\n","醜いアヒルの子を含む $n$匹のアヒルがいるとする\n","- このとき，醜いアヒルの子と普通のアヒルの子の類似性は、任意の二匹の普通のアヒルの子の間の類似性と同じになるという定理\n","\n","おそらく、醜いアヒルの子は黒いのだから、色を特徴量にしてすぐに区別できるであろう、と考えるであろうが、それには人間の背景知識が利用されている\n","\n","$n$匹のアヒルの子を区別するためには$F=log(n)$個の二値の特徴量を使う\n","- これはトーナメントを考えればよく、一つの特徴量が集団を2分し、それぞれの集団を新しい特徴量がまた2分し、と考えることを意味する\n","\n","これらの特徴量を用いて分類しようとすると、これらの特徴量のどれに合致するかの数、つまり特徴そのものではなく、特徴に合致した数はどれも同じになり、区別できない\n","- 言い方を変えれば、醜いアヒルの子と同じように他のアヒルも独特なのだ、醜いアヒルの子と普通のアヒルの子は、他のアヒルの子とも同じくらい類似しているのだ、ということを意味している\n","\n","哲学的であるが、具体化してみると、次の通りである\n","- $a, b, c, d, e, f, g, h$の8匹のアヒルがあり、これを特徴量で区別する\n","- この時、$K=log(8)=3$となる\n","- 特徴量は、例えば羽の色の明るさかもしれないが、色情報RGBの値であったり、大きさであったり、食事量であったり、遺伝子の長さであったり、様々想定される\n","- ある特徴量$s_0$で、$[a, b, c, d]$と$[e, f, g, h]$に区別できる\n","- 別の特徴量$s_{00}$と$s_{01}$を用いるとそれぞれ2分され、$[a,b], [c, d], [e, f], [g, h]$に分類できる\n","- $s_{000}, s_{001}, s_{010}, s_{011}$を用いることで全てバラバラに分類できる\n","- ここで、利用した特徴量の数は7個であり、これは$N=2^n-1$、つまり、$7=2^3-1$となる\n","\n","ここでもう一つ仮定を加える\n","\n","例えば、$s_{00}$は、$[a, b, c, d]$を$[a, b]$と$[c, d]$を分けるが、ここに含まれない$[e, f, g, h]$に対してどのように合致するかは言及していない\n","\n","以後の説明のため、ここではどれにも合致しないつまり、$[e, f, g, h]$には含まれない特徴と仮定する\n","- 仮にそうであっても、この定理の根底には関わらない\n","\n","さて、ここでaが見にくいアヒルであったとする\n","- 醜いアヒルの子であるaを識別できた特徴量の数は、$s_0, s_{00}, s_{000}$の$ 3 $つである\n","\n","ところが、b, c, d, e, f全てについて、これらを識別できた特徴量の数は等しく$3$となることから、醜いアヒルの子を特別扱いしているが、実はすべてのアヒルについて同様に独自であるといえるであろう\n","\n","色の違いを大きな違いと考える「人間」が持つ背景知識に基づいているだけで、数論的にはそのような背景知識は意味がない\n","- 醜いアヒルの子を特徴づけるためには、その目的に適した特徴量の設計が重要であることを示している\n"]},{"cell_type":"markdown","metadata":{"id":"oP70RkVL2YSv"},"source":["# 機械学習の分類"]},{"cell_type":"markdown","metadata":{"id":"eX5rBZyZz_Xr"},"source":["## 教師あり学習と教師なし学習\n","\n","機械学習の分類には、様々あるが、最も大きな分類は教師あり学習と、教師なし学習である。まずは、この分類について抑える。"]},{"cell_type":"markdown","metadata":{"id":"ow0swEcSiVhl"},"source":["### 教師あり学習(supervised learning)\n","\n","データが入力と出力により構成される\n","\n","教師あり学習は､予測子(predictor)と呼ばれる一連の特徴量(feature)からターゲット(target)の数値を予測する回帰(regression)タスクでも使われる\n","\n","あるデータを教師データとして学習させて、未知の入力に対して「正解」と判断できる出力を得ることができる\n","\n","たとえば、ロジスティック回帰(logistic regression)は一般に分類に用いるが、特定の分類に属する確率の数値（たとえば「20％の確率でスパム｣）といった判定に利用することもできる\n","\n","次のような手法がある\n","\n"," - クラスタリング\n"," - 線形モデル\n"," - ロジスティック回帰\n"," - 判別分析\n"," - K近傍法\n"," - 決定木\n"," - サポートベクターマシン\n"," - ニューラルネットワーク\n"," - ベイズ\n"," - ランダムフォレスト等"]},{"cell_type":"markdown","metadata":{"id":"t2t2Am6S0QW6"},"source":["### 教師なし学習(unsupervised learning)\n","\n","データは入力のみで、以下のような手法がある\n","\n","- クラスタリング\n"," - k平均\n"," - 階層型クラスタ分析\n","- 頻出パタンマイニング\n","- 外れ値検出\n","- 相関ルール学習\n"," - アプリオリ\n"," \n","例えば 売上記録に対して相関ルール分析を行うと、バーベキューソースとポテトチップを買う人はステーキ肉も買っていくなどといった関連が取得できるため、これらの商品を近くに配置すると売上増が期待できる"]},{"cell_type":"markdown","metadata":{"id":"QGh-TD-J0Q4H"},"source":["#### その他\n","\n","他にも様々な機械学習手法がある。\n","\n","- 半教師\\\n","半教師あり学習とは、一部のデータのみラベルがつけられているデータを扱う場合に用いられる手法である\n","\n","- 特徴量エンジニアリング\\\n","特徴量エンジニアリングは、機械学習モデルのパフォーマンスを向上させるために、特徴量と呼ばれる追加の予測因子を構築してデータセットに追加すること\n","\n"," - Sparce Coding\n"," \n"," - 次元削減など\n"," \n"," \n","- その他、深層(Deep)、能動(Active)、逐次(sequential)、転移(transfer)、強化(rainforcement)、模倣(Imitation)、連帯(federation)、GANなど\n"," - 能動学習=全てではなく確度の少ない一部だけラベル付けする\n"," - 逐次学習=データは逐次的に与えられ、そのたびにパラメータを更新する\n"," - 転移学習=学習済みモデルの一部、一般に最後の層に限定して再学習を行うことで少ないデータで効率よく学習させる\n"," - 強化学習=試行錯誤を通じて「価値を最大化するような行動」を学習する\n"," - 連帯学習=モデル構築に必要なデータを一か所に集めて学習させるのではなく、分散された端末において学習も行い、その改善情報のみを集めることで全体の精度を高めようという試みで、特にプライバシが懸念される場合に重要視される\n","   - 最近 Swam Learning(群れ学習)なども出てきた\n"," - 敵対的生成ネットワーク(Generative Adversarial Network)=例えばフェイクを作るGeneratorと、フェイクと現物を見抜くDiscriminatorが相互に学習することで極めて現物に近いフェイクを生み出すような学習手法\n","- ハイブリッド学習\n","複数の学習結果を総合的に扱う手法\n","\n","- 強化学習\n","  - 学習システム(この分野ではエージェントagentと呼ぶ)が観察した環境に従って行動を選択して実行し、報酬(reward)もしくはペナルティ(penalty)を受ける場合もある)。エージェントは方策(policy)と呼ばれる最良の戦略を学習し、高い報酬を得るようになる。AlphaGoも強化学習に従う。ロボットの歩行などにも使われ、モデルベースの歩行手法よりも高い性能を得たためモデルベースアプローチは下火になった"]},{"cell_type":"markdown","metadata":{"id":"Val4U8xYsPzg"},"source":["## ディープラーニング(深層学習)\n"]},{"cell_type":"markdown","metadata":{"id":"brJwj9g-GVKH"},"source":["### 種類\n","- ディープニューラルネットワーク  \n","パターン認識を行うニューラルネットワーク（NN）の多層構造\n","- 畳み込みニューラルネットワーク (Convolusional: CNN)\n","画像を扱うDNNの初期層などによく利用され、高い画像認識能力を有する\n","- 再帰型ニューラルネットワーク(Recursive: RNN) \n","音声、動画データなど可変長データに対応、音声認識、動画認識、自然言語処理が得意で、LSTM、GRU、LSTNetなどが著名\n","- その他様々なモデルが存在"]},{"cell_type":"markdown","metadata":{"id":"iYpjL_b8GX-o"},"source":["### 得意なこと\n","- 画像認識、様々あるが著名なところではYoLoなど。物体認識の他、セグメンテーションと呼ばれる領域判別などがある\n","- 音声認識\n","- 自然言語処理\n","- 異常検知\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/scilearn/dlhier.png\" width=\"50%\">"]},{"cell_type":"markdown","metadata":{"id":"ZI02uDkp171h"},"source":["## バッチ学習とオンライン学習\n"]},{"cell_type":"markdown","metadata":{"id":"B0uTlWEVGcsk"},"source":["### バッチ学習\n","バッチ学習では訓練時にすべての訓練データを与える\\\n","あるまとまったデータを用いて一通りの学習を行うまとまった1プロセスをバッチと呼ぶ"]},{"cell_type":"markdown","metadata":{"id":"t65EDYpYGeo7"},"source":["### オンライン学習\n","オンライン学習ではひとつづつ、あるいはミニバッチ(mini-batch)と呼ばれる小さなグループで逐次的に訓練することで、学習が進む\\\n","データが届くたびに学習が行われることから、オンラインと呼ばれる\n","\n","バッチ学習でも時間をかけて、データを更新しつつ行えば、広義にはオンライン学習といえる\\\n","古いデータを省いて学習させるのは当然であろうし、計算が比較的すぐに終わるのであればオンラインと呼べる場合もある"]},{"cell_type":"markdown","metadata":{"id":"ApO2Iu_OvEmG"},"source":["# 機械学習の勘所"]},{"cell_type":"markdown","metadata":{"id":"9UPP5JNGi9Ty"},"source":["## 万能なアルゴリズムは存在しない(ノーフリーランチ定理)\n","\n","教師ありの機械学習モデルに対するノーフリーランチ定理は、数学者のDavid H. Wolpert氏が1996年の論文の中で次のように提示したことに始まる\n","\n","原文:\n","> We have dubbed the associated results NFL theorems because they demonstrate that if an algorithm performs well on a certain class of problems then it necessarily pays for that with degraded performance on the set of all remaining problems.\n","\n","DeepLによる機械翻訳\n","> 我々は、アルゴリズムが特定のクラスの問題で優れた性能を発揮する場合、残りのすべての問題の集合で性能が低下し、その代償を支払う必要があることを示しているので、関連する結果をNFL定理と呼んでいます。\n","\n","その他、探索／最適化のアルゴリズムに対するノーフリーランチ定理は、David H. Wolpert氏とWilliam G. Macready氏が1997年の論文で提示している\n","\n","その後多くの研究者が、様々な形でノーフリーランチ定理を証明／実証した\n","\n","つまり、全てのコスト関数（＝価値基準）を最適にするアルゴリズムは存在しないことを意味している\n","- 問題領域の知識を可能な限り使用して最適化すべきであり\n","- 目的に適したアルゴリズムの選択が重要である\n","\n","これは、第4の冬の時代を生み出すに十分な限界を見せているのではないか？という考えもある\n","- まともに解釈すれば、人間がもつ万能性は今の方法では獲得できないのだ、ということになる"]},{"cell_type":"markdown","metadata":{"id":"t5Nbw_O2jJqx"},"source":["## 分析\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dYgDzMAkGrxM"},"source":["### アルゴリズムの選択\n","ノーフリーランチ定理が示すように、アルゴリズムの選択は重要\n","- とはいえ、アルゴリズムだけが悪いのではない！\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aMIUYPRHGtao"},"source":["### ハイパーパラメータの最適化\n","\n","アルゴリズムを選んだ後も、ハイパーパラメータをどうするかは重要な問題\n","\n","- グリッドサーチ：各パラメータを変化させて最も性能のよいパラメータの組み合わせを選択\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/scilearn/gridsearch.jpg\" width=300>\n","\n","- DNNでは網の形状や学習率なども重要\n","  - 全結合ネットワークで深いネットワークを作るなど無意味なことはしない"]},{"cell_type":"markdown","metadata":{"id":"dRNRs8pjkU2G"},"source":["## 過学習\n","\n","適切にデータを前処理、適切なアルゴリズム、適切なハイパーパラメータにより誤差0、F値1になった\n","これは完璧なモデルと呼べるか？\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/scilearn/exceed.png\" width=\"70%\">\n","\n","本来求めたいのは次の関数ではないか？\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/scilearn/good.png\" width=\"45%\">\n","\n","本来求めたい結果の方がAccuracyが低くなるのが問題"]},{"cell_type":"markdown","metadata":{"id":"54AMBYJ5HSa5"},"source":["### 過学習とは？\n","- 与えられたデータに、ノイズも含めて過度に適合し、訓練誤差は小さいが、未知データに対する性能が低下した状態\n","- 未知データに対する性能（汎用性能）を定量化した汎用誤差を小さくすることが重要\n"]},{"cell_type":"markdown","metadata":{"id":"ogMdiuSnymL_"},"source":["#### 過学習とはどういう状態か\n","\n","欲しいモデルとは異なる、あるデータだけに特化したモデルが構築された状態のこと\n","\n","学習曲線、検証曲線、ロス曲線において、学習データのロスとテストデータのロスの間が開いている状態を過学習状態と呼ぶ\n","\n","- ただし、学習があまり進んでいない状態で開いている場合は、モデル構築が不十分で、未学習(アンダーフィッティング)というべき状態であり、過学習(オーバーフィッティング)とは言わない\n","\n","- 学習がある程度進んだ状態で呼ぶ\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/losscurve.png\" width=\"60%\">\n"]},{"cell_type":"markdown","metadata":{"id":"9yO__ALCHUQX"},"source":["### 対策\n","- 正則化：複雑さが増すことに対するペナルティを設ける\n","- 交差検証：データを学習用と評価用に分割  \n","例えば、データ全体をランダムにブロック(ここではAからE)に分けて、青のブロックのデータを用いて学習、赤のブロックのデータを用いて評価、この作業を繰り返す  \n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/scilearn/cross.jpg\" width=\"20%\">\n","\n","- 学習が比較的早く進むadamを用いて比較的簡単なモデルを多めのエポック学習させてみるとよい\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rOLY3fyReJZl"},"source":["## 学習曲線\n","学習曲線は、訓練データのサンプル数と予測性能の関係を示したグラフのこと\n","- 訓練データの数を変化させながら学習と検証を行い、それぞれの評価指標をサンプル数と共にプロットして得られる\n","- 理想的なモデルであれば、サンプル数を大きくしたとき、学習データに対する予測精度と評価データに対する予測精度がほぼ同じ値に漸近する\n","- その漸近される値があらかじめ設定した精度よりも高ければ、そのモデルがうまく作られていることを意味する\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/learning_curve.png\" width=300>\n","\n","- 訓練データが少ない場合は、予測モデルは訓練データそのものを表現する傾向があり、結果として予測性能は高くなるが、未知のデータに対してする予測性能は低くなることが多い\n","\n","- 訓練データが増えると、データに共通する特徴をうまく学習するようになる結果、訓練データ一つ一つへの対応はうまくいかないが、平均して性能が高くなるようなモデルが生成されることが多い\n","\n","なお、学習曲線を評価に用いるケースは稀である\n","- 上記ように学習曲線の横軸はサンプルサイズであり、実はサンプルサイズを変化させて学習させることはあまりない"]},{"cell_type":"markdown","source":["## 検証曲線・ロス曲線\n","- 訓練におけるミニバッチやサンプルを重ねていった場合の、それぞれの評価指標やロスの値をサンプル数などと共にプロットして得られるグラフのこと\n","  - 正答率といった評価指標やロス関数の出力値を時系列で表したグラフ\n","- サンプル毎の値はミニバッチなどを用いる実際の学習形態では得られないため、イテレーション、エポック毎となる\n","- 正解率は別途計算しなければならないためコストが伴うが、ロス関数の値は逆誤差伝播法で必ず求めるため、ロス関数(損失関数)の値、つまり損失曲線がしばしば用いられる\n","- 損失曲線を学習曲線と混同するケースも見られるため、注意が必要\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/haGpo.png\" width=300>\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/4-Figure2-1.png\" width=300>\n","\n","\n","広義には、学習が進むプロセスを把握できるグラフは、すべて学習曲線と呼称する\n","- 学習曲線は、予測モデルが過学習を起こしているのか、学習不足になっているのかを判断する助けになる"],"metadata":{"id":"0r-Pz1lYEEb7"}},{"cell_type":"markdown","metadata":{"id":"nxllD78llRDR"},"source":["## ハイバイアスとハイバリアンス\n"]},{"cell_type":"markdown","metadata":{"id":"eI6qHSDmHYxZ"},"source":["### ハイバイアス\n","学習例を増やしても識別率が低く、訓練データのスコアとテストデータのスコアの差が小さいとき\n","\n","**原因**：学習不足/過少学習(under training/learning)や適合不足(under fitting)の状態で、そもそも、モデルがあっていない、特徴量が少ない、特徴量の選択があっていないなど\n","\n","**対策**：モデルを変える、特徴量を増やす"]},{"cell_type":"markdown","metadata":{"id":"hllcdqWZHaqn"},"source":["### ハイバリアンス\n","学習例を増やしても訓練データのスコアとテストデータのスコアの差が大きいとき\n","\n","**原因**：過学習(over training/learning)、過剰適合/過適合(over fitting)の状態で、モデルはよさそうだが、全体を把握するに十分な学習量がなくデータが不足している場合や、特徴量が多すぎて全体が見通せていない場合など\n","\n","**対策**：データを増やす、特徴量を減らす\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/learning_curve-4.png\" width=700>\n"]},{"cell_type":"markdown","metadata":{"id":"KdT8WzcC3o5M"},"source":["## 評価手法"]},{"cell_type":"markdown","metadata":{"id":"C2OAYDJHnVLI"},"source":["### 回帰モデルの評価\n","\n","ある二つの変数の関係を表す式のうち、統計的手法で推計された式を回帰式、あるいは回帰モデルと呼ぶ\\\n","また、一方が他方をどの程度説明できるかを定量的に分析することを回帰分析という\n","\n","その手法として次のような指標が用いられる\n","\n","以下、共通して次の通りに定義する\n","\n","- データの数：$n$\n","- 真の値：$y_1,\\cdots,y_n$\n","- 予測した値：$f_1,\\cdots,f_n$"]},{"cell_type":"markdown","metadata":{"id":"glHD_b6bHq05"},"source":["#### 平均絶対誤差 (MAE:Mean Absolute Error）\n","単純に平均距離を求める指標\n","- これで十分な場合も多いが、絶対値を用いるため不連続性(微分可能性)を気にする場合もある\n","\n","$$MAE={1 \\over n} \\sum^n_{k=1}{| f_i - y_i|}$$"]},{"cell_type":"markdown","metadata":{"id":"hDmgIlJKHs4y"},"source":["#### 平均二乗誤差 (MSE:Mean Square Error)\n","最も一般的に用いられる指標\n","$$MSE={1 \\over n} \\sum^n_{k=1}{(f_i - y_i)}^2$$"]},{"cell_type":"markdown","metadata":{"id":"T3e8NFGTHuq8"},"source":["#### 平均平方二乗誤差 (RMSE:Root Mean Square Error）  \n","RMSE と MAE は、ともによく使われる誤差の指標\n","- RMS Error、RMSD（Root Mean Square Deviation）などとも呼ばれる\n","- RMSE はMAE よりも外れ値を、よりシビアにとらえる\n","  - 数学的には、RMSEとMSE共にどちらも平均距離を捉えているように見えるが、評価上は「本来の平均である必要」は特にないた、つまり少ない計算量を好む傾向がありMSEがより一般的に用いられる\n","\n","$$RMSE = \\sqrt{{1 \\over n} \\sum^n_{k=1}(f_i - y_i)^2}$$"]},{"cell_type":"markdown","metadata":{"id":"4XS968qyHw81"},"source":["### 相対誤差\n","スケールの違う複数のデータについて差を評価する場合は、絶対誤差ではなく相対誤差を用いる"]},{"cell_type":"markdown","metadata":{"id":"OWI6GDaqHy8R"},"source":["#### 平均絶対誤差率 (MAPE:Mean Absolute Percentage Error)\n","$$MAPE={100 \\over n}\\sum^n_{k=1}\\left |{f_i−y_i \\over y_i}\\right |$$\n","- 100を省略する場合がある"]},{"cell_type":"markdown","metadata":{"id":"LPTuIg1kH0YZ"},"source":["#### 平均平方二乗誤差率 (RMSPE:Root Mean Square Percentage Error)\n","$$RMSPE=\\sqrt{{100 \\over n}\\sum^n_{k=1}\\left ({f_i−y_i \\over y_i}\\right )^2}$$\n","- 100を省略する場合がある"]},{"cell_type":"markdown","metadata":{"id":"nnLTheX_dDpK"},"source":["### 精度\n",">（正解数÷データ数）および誤差率\n","\n","として求めるが、これだけで満足するのはもう終わり\n","\n","例えば、千個の製品で10個が不良品（陽性）の場合、常に陰性と判定するモデルの精度は99%である\n","- これは良いモデルといえるであろうか\n","\n","この場合、10個の不良品のうち、何%正しく不良品と判断したかが重要である\n","- 誤差率しか考えないのはもうやめよう"]},{"cell_type":"markdown","metadata":{"id":"hd697e7SnjOn"},"source":["### 混同行列 (Confusion Matrix)\n","\n","大前提(名前の様に混同しやすいが、この前提さえ覚えていれば混同しない)\n","- 予測したい事象が生じることを「陽性=Positive」、生じなかったことを「陰性=Negative」とする\n","- 予測が正解すると「真=True」、失敗すると「偽=False」\n","とする\n","\n","機械の故障を予測する場合、故障が発生することが陽性=Positiveである、すると、\n","\n","- 故障していると予測し、故障していた（真陽性=Ture Positive:TP）\n","- 故障していないと予測し、故障していなかった（真陰性=True Negative:TN）\n","- 故障していると予測したが、故障していなかった（偽陽性=False Positive:FP）\n","- 故障していないと予測したが、故障していた（偽陰性=False Negative:FN）\n","\n","文脈と順番が逆になることや、悪いこともPositiveになりえること、正解不正解、どのように予測したか、結果がどうであったかなど、複数の情報が混ざるのが混乱の原因で、とにかく大前提を抑えること\n","\n","| | | | |\n","|:-:|:-:|:-:|:-:|\n","| | | 予測値 |(モデルの予測)|\n","| | | 陽性(Positive) | 陰性(Negative) |\n","| 正解| 陽性 | 真陽性(True Positive) | 偽陰性(False Negative) |\n","|(実際のクラス)| 陰性 | 偽陽性(False Positive) | 真陰性(True Negative) |\n","\n","- 真(True)はモデルと実際が一致したことを、偽(False)は誤ったこと、つまり**予想が的中したかどうか**を表す\n","- 陽性か陰性かは**予測されたクラス**を表す\n","\n","陽性であるということは、予想を行う方を表しており、故障を検出する場合は、故障を検出することが陽性、正しく動作していることを検出する場合は、正しく動作していることが陽性である\n","\n","- **正解率・正確さ(Accuracy)**\n","\n"," 全体のデータの中で正しく分類できたTPとTNがどれだけあるかの指標で、この値が大きいほど性能が良い\n","  - **算出式**: $(TP+TN)/(TP+FP+FN+TN)$\n","\n"," 要するに、$T/全体$ という式であり、一般的な指標である\n","  - 1から減ずると、不正解率と呼ぶ\n","\n","- **精度・適合率(Precision)**\n","\n"," Positive と分類されたデータ(TP + FP)の中で実際にPositiveだったデータ(TP)数の割合\n","  - **算出式**: $TP/(TP+FP)$\n","\n"," この値が大きいほど性能が良く、間違った分類が少ないということを意味する\n","\n","- **感度(Sensitivity)・検出率・再現率(Recall)・真陽性率(True Positive Rate)**\n","\n"," 本来Positiveと推測すべき全データからどの程度正しく判定できたかを表し、値が大きいほど性能が良い\n","\n","  - **算出式**: $TP/(TP+FN)$\n","\n"," 取りこぼし無くPositive なデータを正しくPositiveと推測できたかの指標\n"," \n","  - 検出率と精度は対の関係にあり、一般的に精度を上げると検出率は下がる傾向にある点に注意する\n","\n"," <img src='http://class.west.sd.keio.ac.jp/dataai/text/pre-re.png' width=300>\n","\n","  - このバランスをみるには下記のF値を使う\n","\n","- **特異度(Specificity)・真陰性率(True Negative Rate)**\n","\n"," 取りこぼし無くNegative なデータを正しくNegativeと推測できたかの指標で、値が大きいほど性能がよい\n"," - **算出式**: $TN/(TN+FP)$\n","\n"," Negativeと推測すべき全データの内、どれほど回収できたかを表す\n","\n","- **偽陽性率(False Positive Rate)**\n","\n"," 実際にはNegative であるサンプルの内、Positiveであると判定された割合で、この値が小さいほど性能が良い\n","\n","  - **算出式**: $FP/(FP+TN)$\n","\n"," アラートしてはいけないもののうち、アラートを出してしまったものの割合でもあるため、誤報率とも呼ばれる\n","\n","- **偽陰性率(False Negative Rate)**\n","\n"," 実際にはPositive であるサンプルの内、Negativeであると判定された割合で、この値が小さいほど性能が良い\n"," - **算出式**: $FN/(FN+TP)$\n","\n","\n","- **F値**\n","\n"," 適合率と再現率の両方を組み合わせた調和平均で、再現率と適合率を一方に偏らせずに均等に評価したい場合に利用する\n","  - 値が大きいほど性能がよいといえるがその解釈は一概に言えない\n","  - **算出式**: $2×(適合率\\times再現率)/(適合率＋再現率)$\n","\n","まとめると、次のようになる\n","\n","| | | |\n","|:-:|:-:|:-:|\n","|メリット|デメリット|\n","|正解率|最もシンプルで分かりやすい|クラスごとの評価データ数が著しく異なると不適切|\n","|再現率|取りこぼしを発見できる|過検知を発見できない|\n","|適合率|過検知を発見できる|取りこぼしを発見できない|\n","|F値|取りこぼしと過検知をどちらも均等に判断できる|数値の解釈が難しくなる|\n","\n","例えば、千個の製品データ内の10個が不良品（陽性）の場合、常に陰性と判定するモデルの精度は99%、これは良いモデルか？については、次のように解釈できる\n","\n","| | | | |\n","|:-:|:-:|:-:|:-:|\n","| | | 予測値 | |\n","| | | 陽性(Positive) | 陰性(Negative) |\n","| 正解| 陽性 | 真陽性(True Positive) 0 | 偽陰性(False Negative) 10 |\n","|         | 陰性 | 偽陽性(False Positive) 0 | 真陰性(True Negative) 990 |\n","\n","つまり、精度は99%、適合率・再現率・F値は0となるため、正しく推測できていないという結果になる"]},{"cell_type":"markdown","metadata":{"id":"Ylfw7lXbIDeQ"},"source":["#### 多クラス混同行列\n","\n","故障か正常かの2値を扱ったが、物体認識などクラスが複数ある場合でも、正解・不正解を議論するのであれば、同様に各クラスについて混合行列を求めることができる\n","\n","この場合、クラスごと、つまり物体のラベル毎に、それぞれ混合行列を求めることができ、上記の指標値も各クラスごとに算出できる"]},{"cell_type":"markdown","metadata":{"id":"iBOufeKXCmm-"},"source":["### ROC(Receiver Operating Characteristic) 曲線・AUC(Area Under the Curve) \n","\n","2値分類で一般的に利用されているパフォーマンス計測のための可視化手法\n","- ROCは推測曲線と呼ばれ、縦軸にTPR(True Positive Rate)、横軸にFPR(False Positive Rate) の割合をプロットしたグラフ\n","- AUC(Area Under the Curve) はその曲線の下部分のエリアのことで、AUCの面積が大きいほど一般的に機械学習の性能が良い事を意味する\n","\n","AUCが大きいということはすなわち機械学習モデルがNegative と推測すべきものを間違えてPositive と推測している傾向が少なく、Positive と推測すべきものをしっかりとPositive と推測できていることを意味する\n","\n"," - 実際の機械学習モデルはPositiveかNegativeかの判定を0か1かの2極で行うわけではなく、例えばsoftmaxの結果など、一般的には0から1の間の値など、小数点も含む曖昧な値を用いて判断する\n","  - 手書き文字認識MNISTでも、何%で1とみなしたか？といった指標が与えられていたのを思い出してほしい\n","  - さらに、その値に閾値を与えて、より大きい場合はPositive、より小さい場合はNegativeと判断するか、比較して判断する\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8gxF76fEIMfg"},"source":["#### 機械の故障検知を例にROCを理解する\n","\n","故障の原因にはいろいろあるため、様々な特徴量を捉え、実際に故障であったかどうかのラベルを与えたデータをもとに学習を行ったと仮定する\n","- ここで、故障の予兆現象(テストデータに相当し、ここでは要素とする)に名前を付けたとする(実際にそういうことができるかどうかは想定していない)\n","\n"," また、それぞれの機械学習モデルの出力が次のようになったとする\n","- nが正常ラベル、pが異常ラベルとし、モデルの出力値で纏めてある\n","- ここでは全体で29の要素がある\n","\n","> 0.1: $y_{n1}$  \n","> 0.2: $y_{n2}, y_{n3}$  \n","> 0.3: $y_{n4}, y_{n5}, y_{n6}$  \n","> 0.4: $y_{n7}, y_{n8}, y_{n9}, y_{p16}$  \n","> 0.5: $y_{n10}, y_{n11}, y_{n12}, y_{p14}, y_{p15}$  \n","> 0.6: $y_{n13}, y_{p10}, y_{p11}, y_{p12}, y_{p13}$  \n","> 0.7: $y_{p6}, y_{p7}, y_{p8}, y_{p9}$  \n","> 0.8: $y_{p3}, y_{p4}, y_{p5}$  \n","> 0.9: $y_{p1}, y_{p2}$  \n","\n","閾値を操作した場合のTPR(再現率)とFPRをそれぞれ求めると次のようになる\n","\n","| | | |\n","|:-:|:-:|:-:|\n","| $>=$ |TPR             | FPR    |\n","|0.1 |16/(16+0)=1     |13/(13+0)=1 |\n","|0.2 |16/(16+0)=1     |12/(12+1)=0.92 |\n","|0.3 |16/(16+0)=1     |10/(10+3)=0.77 |\n","|0.4 |16/(16+1)=1     | 7/(7+6)=0.54  |\n","|0.5 |15/(15+1)=0.94  | 4/(4+9)=0.31  |\n","|0.6 |13/(13+3)=0.81  | 1/(1+12)=0.08 |\n","|0.7 | 9/(9+7)=0.56  | 0/(0+13)=0 |\n","|0.8 | 5/(5+11)=0.31  | 0/(0+13)=0 |\n","|0.9 | 2/(2+14)=0.13  | 0/(0+13)=0 |\n","\n","- 例えば0.5とすると、全ての$y_p$16個のうち$y_{p1}$から$y_{p13}$までの15個の予測に成功しているのでTPRは0.94、また、全13個の$y_n$のうち故障と判断した、つまり予測に失敗したのは$y_{n10}$以上の4個でFPRは0.31となる\n","\n","これを閾値を変えてグラフにすると、次のようになる\n","- なお、この後自動的にROC曲線を記述する方法について述べるが、ここではその計算過程を明らかにするため、敢えて計算を行っている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/roc1.png\" width=400>\n","\n","x軸の読みをFPR、y軸の読みをTPRとすることでROC曲線が取得できる\n","\n","AUCはこのグラフにおけるx軸側の面積を表し0から1の値をとる\n","- 上に大きな凸が得られているほどAUCの値が大きく、正確に識別していることが期待できる\n","\n","この例では、\n","- 図の左上に閾値0.5の点があり、TPR($y$軸の値)が0.94、FPR:($x$軸の値)が0.31である\\\n","この閾値0.5の点が図の左上に位置しているため、高TPRかつ低FPRであることを意味し故障判定がそれなりにうまくいっていることがわかる\n","- 閾値0.6では、TPRが0.81、FPR:($x$軸の値)が0.08である\\\n","FPRが下がりよくなるが、TPRも下がってしまう\\\n","但し、相対的にFPRの下げ幅の方が大きいため誤検出より減らすという意味では選択としてもあり得る\n","\n","このように閾値を変更すると、改善される一方で副作用もある\n","- ROC曲線・AUCは閾値の調整によって機械学習の性能がどのように変化するかも視覚的に理解できるため、2値分類機械学習モデルの性能を見るには有用である\n","\n","閾値の調整はアプリケーションを見据えて戦略的に行うことが重要"]},{"cell_type":"markdown","metadata":{"id":"8RoopBpyIQSx"},"source":["#### ROCの形の解釈"]},{"cell_type":"markdown","metadata":{"id":"7aypqxPMIhca"},"source":["##### $y=x$に近いROC曲線\n","\n","ROC曲線が$y=x$のグラフに近い場合、正確に判定できていないことを意味し、より具体的には故障か正常かをサイコロを振って決めているような状況となる\n","\n","機械学習としては学習失敗であり、ハイバイアスと同様の状況が想定される\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/roc2.png\" width=300>"]},{"cell_type":"markdown","metadata":{"id":"58vLmxcf9X1W"},"source":["実際にランダムデータを生成して確認する"]},{"cell_type":"code","metadata":{"id":"Bmtd6sF28egH"},"source":["import numpy as np\n","from sklearn.metrics import roc_curve\n","import matplotlib.pyplot as plt\n","np.random.seed(0)\n","y_true_random = np.array([0] * 5000 + [1] * 5000)\n","y_score_random = np.random.rand(10000)\n","roc_random = roc_curve(y_true_random, y_score_random)\n","plt.plot(roc_random[0], roc_random[1])\n","plt.xlabel('FPR: False positive rate')\n","plt.ylabel('TPR: True positive rate')\n","plt.grid()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fxzg0ycp8rte"},"source":["###### 下に凸であるROC 曲線\n","\n","PositiveクラスとNegativeクラスが逆転しているケースで、天邪鬼学習\n","\n","故障であれば正常と判定し、正常であれば故障と判定する状態であり、ラベルの入力ミスなどが疑われる\n","- 2値判定であるならば、単純に結果を反転してもよいであろう\n","\n","<img src='http://class.west.sd.keio.ac.jp/dataai/text/roc3.png' width=50%>\n"]},{"cell_type":"markdown","metadata":{"id":"qWsfgEgBIvsi"},"source":["##### あまりにも結果が良すぎるROC 曲線\n","\n","結果が良いことに越したことはないが、あまりにも結果が良い場合、次の2つを疑う必要がある\n","- テストデータの入力を誤っていないか？トレーニングデータをそのままテストデータとして入力していないか？\n","- そもそも機械学習が必要であったか？線形分離可能であったり、モデルがシンプルであったのではないか？\n","\n","<img src='http://class.west.sd.keio.ac.jp/dataai/text/roc4.png' width=50%>\n"]},{"cell_type":"markdown","metadata":{"id":"-BPy3j7mIx6M"},"source":["##### 実際のROC曲線の例\n","\n","必ず単調増加になる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/scilearn/roc.jpg\" width=\"40%\">"]},{"cell_type":"markdown","metadata":{"id":"evofhqwW923O"},"source":["なお、rocの形がよい、aucの値が大きいからと言って、必ずしも良い学習を行ったとはいえない\n","- 例えば、データが不均衡な場合は正しく判断できないため、別途F1値などを見る必要がある\n","\n","これを解決するマシューズ相関係数が提案されている\n","\n","実際に不均衡なデータを生成して確認する\n","- 5000個のデータを生成して、1が殆ど含まれないデータ、例えば5%にしたデータを生成\n","- このデータをtrainとtestに分割し、ロジスティック回帰で学習させる\n","- その結果をプロットすると、そこそこ良い結果がでている\n"]},{"cell_type":"code","metadata":{"id":"QG6vebiF-1G5"},"source":["from sklearn.datasets import make_classification\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import classification_report\n","#次の行をいろいろ触ってみて、これ以降の結果がどのように変わるか確認するとよいであろう\n","X, y = make_classification(n_samples=5000, n_classes=2, weights=[0.95,0.05], random_state=42)\n","trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=2)\n","model = LogisticRegression()\n","model.fit(trainX, trainy)\n","probs = model.predict_proba(testX)\n","probs = probs[:, 1] \n","fpr, tpr, thresholds = roc_curve(testy, probs)\n","plt.plot([0, 1], [0, 1], linestyle='--', label=\"random\")\n","plt.plot(fpr, tpr, marker='.', label=\"LR\")\n","plt.legend()\n","plt.xlabel(\"FPR\")\n","plt.ylabel(\"TPR\")\n","plt.show()\n","auc_score = roc_auc_score(testy, probs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jgDYCcPKAAxh"},"source":["ところが、classification_reportを用いて実態を見てみると"]},{"cell_type":"code","metadata":{"id":"ZsqUcEXoAFDI"},"source":["predictions = model.predict(testX)\n","print(classification_report(testy, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-gya_hfAHhP"},"source":["このように、1つまり少数であるデータのrecallやF1値は、0.17や0.25と極めて低い値になっていることがわかる"]},{"cell_type":"markdown","metadata":{"id":"JCHP6dDiAZ7N"},"source":["### マシューズ相関係数(MCC)とF1スコア\n","\n","不均衡データ(imbalanced data)について評価するには、マシューズ相関係数(Matthews Correlation Coefficient)とF1_Scoreの利用が望ましい"]},{"cell_type":"markdown","metadata":{"id":"K1Qn8xrYF9CM"},"source":["\n","#### F1スコア\n","\n","まずF1値について、より詳細に説明する\n","\n","> $2×(適合率(PRE)\\times再現率(REC))/(適合率(PRE)＋再現率(REC))$\n","\n","と記載したが、書き換えれば、\n","$F_1 = (\\frac{REC^{-1}+PRE^{-1}}{2})^{-1}$\n","である\n","\n","さらに一般化した、$F_\\beta$スコアは、\n","$$\n","F_\\beta = (1+\\beta^2)\\frac{PRE\\cdot REC}{(\\beta^2\\cdot PRE)+REC}\n","$$\n","と定義され、$\\beta$を重みとして、$PRE$と$REC$の重点度合いを制御することができる\n","- $F_1$スコアは、$F_\\beta$スコアにおいて、$\\beta = 1$の場合を表す"]},{"cell_type":"markdown","metadata":{"id":"Ew4ni7SyF-1M"},"source":["#### MCCスコア\n","\n","MCCは、真陽性(TP),偽陽性(FP),真陰性(TN),偽陰性(FN)を全て考慮し、かつ、クラスのサイズが大きく異なる場合でも使用できる分類モデルの評価指標である\n","- MCCは予測された2値分類の結果と正解の相関係数であり、予測と答えがどれだけ近いかを測る指標である\n","- 最悪-1~最善1までの値をとり、1は完璧な予測結果であったこと、0はランダムな予測結果であったこと、-1は予測結果と実際結果が完全不一致であったことを表す\n","\n","MCCは次の式で与えられる\n","\n","$$MCC=\\frac{TP\\cdot TN - FP\\cdot FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\n","\n","先ほどの不均衡データを用いて、これらの指標の値を求める"]},{"cell_type":"code","metadata":{"id":"t4HiJM-wFGjD"},"source":["from sklearn.metrics import matthews_corrcoef\n","from sklearn.metrics import f1_score\n","thresholds = np.linspace(0.1,1,num=10)\n","mcc_list = []\n","f1_list = []\n","for thr in thresholds:\n","    predict  = (probs > thr).astype(int)\n","    mcc = matthews_corrcoef(testy, predict)\n","    f1 = f1_score(testy, predict)\n","    mcc_list.append(mcc)\n","    f1_list.append(f1)   \n","plt.plot(thresholds, f1_list, linestyle='--', label=\"f1_score\")\n","plt.plot(thresholds, mcc_list, marker='.', label=\"mcc\")\n","plt.legend()\n","plt.xlabel(\"Threshold\")\n","plt.ylabel(\"Score\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6PEe0HGsGFUM"},"source":["このようにスコアが芳しくないことがわかり、モデルの評価が行えていることがわかる\n","- F1値とMCCがほぼ同じような挙動をしめし、どちらでも判定可能であることがわかる\n","\n","これらは、Positiveが少数であった場合であるが、逆にNegativeが少数であった場合、F1_scoreとMCCは異なる挙動を示す\n","- 次のように、F1値は良いモデルであるかのようなふるまいをするため、MCCで評価することが求められる"]},{"cell_type":"code","metadata":{"id":"quRsc_XoGzZ9"},"source":["X, y = make_classification(n_samples=5000, n_classes=2, weights=[0.05,0.95], random_state=42)\n","trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=2)\n","model = LogisticRegression()\n","model.fit(trainX, trainy)\n","probs = model.predict_proba(testX)\n","probs = probs[:, 1] \n","thresholds = np.linspace(0.1,1,num=10)\n","mcc_list = []\n","f1_list = []\n","for thr in thresholds:\n","    predict  = (probs > thr).astype(int)\n","    mcc = matthews_corrcoef(testy, predict)\n","    f1 = f1_score(testy, predict)\n","    mcc_list.append(mcc)\n","    f1_list.append(f1)\n","plt.plot(thresholds, f1_list, linestyle='--', label=\"f1_score\")\n","plt.plot(thresholds, mcc_list, marker='.', label=\"mcc\")\n","plt.legend()\n","plt.xlabel(\"Threshold\")\n","plt.ylabel(\"Score\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8qMwe9HG80X"},"source":["結局のところ、MCCが最も安全であるといえるが、残念ながらその解釈は最も直観的ではない"]},{"cell_type":"markdown","metadata":{"id":"1KW_3Oe-eOxe"},"source":["# 課題(混同行列)\n","\n","次の問題に答えなさい\n","- 内容を理解すれば、問題はコピペで終わるはずです\n","- ノートブックには次の内容を先頭に必ず記述すること\n","- 先頭セルはテキストで、\n","「# **データシステムの知能化とデザイン**」と記載\n","- さらに「# 第2回課題」と記載\n","- 次に、「## 学籍番号」と「## 氏名」を記載\n","\n","**これらのタイトルは、全ての課題に共通する事項である**\n","\n","これ以降省略するが、**忘れずに記載すること**\n","\n","今回は以下の問題に解答することを課題とする\n","\n","## 問題\n","\n","次の問題に応えなさい\n","- 解答は、Google Colaboratoryのノートブック形式でコードと結果をセルに記述し、LMSより提出しなさい\n","- ノートブックの名前は、「DataAI課題2.ipynb」とすること\n","- 全ての問題を一つのノートブックに含めなさい\n","- 解答には、「課題解答のための参考コード例」を参考にしなさい\n","  - なお、Google Colaboratoryを用い、プログラムされていれば特に言語は問わない\n","  - pythonによるプログラムを期待しているが、Google Colaboratoryには、pythonだけでなく、c言語に加え、R, ruby, perlなど様々な言語の設計環境が備わっており、GO言語などデフォルトで入っていない場合でも、aptを使ってワンコマンドで簡単にインストールできる\n","  - こうなれば、fortran, lisp, java, javascript, php, D言語, さらにはbash, cshシェルスクリプトを含む、プログラミング言語の範疇に入れば何でも用いてよい\n","  - 難読化されていなければ、すべて受け入れるので、言語や仕組みに何ら遠慮はいらない\n","- 純粋に混同行列の問題であって、機械学習の問題ではないことに注意しなさい\n","  - つまり、エクセルシートで、マクロを使わず表の式だけで解ける問題である\n","\n","**(問題1)** 下記に示す検査Aと検査Bの2種類の「課題回答用データ」それぞれを用いて、混合行列より正解率、再現率、適合率、F値を各データ毎に求めなさい。なお、**検査A、検査B共に値が0.8よりも小さいときに疾患と判断する**\n","\n","**(問題2)** 下記に示す2種類の「課題回答用データ」を用い、それぞれについてROC曲線を描きなさい\n","\n","なお、値が小さいと疾患であるとみなすため若干の工夫が必要である\n","\n","(ヒント)\n","- 問題1で「0.8よりも小さいときに疾患」としていますが、この0.8というはどうやって決めるのでしょうか？どうやれば適した値がでるのでしょうか？これを決定する作業が、ROCです。ROCを求めるためには、0.8ではない値を使って作成する必要がありますね。\n","- このROCを書けば、追加でAUCを求めることができます。AUCが求まれば、利用したモデルが適切かどうかがわかる、ということになります。\n","\n","**(問題3)** AUC (Area Under the Curve)による面積をそれぞれ求めなさい\n","\n","**(問題4)** 「課題回答用データ」に示した検査Aと検査Bは、どちらがより信頼できるといえるか、簡単な理由と共にテキストのセルとして答えなさい\n"]},{"cell_type":"markdown","metadata":{"id":"xOXPLVSq0lzD"},"source":["## 課題回答用データ\n","\n","今回利用するデータは、2種類の検査手法、検査Aと検査Bで疾患を発見できるかどうか、どちらの検査の方が正確かどうかを調査するために取得したとする\n","\n","以下は、CSV形式です\n","\n","次のデータは直接プログラムに記述してもよい\n","- 読み込み方を調べるなどしてcsvファイルを扱えるようであれば、http://class.west.sd.keio.ac.jp/dataai/data/p2data.csv よりwgetでダウンロードして利用するプログラムを用いてもよい\n","  - 記述的な観点で妥協・遠慮する必要はない\n","  - ダウンロードしたファイルはフォルダに表示される\n","- 表示まで時間がかかる場合があるので注意すること\n","\n","```\n","検査A,検査B,疾患\n","-2.475 ,-1.913 ,1\n","-2.436 ,-1.316 ,1\n","-1.630 ,-0.805 ,1\n","-1.333 ,-0.658 ,1\n","-0.964 ,-0.299 ,1\n","-0.960 ,-0.199 ,1\n","-0.780 ,0.162 ,1\n","-0.730 ,0.383 ,1\n","-0.432 ,0.412 ,1\n","-0.326 ,0.619 ,1\n","-0.261 ,0.692 ,1\n","0.173 ,0.824 ,1\n","0.575 ,1.578 ,1\n","0.743 ,1.764 ,1\n","1.682 ,1.801 ,1\n","-0.596 ,-0.602 ,0\n","-0.141 ,-0.172 ,0\n","0.103 ,-0.071 ,0\n","0.196 ,0.108 ,0\n","0.199 ,0.314 ,0\n","0.340 ,0.361 ,0\n","0.429 ,0.406 ,0\n","0.522 ,0.469 ,0\n","0.694 ,0.511 ,0\n","0.790 ,0.520 ,0\n","0.853 ,0.558 ,0\n","0.888 ,0.573 ,0\n","0.992 ,0.794 ,0\n","1.186 ,0.835 ,0\n","1.238 ,0.965 ,0\n","1.297 ,1.377 ,0\n","1.393 ,1.500 ,0\n","1.510 ,1.512 ,0\n","1.808 ,1.673 ,0\n","1.968 ,1.830 ,0\n","1.995 ,1.891 ,0\n","2.367 ,2.024 ,0\n","2.620 ,2.399 ,0\n","2.855 ,2.631 ,0\n","2.908 ,2.706 ,0\n","2.928 ,2.992 ,0\n","2.953 ,3.038 ,0\n","3.094 ,3.090 ,0\n","3.547 ,3.218 ,0\n","3.886 ,3.997 ,0\n","```"]},{"cell_type":"markdown","metadata":{"id":"940Abb7Qq2sW"},"source":["## 課題解答のための参考コード\n","まずは一般的な記述例を示す\n","- Pythonおよびscikit-learnを使って多クラス混同行列を作り、評価指標を計算する\n","  - なお、繰り返しとなるがGoogle Colaboratoryでコードを書く際は、日本語を用いてはならない\n","\n","問題設定として、ここでは、あえて、多クラス混同行列を扱ってみよう\n","- 答えがコピペですぐに出るのは避けるためで、簡単なものを示して発展形を答えさせるのではなく、発展形を示して、簡単なものを答えさせるというパターンである\n","\n","手でじゃんけんの型を提示し、これをAIで判別するという事例を想定する\n","- 教師データとして trainがあり、その予測データとして resultがある\n","- このデータはラベルで入っているため数値化が必要であるが、ラベルを1, 2, 3という数字に変換する際の数字とラベルの対応をとるための行列がnameである\n","\n","\n","課題は2値によるシンプルな混同行列であり、下記よりも簡単に求めることができる\n","- ここでは、csvファイルを読み込むといったことは考えず、上記データをコピペしてそのままpythonの配列に入れてしまうという「ビッグデータでは絶対に無理だが、とりあえず初心者が好きそうな方法」になる\n","  - 大ヒントを出せば、trainは、データから結局PositiveかNegativeが判断できるのだから、0と1で埋めればよいし、resultも同様で、さらにnameは全部不要\n","  - 数字だけ埋めれば、下記10行程度で課題は終わる"]},{"cell_type":"code","metadata":{"id":"zkuyIpbAmCPU"},"source":["train = [\"Gu\",\"Choki\",\"Pa\",\"Pa\",\"Pa\",\"Pa\",\"Gu\",\"Choki\",\"Pa\",\"Gu\"]\n","result = [\"Gu\",\"Choki\",\"Pa\",\"Choki\",\"Choki\",\"Choki\",\"Gu\",\"Pa\",\"Gu\",\"Gu\"]\n","name = [\"Gu\",\"Choki\",\"Pa\"]\n"," \n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import f1_score\n","val_mat = confusion_matrix(train, result, labels=name)\n","val_mat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dsCndq0nqvBz"},"source":["但し、上記の方法では、ROCが求められない\n","- この方法でROCはできませんでした！といった演習レポートを作成しても、点数(4/5点)はもらえます\n","\n","もし、卒業論文発表のデータ解析で文句を言われることがないようにしたい、レポート満点を目指したいならば、より実践的な例として、以下のコードを参考にレポートを作成するとよい\n","- なお、混合行列の値が出ることから、そこから計算で正解率、再現率、適合率、F値を求めることができる\n","  - 各自やってみるとよいであろう"]},{"cell_type":"markdown","metadata":{"id":"FgSigTCveCaQ"},"source":["## さらに実践的な参考コード\n","(ここでも、コピペは困るので)さらに実践的な課題として、学習結果がsoftmaxによる値、つまり学習結果としての何%正しいとみなしたかという「確度」で示されているとする\n","  - つまり、resultとしては、最も確率の高いじゃんけんの型を出すことになる\n","  - argmaxは、配列から最も値の大きい列を返す関数であり、argmaxを用いて0, 1, 2の値へ変換できる\n","\n","trainは、じゃんけんの型それぞれについて、どれを出したかを0か1かで記載されている\n","- これも、0, 1, 2に変換しなければならないが、同様にargmaxで変換できる"]},{"cell_type":"code","metadata":{"id":"a4nWirgVqmlk"},"source":["result = [\n","    [0.1, 0.2, 0.7],\n","    [0.5, 0.3, 0.3],\n","    [0.2, 0.3, 0.2],\n","    [0.2, 0.7, 0.2],\n","    [0.2, 0.5, 0.2]\n","]\n","train = [\n","    [0, 0, 1],\n","    [1, 0, 0],\n","    [0, 0, 1],\n","    [0, 0, 1],\n","    [0, 1, 0]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-eNhbu82r_ul"},"source":["numpyのargmaxを使って正解を得る\\\n","上記のじゃんけん例はargmaxによる値を示しているといえる"]},{"cell_type":"code","metadata":{"id":"A5sp4Wo5r2SA"},"source":["import numpy as np\n","resulta = [np.argmax(i) for i in result]\n","traina = [np.argmax(i) for i in train]\n","print(resulta)\n","print(traina)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-kBga-oCtZ-F"},"source":["conf_mat = confusion_matrix(traina, resulta)\n","conf_mat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cye7K2F2aGT"},"source":["# このセルは本質ではないが、要素を取り出す場合は、flatten()が便利であろう\n","confa = []\n","confa = conf_mat.flatten()\n","confa[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3LrSNDvxUrMv"},"source":["# 当然だが、次のようにしてもよい\n","a1, a2, a3, b1, b2, b3, c1, c2, c3 = conf_mat.flatten()\n","a1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iugt7tcJvx0M"},"source":["## 正解率"]},{"cell_type":"code","metadata":{"id":"gA3-zEPnmPnr"},"source":["acc_score = accuracy_score(traina, resulta)\n","acc_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xm1SaD6J4IYM"},"source":["## 再現率"]},{"cell_type":"code","metadata":{"id":"oaB8oHWrmi-d"},"source":["rec_score = recall_score(traina, resulta, average=None)\n","rec_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fBkeu5N16auV"},"source":["全体平均をとるにはaverage='macro'もしくは'micro'とする\n","- それぞれの計算結果の平均をとるのがmacroで、それぞれの状態でTP, FP, FNなどを数え、その合計カウント数から平均を計算するのがmicroである\n","  - macroは各クラスの要素数の違いを吸収するが、少ないクラスの影響を受けやすい\n","  - microは少ないクラスの影響を受けにくいが、単純に各指標の平均を得るわけではない\n","\n","macroは単純に1, 1, 0.3333の平均の値になっていることがわかるであろう\n","\n","また、average='weighted'にすると、それぞれの個数の違いを重みで反映させることができる\\\n","詳しくは調べてみること\n","\n","なお、averageの指定は適合率、F値でも可能である"]},{"cell_type":"code","metadata":{"id":"TMpgTklFnyzh"},"source":["recall_score(traina, resulta, average='macro')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQXm7SHq7Mmq"},"source":["recall_score(traina, resulta, average='micro')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MdOuB7gM4KiM"},"source":["## 適合率"]},{"cell_type":"code","metadata":{"id":"Wj_Rz4GfmnGu"},"source":["pre_score = precision_score(traina, resulta, average=None)\n","pre_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fe_Z4zkv4TEm"},"source":["## F値\n"]},{"cell_type":"code","metadata":{"id":"gEL22V5xmrm_"},"source":["f1_score = f1_score(traina, resulta, average=None)\n","f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yEXhb1Oo9oIQ"},"source":["scikit-lernのバージョンにもよるが、先に示したように、適合率、再現率、F1値およびそれらのマクロ平均、マイクロ平均、加重平均をすべて算出させることができる\n","- なお、supportはここでいうtrainaにおける各クラスの個数を示している"]},{"cell_type":"code","metadata":{"id":"sTD7V3Ct9d0f"},"source":["from sklearn.metrics import classification_report\n","print(classification_report(traina, resulta))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2il1RsH-NZv"},"source":["# ラベルで出したいなら、target_namesで指定する\n","print(classification_report(traina, resulta, target_names=name))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6u1sYC5p_Tf8"},"source":["さらに、この結果を取り出す場合は、output_dict=Trueとして計算させれば配列で取得できる\n","- ここでは、あえてtarget_nameをラベル名でしていしておく\n","- target_namesを指定しない場合も試しておくと良い"]},{"cell_type":"code","metadata":{"id":"xR4uwYOK-vkK"},"source":["cr = classification_report(traina, resulta, target_names=name, output_dict=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6NK9B0xl-9gm"},"source":["何も考えずにcrを表示"]},{"cell_type":"code","metadata":{"id":"X00frVhp_B4a"},"source":["cr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xH3-F9V_kZ2"},"source":["次のようにしてそれぞれの値を取り出すことができる"]},{"cell_type":"code","metadata":{"id":"X395Vkwf_Dp3"},"source":["cr['Choki']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_sdZQo7_bHP"},"source":["cr['accuracy']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dUCVZLGr_eAN"},"source":["cr['Gu']['recall']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iycq5OaA_ryf"},"source":["# pandasのDataFrame形式にすることも当然でき、ここまでできれば、csvファイルへの出力なども簡単にできる\n","import pandas as pd\n","df = pd.DataFrame(cr)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dbiZoj7aATtL"},"source":["次のコードでcsvファイルを生成している\n","- 左のメニューからフォルダアイコンを選ぶと、中にresult.csvが保存されているのがわかるであろう"]},{"cell_type":"code","metadata":{"id":"bL-fCtWhAAr_"},"source":["df.to_csv(\"result.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eq5cEE-ZJ3Rs"},"source":["## ROC曲線の描画\n","\n","pythonを使うなら、1から作る必要は全くない\n","- 先人が全て準備してくれている\n","\n","ROC曲線の算出にはsklearn.metricsモジュールのroc_curve()関数を使う\n","\n","テストデータ等の正解クラスと、モデルの出力としての予測スコアをそれぞれ指定して求める\n","\n","出力は、3つの配列要素で構成され、それぞれがさらに配列で構成されている\n","- 3つの要素は偽陽性率(FPR), 真陽性率(TPR), 閾値である\n"]},{"cell_type":"code","metadata":{"id":"K1e9hnxaKWRD"},"source":["from sklearn.metrics import roc_curve\n","y_true  = [0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1  ]\n","y_score = [0.1,0.2,0.2,0.3,0.3,0.3,0.4,0.4,0.4,0.4,0.5,0.5,0.5,0.5,0.5,0.6,0.6,0.6,0.6,0.6,0.7,0.7,0.7,0.7,0.8,0.8,0.8,0.9,0.9]\n","roc = roc_curve(y_true, y_score)\n","roc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OePWkEGxLRoT"},"source":["従って、この中のFPRとTPRを用いてグラフにすればよい\n","\n","結果が、手計算と同じであることが確認できる"]},{"cell_type":"code","metadata":{"id":"geEBBTC7LZb4"},"source":["plt.plot(roc[0], roc[1], marker='o')\n","plt.xlabel('FPR: False positive rate')\n","plt.ylabel('TPR: True positive rate')\n","plt.grid()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGFZn3tBwniw"},"source":["## AUCの算出\n","\n","こちらもscikit-learnを用いれば簡単に求まる\\\n","ROC-AUCスコアの算出にはsklearn.metricsモジュールのroc_auc_score()関数を使う\n"]},{"cell_type":"code","metadata":{"id":"Kt6nZ1DoxxgT"},"source":["from sklearn.metrics import roc_auc_score\n","auc = roc_auc_score(y_true, y_score)\n","auc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Blby-PW8yDR_"},"source":["相当高い値になるが、あくまでも例題である"]}]}