{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataai-text-6-ニューラルネットワークの基礎.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/japan-medical-ai/medical-ai-course-materials/blob/master/notebooks/Introduction_to_Neural_Network.ipynb","timestamp":1550816046069}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RpSvTCHHR_fO"},"source":["---\n","> 盗人には網を張れ\\\n","> そのデータを学習するにも網を張れ\n","---"]},{"cell_type":"markdown","metadata":{"id":"Da9LzFk5G38W"},"source":["# ニューラルネットワークの基礎\n","\n","より一般的なのは、全結合層(Full connected layer)、つまり、全てのノードが次の層のすべてのノードに繋がっている形態であるが、画像認識などに用いられる Convolutional Neural Network (CNN) や、自然言語処理などに用いられる Recurrent Neural Network (RNN) など様々な種類が提案されている\n","\n","最初に全結合型と呼ばれるニューラルネットワークの構造について説明し、複数の入力データと望ましい出力の組からなる学習用データセットを用いてどのように学習させるのかについて説明する\n","\n","- これには、ニューラルネットワークによって表現される複雑な関数を、現実的な時間で学習するための誤差逆伝播法（バックプロパゲーション）と呼ばれるアルゴリズムを用いる\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LICMyO4rKUX9"},"source":["## ニューラルネットワーク(NN)の構造\n","\n","NNの構造を図式化すると次のようなイメージとなる\n","\n","- 例えば、赤ワインと白ワインを分けるNNが。入力変数が{年数，アルコール度数，色合い，匂い}の4変数，出力変数が{白ワイン，赤ワイン}の2変数の場合を示す\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/3-01.png\">\n","\n","-  図のように**ノード**もしくは**ユニット**が**層**を成して結合した構造を有する\n","\n","-  一番初め(左)の層を**入力層（input layer）**，最後の層(右)を**出力層（output layer）**、それ以外を**中間層（intermediate layer）** もしくは **隠れ層（hidden layer）** と呼ぶ\n","\n","- 中間層の数は問題に応じて0層も含めて自由に設定できる\n","\n","- この例では各層間の全てのノードが互いに結合されており、**全結合型のニューラルネットワーク**と呼ばれる基本形である"]},{"cell_type":"markdown","metadata":{"id":"meyqKCr-NUDs"},"source":["ここに、年数が3年物でアルコール度数が14度、色合いが0.2、匂いが0.8で表されるワインがあるとする\n","\n","- このようなデータを上記NNに与えたとき、結果として得られる値に着目したとき、白ワイン $y_{1} = 0.15$, 赤ワイン $y_{2}= 0.85$ となったとする\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/3-02.png\">\n","\n","- このとき、出力値の中で最も大きな値となっている変数に対応するクラス、すなわち「赤ワイン」をこの分類問題におけるこのニューラルネットワークの**予測結果**とする\n","\n","- ここで出力層のすべての値を合計すると1になっていることに注意する\\\n","これは、自然とそうなるのではなく、狙ってあたかも出力層のそれぞれのノードが持つ数値が各クラスに属している確率を表しているかのように、特に出力層においてはsoftmaxを用いて表現しているからである\n","\n","- また、一般にカテゴリ数と同数のノードが出力層に必要である\n","\n","次に、ニューラルネットワークの内部で行われる計算について述べる\n","\n","- ニューラルネットワークの各層は、前の層の値に線形変換と非線形変換を順番に施して計算を進めている"]},{"cell_type":"markdown","metadata":{"id":"X9-RYTlXNzNQ"},"source":["### 線形変換\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/linear_transformation.png\" width=300>\n","\n","ここで言う線形変換とは、重み行列 ($w$) $\\times$ 入力ベクトル ($h$) $+$ バイアスベクトル ($b$) といった計算を意味する\n","\n","- この変換の入力が$h$、パラメータが$w$と$b$である\n","\n","  - 以下では入力層（上図における $x_1, x_2, x_3, x_4$）を0層目の隠れ層と数えて、 $h_{01}, h_{02}, h_{03}, h_{04}$ と表記する\n","  - $h$は積和を計算することから、$\\sigma$と表記されることも多い\n","\n","  - なお、数学では線形変換は ${\\bf w} \\times {\\bf h}$ といった変換を意味し、ここで述べた$w \\times h + b$という変換は厳密には**アファイン変換(もしくはアフィン変換)**と呼ばれる\n","    - 深層学習の文脈ではこの変換も**線形変換**と呼ぶことが多い\n","\n","この行列演算およびその展開式は次のようになる\n","\n","- 式におけるバイアス（$b_1, b_2, b_3$）は上図では省略されている\n","\n","**行列式**\n","\n","$$\n","\\begin{aligned}\n","\\begin{bmatrix}\n","u_{11} \\\\\n","u_{12} \\\\\n","u_{13}\n","\\end{bmatrix}&=\\begin{bmatrix}\n","w_{11} & w_{12} & w_{13} & w_{14} \\\\\n","w_{21} & w_{22} & w_{23} & w_{24} \\\\\n","w_{31} & w_{32} & w_{33} & w_{34}\n","\\end{bmatrix}\\begin{bmatrix}\n","h_{01} \\\\\n","h_{02} \\\\\n","h_{03} \\\\\n","h_{04}\n","\\end{bmatrix}&+&\\begin{bmatrix}\n","b_{1} \\\\\n","b_{2} \\\\\n","b_{3}\n","\\end{bmatrix}\\\\\n","\\\\\n","{\\bf u}_{1}&={\\bf W}{\\bf h}_{0}&+&{\\bf b}\n","\\end{aligned}\n","$$\n","\n","**展開式**\n","\n","$$\n","\\begin{aligned}\n","u_{11}&=w_{11}h_{01}+w_{12}h_{02}+w_{13}h_{03}+w_{14}h_{04}+b_{1} \\\\\n","u_{12}&=w_{21}h_{01}+w_{22}h_{02}+w_{23}h_{03}+w_{24}h_{04}+b_{2} \\\\\n","u_{13}&=w_{31}h_{01}+w_{32}h_{02}+w_{33}h_{03}+w_{34}h_{04}+b_{3}\n","\\end{aligned}\n","$$\n","\n","${\\bf W}$ および ${\\bf b}$ についても、どの層とどの層の間の計算に用いるかを明確にするため添え字をつけるべきであるが、ここでは省略している"]},{"cell_type":"markdown","metadata":{"id":"JmlTx1YF4xMD"},"source":["### 非線形変換\n","\n","線形変換のみでは、次の左図のような場合は関係を表現できるが、右のような場合は適切に表現できない。\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/3-04.png\" width=300>\n","\n","そこで、各層で線形変換に引き続いて非線形変換を施すことで全体の関数が非線形性を持つようにする\n","\n","- この非線形変換を行う関数を、特に **活性化関数** と呼ぶ\n","\n","上図の線形変換の結果 $u_{11}, u_{12}, u_{13}$ に活性化関数を使って非線形変換を行った結果を $h_{11}, h_{12}, h_{13}$ とし、これらを活性値(activation)と呼ぶ\n","- これが次の層への入力となる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/activation.png\" width=300>"]},{"cell_type":"markdown","metadata":{"id":"La_zkyOqN6XR"},"source":["## 活性化関数と損失関数\n","\n","活性化関数とは\n","- ニューロンの興奮/抑制状態を決める関数\n","- 関数への入力を、興奮/抑制状態を表す値に変換\n","\n","損失関数（誤差関数）\n","\n","- 出力と正解の間の「誤差」を定義する関数\n","\n"]},{"cell_type":"markdown","metadata":{"id":"m27iBO1pNqF9"},"source":["## 活性化関数\n","\n","- ReLU関数(ランプ関数)\n"," - 最近提案されたが多層では最もよく利用される活性化関数\n"," - シンプルで演算が高速、正の入力値では微分値が1固定で入力に応じて値を大きくできるため勾配消失が起こりにくい\n"," - 多層であるDNNでは特に重要だが、以下の欠点がある\n","   - x=0で不連続微分不可能であることを基本的に無視\n","   - 負の場合は収束しにくい\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/act-relu.png\" width=300>\n","\n","- シグモイド関数=$\\frac{1}{1+e^{−𝑎𝑥}}$\n"," - 誤差逆伝播法が登場した当初よく利用されていた\n"," - 今は狙って使われるだけで一般的ではなくなった\n"," - 極端に大きい・小さい入力に対して応答が悪く、微分の最大値が0.25のため多層では勾配消失の問題が発生、計算量も大きめ\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/act-sigmo.png\" width=300>\n","\n","- tanh関数\n"," - 微分の最大値が1のため勾配消失の問題を解決しやすい\n"," - 極端に大きい・小さい入力での微分が0となる問題が残っている\n"," - 計算量も多め\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/act-tanh.png\" width=300>\n","\n","- Linear関数\n"," - 線形関数や恒等関数と呼ばれ、要するに𝑦=𝑥という関数で入力そのまま出力するなにもしない関数\n"," - 活性化関数には非線形性が必要であるということを示すためにあるようなもので、普通は利用しない\n","   - 最終層などで広い値の範囲を得たい時などに利用\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/act-eq2.png\" width=300>\n","\n","- logistic関数=$\\frac{𝐴}{1+e^{−𝑎(𝑥−𝑥_0)}}$\n"," - シグモイド関数がパラメータで曲線の形しか変えられないのに対し、さらにパラメータで平行移動させることができる\n"," - 分類問題の回帰手法 (最尤推定を行う)に用いることが多い\n"," - 常に出力が0と1の間に入るので、確率と関係させて物事を考えることができる\n","\n"," - 計算は多め\n","\n","\n","- softmax関数\n"," - 常に出力が0と1の間に入るため確率と関係させることができる\n"," - 他の値と比べて目立った値ほど1に近づき、また総和が1になるため、最終的な「判断結果の確率指標」として利用される\n"," - 計算は多め\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/act-softmax.png\" width=300>\n"]},{"cell_type":"markdown","metadata":{"id":"s-eFDAuJ-Cse"},"source":["### 数値を見ながら計算の流れを確認\n","\n","下図のような具体的な数値を用いて、入力 $x_1, x_2, x_3$ から出力 $y$ を求める過程について確認する\n","\n","- 計算を簡略化するためバイアス ${\\bf b}$ の計算は省略する\n","\n","- すなわち、バイアスは全て0とする。数値例として，${\\bf x} = \\begin{bmatrix} 2 & 3 & 1 \\end{bmatrix}^T$ が与えられた時の出力 $y$ の計算手順を示す\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/output.png\" width=300>\n","\n","重回帰分析では、目的関数のパラメータについて、その導関数を0とおくことで、解析的に最適なパラメータを計算したが、ニューラルネットワークでは一般的に、解析的にパラメータを解くことはできない\n","\n","- そこで、別の方法として、この導関数の値(勾配)を利用してパラメータを逐次的に最適化する\n","\n","- この方法を採用する結果、**まずパラメータを乱数で初期化した後、まずは一度データを入力して目的関数の値を計算する**という手順、すなわち**順伝播**の計算を行う\n","\n","- 次にその関数の勾配を計算し、その結果を利用してパラメータを更新させる、すなわち**逆伝播**の計算を行う\n","\n","- さらに、その更新後の新しいパラメータを使って再度入力データを処理して(順伝播)目的関数の値を計算、といったプロセスを繰り返す\n","\n","このように、順伝播と逆伝播の2つで構成され、これらが交互に計算される\n","\n","順伝播について、パラメータを初期化した結果、上の図のグラフの枝に記載されている数値になったとして、入力層の値に線形変換を施すところまでの計算は次のように行われる\n","\n","最初に、次の計算が行われる\n","\n","$$\n","\\begin{aligned}\n","u_{11}&=3\\times 2+1\\times 3+2\\times 1=11\\\\\n","u_{12}&=-2\\times 2-3\\times 3-1\\times 1=-14\n","\\end{aligned}\n","$$\n","\n","次に非線形変換を行う活性化関数としてReLU関数を採用した場合、以下のように中間層の値が計算される\n","\n","$$\n","\\begin{aligned}\n","h_{11} &= \\max(0, 11) = 11 \\\\\n","h_{12} &= \\max(0, -14)  = 0\n","\\end{aligned}\n","$$\n","\n","同様に、出力層の $y$ を計算すると、\n","\n","$$\n","y = 3 \\times 11 + 2 \\times 0 = 33\n","$$\n","\n","となる"]},{"cell_type":"markdown","metadata":{"id":"ivVppUOibSHy"},"source":["## 目的関数・損失関数\n","\n","ニューラルネットワークは、微分可能でさえあれば(厳密にはところどころ微分不可能なところが存在したとしても)、解きたいタスクに合わせてどのような目的関数でも、基本的には利用することができる"]},{"cell_type":"markdown","metadata":{"id":"BCGZbTKcbUpe"},"source":["### 平均二乗誤差(MSE)\n","\n","例えば、出力層に$N$個のノードを持つニューラルネットワークについて、回帰問題を解く場合を考える\n","\n","- $N$個の出力それぞれ（$y_n (n=1, 2, \\dots, N)$）に対して望ましい出力（$t_n (n=1, 2, \\dots, N)$）が与えられたとき、目的関数をそれぞれの出力（$y_n$）と対応する正解（$t_n$）の間の **平均二乗誤差（mean squared error）**一般に**MSE**を求めることで回帰問題を解く\n","\n","$$\n","\\mathcal{L} = \\dfrac{1}{N} \\sum_{n=1}^{N}(t_{n} - y_{n})^{2}\n","$$\n","\n","これを最小にするようにニューラルネットワーク中のパラメータを決定すればよい\n","- 例えば、図の例で正解として $t = 20$ が与えられたときの目的関数の値は、\n","\n","$$\n","\\mathcal{L} = \\dfrac{1}{1} (20 - 33)^2 = 169\n","$$\n","\n","となる\n","\n","これを小さくするような重み行列の値を探せばよい"]},{"cell_type":"markdown","metadata":{"id":"EppPEA-BgDxZ"},"source":["### 交差エントロピー\n","\n","分類問題では、しばしば**交差エントロピー（cross entropy）** が目的関数として利用される\n","\n","例として、$N$クラスの分類問題を考える\n","- ある入力$x$に対する$N$ 個の出力があり、出力それぞれについて、入力が$n$番目のクラスに属する確率を$y_n = p(y=n|x)$とする\n","  - これは、入力 $x$ が与えられたという条件における予測クラスを意味する $y$ が $n$ であるような確率を意味する\n","\n","- ここで、$x$ が所属するクラスについて、正解が ${\\bf t} = \\begin{bmatrix} t_1 & t_2 & \\dots & t_N \\end{bmatrix}^T$ というベクトルで与えられているとする\n","  - だだし、このベクトルは $t_n (n=1, 2, \\dots, N)$ のいずれか1つだけが1であり、それ以外は0であるようなベクトル、 **one-hotベクトル** とする\n","\n","この1つだけ値が1となっている要素は、その要素のインデックスに対応したクラスが正解であることを意味する\n","- 例えば、$t_3 = 1$であれば3というインデックスに対応するクラスが正解となる\n","\n","この時、交差エントロピーは以下のように計算できる\n","\n","$$\n","\\mathcal{L} = - \\frac{1}{N} \\sum_{n=1}^{N}t_{n}\\log y_{n}\n","$$\n","\n","- 情報理論などで用いられる交差エントロピーの定義とは上記は異なる形を有することに注意する\n","\n","- 情報理論では、無理やり書くと$- \\frac{1}{N} \\sum_{n=1}^{N}y_{n}\\log y_{n}$となるが、このように書くと「交差」という意味が明確になるであろう\n","\n","つまり、推定値$y$に対する正解$t$があり、この2つが完全に一致すれば普通にエントロピーを計算していることになり、この時値が最小値となる\n","\n","さらに言えば、**ある確率分布を仮定して生成した別の確率分布が示す予測のはずれやすさ**といえる\n"]},{"cell_type":"markdown","metadata":{"id":"WqFc0jYJFLYz"},"source":["### 交差エントロピーの実際\n","\n","$\\mathcal{L}$における$\\frac{1}{N}t_{n}$の部分は真の確率$p$に相当し、$y_n$は推定した確率分布$q$に相当する\n","\n","$p$と$q$の確率分布が似ていると交差エントロピー誤差は小さくなり、似ていないと交差エントロピー誤差は大きくなる\n","\n","物体認識を想定して具体例を示す\n","\n","- 写真に\n","\n","  - バナナ\n","  - りんご\n","  - みかん\n","\n","のどれが映っているかを、推定するとする\n","\n","- 写真に映っている果物がバナナの場合、真の確率分布$p$はone-hotで$(1, 0, 0)$となり、また写真から推定した確率分布$q$を$(0.8, 0.1, 0.1)$とする\n","\n","  - この場合、交差エントロピー誤差は次のようになる\n","\n","$$\n","\\begin{align}\n","H(p, q)& = -(1\\cdot log0.8 + 0\\cdot log0.1 + 0\\cdot log0.1) \\\\\n","& = -(log0.8) \\\\\n","& = -(-0.09) \\\\\n","& = 0.09\n","\\end{align}\n","$$\n","\n","- 一方、推定した確率分布$q(x)$が$(0.3, 0.4, 0.3)$であった場合、交差エントロピー誤差は次のようになる\n","\n","$$\n","\\begin{align}\n","H(p, q)& = -(1\\cdot log0.3 + 0\\cdot log0.4 + 0\\cdot log0.3) \\\\\n","& = -(log0.3) \\\\\n","& = -(-0.52) \\\\\n","& = 0.52\n","\\end{align}\n","$$\n","\n","  - 交差エントロピー誤差は後者よりも前者の方が小さく、真の確率分布$p$に近いのは前者の確率分布$q$となることから、交差エントロピー誤差が損失関数として適しているといえる\n","\n","MSEも損失関数として直観的でわかりやすい形を有するが、NNでは一般に交差エントロピー誤差をもちいる\n","- これは、NNにおいて、交差エントロピー誤差が確率的勾配降下法との相性が良いためである\n","\n","確率的勾配降下法は、偏微分により傾きを求めて損失関数が小さくなる方向に進めて逐次最適化する手法であるが、\n","\n","- 自然対数$log(x)$を微分すると$1/x$\n","- $e^x$を微分しても積分しても$e^x$\n","\n","という性質を有することで、計算式が複雑になるのを防ぐことができる\n","\n","また、詳細は割愛するが、ソフトマックス関数と交差エントロピー損失関数のソフトマックス関数値での微分は、正解データと予測値のみを用いて表現できることを実際に計算することで示すことができる\n","- Deep Learning MIT Press book 式10.18参照 http://www.deeplearningbook.org"]},{"cell_type":"markdown","metadata":{"id":"axAA_eYUgGeF"},"source":["#### KLダイバージェンス\n","\n","2つの確率分布の差異を計る尺度として用いられる\n","\n","確率分布 $\\hat{p}(y|x)$ と $q(y|x)$ の間のKLダイバージェンスは次のように定義できる\n","\n","$$\n","\\begin{align}\n","KL(p||q) &= \\int_{x, y} \\hat{p}(y|x) \\log \\frac{\\hat{p}(y|x)}{q(y|x)} dx dy\\\\\n","&=\\int_{x, y} (\\hat{p}(y|x) \\log \\hat{p}(y|x) - \\hat{p}(y|x)\\log q(y|x)) dx dy\n","\\end{align}\n","$$\n","\n","つまり、KLダイバージェンスは、その意味として、交差エントロピー$\\mathcal{L}$、エントロピー$\\mathcal{H}$とすると、その差、$\\mathcal{L}-\\mathcal{H}$を求めることになる\n","\n","- つまり、$\\mathcal{L}= KL + \\mathcal{H}$であるから、確率分布$P(x)$と$Q(x)$の交差エントロピーは$P(x)$のエントロピーと$P(x)$から見た$Q(x)$のKLダイバージェンスを足し合わせた値である\n","\n","- さらに言えば、$P(x)$のエントロピーが不変であれば、KLダイバージェンスを最小化するという命題は交差エントロピーを最小化するという命題と等しく、データセットが固定であれば、$P(x)$のエントロピーは不変である\n","  - つまり、普通に機械学習は計算コスト上、値の拡散度合い上、交差エントロピーでよいという判断になる\n","\n","  - エントロピーはあちこちで現れるので注意しないといけないが、ここでは情報でいう平均情報量であるため、$\\mathcal{H}$である(物理屋は$\\mathcal{S}$であろう)\n","\n","この意味であるが、エントロピーは「ある確率分布の予想のはずれやすさ」であり、交差エントロピーが、**「ある確率分布を仮定して生成した別の確率分布が示す予測のはずれやすさ」**といえる\n","\n","- これらの差は、意味合いとしては**ある確率分布と別の確率分布のずれ**と表現できる\n","\n","- 常に**交差エントロピー ≧ エントロピー**であるため、KL divergence ≧ 0となる\n","\n","さて、KLダイバージェンスを用いて、2つの確率分布の差異を求めることができ、差異が大きいほど値が大きくなるが、その問題点として、KL divergenceには対称性がない、つまり$D_{KL}(P||Q)$と$D_{KL}(Q||P)$は等しくなく、どちらを使うかという問題が発生すると共に、距離の公理を満たさない\n","\n","そこで対称となるように定義した指標としてJensen-Shannon(JS) divergenceがある\n"," \n","  $$ D_{JS} = \\frac{1}{2}D_{KL}(P||M) + \\frac{1}{2} D_{KL}(Q||M) \\\\ (ただし M(x) = \\frac{P(x) + Q(X)}{2}) $$\n","\n","計算量が増えるが、距離の概念を持ち出したい時など、特に可換であることが求められる場合に用いる"]},{"cell_type":"markdown","metadata":{"id":"LdhvoUFgGj94"},"source":["KLダイバージェンスと、JSダイバージェンスをグラフで示す\n","\n","赤と青がそれぞれP(x)とQ(x)の分布で、 黄色がかった部分の分布がP(x)とQ(x)の平均の分布でM(x)である\n","- KL divergenceの場合と同じく、赤と青の分布が離れるにつれてJS divergenceの値も大きくなる\n","- ただし、大きくなる速度はKLの方が速い"]},{"cell_type":"code","metadata":{"id":"CMD7hk0oGwe7"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.stats import norm, entropy\n","x = np.linspace(-10.0, 10.0, 10000)\n","plt.figure(figsize=(12,8))\n","for i in np.arange(3):\n","    for j in np.arange(3):\n","        index = i*3 + j\n","        p = norm.pdf(x, loc=0, scale=1)\n","        q = norm.pdf(x, loc=index*0.5, scale=1)\n","        m = (p+q)/2\n","        # KL divergenceとJS divergenceの計算\n","        kl = entropy(p, q)\n","        kl_pm = entropy(p, m)\n","        kl_qm = entropy(q, m)\n","        js = (kl_pm + kl_qm)/2\n","        # plot\n","        plt.subplot(3,3,i*3+j+1)\n","        plt.fill_between(x, m, facecolor=\"y\", alpha=0.2)\n","        plt.fill_between(x, p, facecolor=\"b\", alpha=0.2)\n","        plt.fill_between(x, q, facecolor=\"r\", alpha=0.2)\n","        plt.xlim(-5, 7)\n","        plt.ylim(0,0.45)\n","        plt.title(\"KLD:{:>.3f}\".format(kl) + \",   JSD:{:>.3f}\".format(js))\n","        plt.tick_params(labelbottom=\"off\")\n","        plt.tick_params(labelleft=\"off\")\n","plt.subplots_adjust(wspace=0.1, hspace=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Wasserstein Loss\n","\n","#### Wasserstein Distance\n","\n","Wasserstein distanceはJS divergenceと同様2つの確率密度関数の距離をはかる指標で、Earth Mover's distanceとも呼ばれ、EM distanceと略されることもある\n","  - 実際に土を運ぶ例えで説明されている\n","\n","Wasserstein distanceは、ある確率密度関数を動かしてもう一つの確率密度関数に一致させるときの最小コストを意味する\n","\n","2つの確率密度関数$p_r$と$p_g$のWasserstein distanceは次のように与えられる\n","\n","$$ W(p _ r, p _ g) = \\inf _ {\\gamma \\sim \\Pi(p _ r, p _ g)} \\mathbb{E} _ {(x,y) \\sim \\gamma} \\left[ ||x - y || \\right] $$ \n","\n","$\\inf$は下限でありwasserstein distanceを求めることそのものが最適化問題となる\n","\n","$\\gamma(x,y)$は$p_r$のある地点$x$から$p_g$のある地点$y$に動かす確率密度の単位幅に相当する面積とする\n","- 正確には地点$x$から全面積$\\int p_r(x)dx$のうちどの面積を地点$y$へ移動するかを表す\n","- 移動によりp_rをp_gに一致させることから、$\\sum_x\\gamma(x,y)=p_g(y)$であり、逆に、$\\sum_y\\gamma(x,y)=p_r(x)$も成り立つ\n","\n","この面積に移動距離$||x-y||$を掛けることでコストを求めることができる\n","\n","候補となる動かし方戦略\\gammaのうち総コストが最小となる場合を求めることでWasserstein Distanceを得ることができる\n","\n","#### Wasserstein Distanceの実際\n","\n","Wasserstein DistanceはKantorovich-Rubinstein双対性を使って、\n","\n","$$ W(p _ r, p _ g) = \\frac{1}{K} \\sup _ {||f|| _ {L} \\leq K} \\mathbb{E} _ {x \\sim p _ {r}} [f(x)] - \\mathbb{E} _ {x \\sim p _ {g}} [f(x)] $$\n","\n","と変換することができる\n","\n","この場合のDiscriminatorは良い$f$を求めることを目的とするが、そのためにWGANは損失として$p_r$(現実のデータの分布)と$p_g$(Generatorが生むデータの分布)間のWasserstein distanceを利用する\n","- つまり、学習が進むにつれてGeneratorは現実のデータの分布に近いデータの分布を出力できるようになる\n","\n","$$ L(p _ {r}, p _ {g}) = W(p _ {r}, p _ {g}) = \\max _ {w \\in W} \\mathbb{E} _ {x \\sim p _ {r}} [f(x)] - \\mathbb{E} _ {z \\sim p _ {z}} [f(g _ {\\theta}(z))] $$ \n","\n","ただ、もう一つ勘案しなければならないことがある\n","\n","#### Lipschitz 連続性\n","\n","Wasserstein distanceの$f$には$||f||_L \\le K$という制約がある\n","- この制約をK-リプシッツ連続という\n","\n","関数$f:ℝ → ℝ$は次の条件を満たす時にK-リプシッツ連続となる\n","\n","「ある定数$K≥0$が存在し、全ての$x1,x2∈R$に対して$ |f(x _ {1} - f(x _ {2})| \\leq K |x _ {1} - x _ {2}| $となる\n","- つまり任意の区間の傾きがある値K(リプシッツ定数)より小さいことを意味する\n","\n","任意の場所で微分可能な関数はリプシッツ連続であるが、逆は成り立たない(例えば、f(x)=|x|は原点で微分不可能)\n","\n","$ L(p _ {r}, p _ {g}) $の式における$f$はK-リプシッツ性を維持しなければならないが、その簡単かつ強力な方法は、重み$w$を更新した後、$w$を$[-0.01, 0.01]$といった小さな範囲でクリップする方法である\n","- パラメータ空間$W$は小さくなり、$f$の傾きを抑えることができる\n","- 一方でネットワークが極端に単純化され学習が収束しない場合が想定される\n","\n","そこで、勾配制約という手法が提案された\n","\n","$$\\lambda 𝔼_{\\hat{x}～ℙ_\\hat{x}}[(||\\nabla_{\\hat{x}}D(\\hat{x})||_2-1)^2]  $$\n","\n","$\\nabla$は勾配演算子、$\\lambda$はPnelty coefficientで10といったの値\n","\n","そこで、もともとのcricic Lossに、勾配制約を加えて全体のロストする\n"],"metadata":{"id":"TD24jLjLsTuO"}},{"cell_type":"markdown","metadata":{"id":"jjTEj26sezL4"},"source":["### 気になること#1(割合で計算したらどうしてだめ？)\n","\n","もっともな疑問として、例えば$a_1, a_2, a_3$があった場合、確率でよいのだから、$a_1/\\sum_a, a_2/\\sum_a, a_3/\\sum_a$でもよいではないか？と考えるかもしれない\n","- もちろん、そうであり、実際このような関数は微分の計算も容易で利用できなくはない\n","- ただし、実際には収束速度が遅い\n","  - 正規化すれば分母は1であるから、結局$y=x$的な評価であり、微分値がつねに等しく1となることから、外れているからと言って急速に近づこうとはしない\n","  - 交差エントロピーなどに含まれる$-log(x)$の演算は、xが小さい場合急激に値が大きくなるとともに、$0<x<1$であるため確率を扱う上で都合がよい\n","    - 例えば確率1では値が0になり、確率が0に近づくと急激に値が大きくなる\n","  - さらに微分を考えても、$1/x$であり、確率として$0<y<1$の値の範囲で考えても、誤差が大きいとき、つまり0に近づくにつれて値が急激に大きくなることから損失関数として適している\n","- したがって、学習速度や扱いやすさを考慮すると普通は使わない\n","\n","NNの発展は、様々な要素があるが、計算性能の向上に加え、数理学的な計算量削減と意味付けによるところも多いことがわかる"]},{"cell_type":"markdown","metadata":{"id":"Q8nZn-9WlFUa"},"source":["### 気になること#2(交差エントロピーかKLダイバージェンスか、それとも)\n","\n","- 交差エントロピーは予測の難しさそのもの表現している\n","- KLダイバージェンスは、 P(x)からQ(x)の**相対的**な予測の難しさ、どれだけ似ているかを表現している\n","- JSダイバージェンスは、P(x)とQ(x)の双方からみた予測の難しさを対称性を保って表現している\n","- GANでは、KLやJSを利用することがあったが、Wasserstein distanceの登場により、WDを利用することが一般的になりつつある\n","\n","ほぼ単純に、計算速度を向上するという目的で、交差エントロピーが利用されている\n","- 距離の概念を持ち込む場合には、対称性があり距離としても定義できるJSダイバージェンスを用いる\n","  - ユークリッド距離のように確率分布間の距離が求められるため\n","  - 情報幾何学の領域\n"]},{"cell_type":"markdown","metadata":{"id":"5betis1dl1D5"},"source":["### 気になること#3(結局何を使えばよいの？)\n","\n","必ずそうでなければいけない、ということもないが、一般的に次のような方針となる\n","\n","#### **バイナリ分類：2つの排他的なクラスの分類**\n","\n","バイナリクロスエントロピーを利用する\n","\n","出力$y$と$1−y$がそれぞれクラス1,2に属する確率を表す場合、交差エントロピーを利用するため元の式の両方の対数をとるなど変形すると次のバイナリクロスエントロピー(2値交差エントロピー)を得ることができる\n","- PyTorchではBCELoss\n","- softmaxの出力は確率のように足して1になるため、出力$y$と$1−y$とする\n","\n","$$\n","loss(o,t)=−\\frac{1}{n}\\sum_i{t_ilog(o_i)+(1−t_i)log(1−o_i)}\n","$$\n","\n","さらにsigmoidを用いて[0, 1]の値をとるようにしたあと2値交差エントロピーを利用することが通常行われる\n","- これを一度に行うのがBCEWithLogitsLoss\n","- PyTorchではBCEWithLogitsLoss\n","\n","$$\n","loss (o, t) = -\\frac{1}{n} \\sum_i \\left\\{t_i \\log(sigmoid(o_i)) + (1-t_i) \\log(1- sigmoid(o_i))\\right\\}\n","$$\n","\n","つまり、PyTorchのBCELossとBCEWithLogitsLossは、入力定義が異なる\n","- BCELossはシグモイドをとった後の値を入力とする\n","- BCEWithLogitsLossはシグモイドをとる前の値を入力とする\n","- BCEWithLogitsLossはシグモイド層とBCELossを1つのクラスにまとめたもので、単純なSigmoidとBCELossの組み合わせよりも数値的に安定するように工夫されている\n","\n","#### **マルチクラス分類：3つ以上の排他的なクラス**\n","\n","3つ以上のクラスの**どこか一つだけ**に分類される\n","\n","カテゴリカルクロスエントロピーを使用する(PyTorchではCrossEntropyLoss)\n","\n","PyTorchには純粋なカテゴリカルクロスエントロピーロス関数は定義されておらず、その上位互換が存在する(CrossEntropyLoss)\n","- 実は使いやすいように、安定するように工夫されているのだが、この工夫が逆に学ぶ上で疑問を生んでいる\n","- 次のように記述すると等価になりますが、この方法を用いてはいけません(普通にCrossEntropyLoss関数を使うこと！)\n","```\n","nn.NLLLoss()(torch.log(y_pred), y_true)\n","```\n","- これらについては、PyTorchに入ってから別途コードを用いて説明します\n","- PyTorchでは収束しやすいように裏で様々な手法が用いられており、これらは基本的に記述する必要がないが、これらの手法を利用するためには、利用側が意識して複合機能関数を利用する必要がある\n","\n","#### **マルチラベル分類：非排他的なクラスのみ**\n","\n","3つ以上のクラスの**複数**に分類されてもよい\n","\n","この場合は、バイナリクロスエントロピーを使用する\n","- つまりそれぞれのラベルについて0か1かを選択する、という問題として捉える\n","- ベルヌーイ分布を多次元にしたカテゴリカル分布に基づくカテゴリカルクルスエントロピーを用いると、どれか1つを選択するため、明らかに精度が低下、そもそも利用できない\n","- MSEなどでも問題はない\n","\n","ちなみに\n","- 事象の想起を扱う分布がベルヌーイ分布(コイントス)\n","$Bern(x|\\mu)=\\mu^x(1-\\mu)^{1-x}$\n","- ベルヌーイ分布を多試行化すると二項分布(何回も投げるコイントス)\n","$Bin(m|\\mu,N)=\\frac{N!}{m!(N-m)!}\\mu^m(1-\\mu)^{N-m}$\n","- ベルヌーイ分布を多次元化するとカテゴリカル分布(サイコロ)\n","$Cat({\\mathbf x}|{\\mathbf \\mu})=\\prod^K_{k=1}\\mu^{x_k}_k$\n","- 二項分布を多次元化する、カテゴリカル分布を多試行化すると多項分布(何度もサイコロ)\n","$Mult({\\mathbf m}|{\\mathbf \\mu}, N)=\\frac{N!}{m_1!\\cdots m_K!}\\prod^K_{k=1}\\mu^{m_k}_k$\n","- ベータ分布はベルヌーイ分布と二項分布についての共役事前分布\n","$Beta(\\mu|a,b)=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\mu^{a-1}(1-\\mu)^{b-1}$\n","- ディレクレ分布はカテゴリカル分布と多項分布についての共役事前分布である\n","$Dir({\\mathbf \\mu$|{\\mathbf \\alpha}}=\\frac{\\Gamma(\\sum^K_{k=1}\\alpha_k)}{\\Gamma(\\alpha_1)\\cdots \\Gamma(\\alpha_K)}\\prod^K_{k=1}\\mu^{\\alpha_k-1}_k$\n","\n","出力層の活性化関数にsofmaxを用いると、合計が1になるため、ある特定のラベルを際立たせることしかできなくなる\n","- そこで、出力の和が1という制限を外し、一般にsigmoidを用いる(tanhなどもありえる)\n","\n","マルチクラスにおいて、正解を1、残り全て0とするone-hotは、正解すべてを1とする(multi-hot?)ならばマルチラベルでも利用できる。さらに言えば、ある複数のラベルに属する場合、これを新たな1つのラベルとして定義すれば、one-hotのままでよい\n","- つまり、マルチクラス分類とすることもできなくはない\n","- ただしラベルが膨大に増える結果、ネットワークも複雑になりやすく、学習不足に陥りやすい"]},{"cell_type":"markdown","metadata":{"id":"Drh35j_lCYiy"},"source":["## ニューラルネットワークの最適化\n","\n","NNの目的関数が望ましい値をとるようにNNの主に${\\bf W}$や${\\bf b}$などのパラメータを決定することを、NNの最適化と呼ぶ\n","\n","- 既に述べたように、NNの各パラメータを、目的関数に対する勾配を0とおいて解析的に解くことは一般的には困難\n","- しかしながら、教師データをNNに入力すれば、その入力値における目的関数の勾配を数値的また、逐次的に求めることは可能\n","- 学習するとも表現し、深層NNでは「カーネル関数をデータに合わせて学習する方法」とも言える\n","  - 各層でデータから適応的にカーネル関数を獲得する点で、通常のカーネル法と異なる\n","\n","\n","### 初等的な例題的な勾配降下法の説明\n","\n","目的関数は多次元で複雑な形を有するが、パラメータ $w$ と目的関数 $\\mathcal{L}$ の値はシンプルな二次関数の形をもつとして、この目的関数が最小値を与えるような $w$ の決定を考える\n","\n","- NNのパラメータはまず乱数で初期化され、$w=3$ と初期化されたとする\n","\n","- 次に、$\\mathcal{L}$の勾配 $\\frac{\\partial \\mathcal{L}}{\\partial w}$ は、目的関数が全パラメータについて微分可能であると定義されており、 $\\mathcal{L}(w)$ という関数の接線の傾き(勾配; gradient)を必ず求めることができる\n","  - $w=3$のとき微分値が$3$ になったとする\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/3-11.png\" width=300>\n","\n","> 厳密には損失関数に微分不可能な点が存在する可能性があり、ReLUにおいても$x=0$ において微分不可能である\n","\n",">しかしながら、このような値に落ちることは稀で、簡単な例外処理で対応できるため無視してよい\n","\n","- 次に、$w$ の値が正であるため、$\\mathcal{L}$ の値を小さくするために傾きの逆方向へ $w$ を変化させる必要がある\n","  - さらに、勾配が大きいほど大きく変化させるため、$w$ **から** $\\partial \\mathcal{L} / \\partial w$ **を引く**という方針が見える\n","  - 実際には、$w$ の更新量のスケール(ステップサイズ)を調整するため、勾配に **学習率 (learning rate)** と呼ばれる値を乗じる\n","\n","> 例えば、学習率を $0.5$ とすると、$w$の更新量は **学習率** $\\times$ **勾配** となり、$0.5 \\times 3 = 1.5$ と求まる\n","\n","> $w=3$ からこの値を引いて$w \\leftarrow w - 1.5$ と更新すると、$w=1.5$ となる\n","\n","- これらの処理を繰り返すことで$\\mathcal{L}$が最小値をとるときの$w$の値に近づく\n","  - このような勾配を用いた目的関数の最小化手法を **勾配降下法** と呼ぶ\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tu8NmHaZig8i"},"source":["### ミニバッチ学習\n","\n","ニューラルネットワークを勾配降下法で最適化する場合、計算量削減のため、データを一つ一つ用いてパラメータを更新することは行わず、いくつかのデータをまとめて入力し、それぞれの勾配を計算したあとに、その勾配の平均値を用いてパラメータの更新を行う\n","- これを **ミニバッチ学習** と呼ぶ\n","\n","- ミニバッチ学習では、学習データセットから$k (>0)$ 個のデータを抽出し、その $k$ 個のデータに対する目的関数の平均の値を小さくするようにパラメータを更新するという作業を繰り返す\n","  - 他の異なる $k$ 個のデータの組み合わせに対しても繰り返す\n","  - 結果的にはデータセットに含まれる全てのデータを使用する\n","\n","実際には、次の処理を行う\n","\n","- データセット内のサンプルのインデックスをランダムにシャッフルして並べた配列を作成する\n","- その配列の先頭から $k$ 個ずつインデックスを取り出し、ミニバッチを構成する\n","- 全てのインデックスを使い切るまでの一連の処理を **1エポックの学習** と呼ぶ\n","\n","$k$ をバッチサイズもしくはミニバッチサイズと呼び、このような学習方法を**確率的勾配降下法 (SGD: Stocastic Gradient Descent)** と呼ぶ\n","\n","現在、ほとんどのニューラルネットワークにおける最適化手法はSGDを基本としている\n","- SGDを用いることで、計算時間が劇的に少なくできるだけでなく、図のように目的関数が凸関数でなかった場合であっても、適当な条件のもとで**ほぼ確実に**局所最適解に収束することが知られている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/3-14.png\" width=300>"]},{"cell_type":"markdown","metadata":{"id":"_eSwLE3ruvX9"},"source":["さらに、モデルの過学習を防ぐために、正則化を行う場合もある\n","\n","- 例えばL1正則化ではパラメータ$w_i$が学習が進むにつれ0になりやすくなるようにする\n","  - 結果的に層の間のリンクが失われる\n","  - すると、ノードの利用量を制限する方向に進む\n","  - このことから、**次元圧縮**という表現が用いられる\n","\n","- この次元圧縮という考え方は、DNNにおける重要な機能であり、正則化によらず、敢えて中間ノード数を減らすというテクニックとしても用いられる\n","\n","複雑なDNNは、収束しにくいと考えるかもしれない\n","- もちろん、そうではあるが、実際は計算さえできれば、かなり規模が大きくても収束してしまうようになってしまった\n","- つまり、かなり無茶しても結構収束してしまう、そういう手法ができてしまったと考えた方が良い\n","\n","L2正則化は、モデルの過学習を防ぐための手法の一つとして利用されている\n","- 過学習の防止策として他にも敢えて一部のノードの計算を省いて($w$を0として)計算するdropoutなどが存在する\n","- 繰り返すが、そういう無茶をしても収束できるようになってしまったと考えた方が良い\n","\n","もし、研究でDNNを利用するのであれば、「あえて収束しない方向に動く」方が楽に新発見ができるかもしれない\n","- GANでさえ収束するのである"]},{"cell_type":"markdown","metadata":{"id":"gtJOsYWkKPDj"},"source":["### パラメータ更新量の算出\n","\n","下図のような3層の全結合型ニューラルネットワークについて、1層目と2層目の間の線形変換を ${\\bf w}_1, {\\bf b}_1$、2層目と3層目の間の線形変換を ${\\bf w}_2, {\\bf b}_2$ というパラメータで表現する\n","- これらをまとめて $\\boldsymbol{\\Theta}$ とする\n","- 図ではバイアス ${\\bf b}_1, {\\bf b}_2$ は省略している\n","\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/3-08.png\" width=300>\n","\n","入力ベクトルを ${\\bf x}$、出力ベクトルを ${\\bf y} \\in \\mathbb{R}^N$（$N$ 次元実数ベクトル）とし、入力 ${\\bf x}$ に対応した「望ましい出力」である教師ベクトルを ${\\bf t}$ とする\n","\n","また、目的関数として前述の平均二乗誤差関数を用いる\n","\n","以下に、パラメータを乱数で初期化したあと、入力 ${\\bf x}$ が与えられたときの目的関数の各パラメータの勾配を計算し、各パラメータの更新量を算出する具体的方法を示す\n","\n","- 目的関数を改めてベクトル表記を用いて書き下すと次の通りとなる\n","$$\n","\\mathcal{L}({\\bf y}, {\\bf t}) = \\frac{1}{N} || {\\bf t} - {\\bf y} ||_2^2\n","$$\n","\n","  - ここで、$|| {\\bf t} - {\\bf y} ||_2^2$はユークリッドノルムの2乗を意味し、結果的に$({\\bf t} - {\\bf y})^T({\\bf t} - {\\bf y})$と同等となる\n","  \n","- さらに，ニューラルネットワーク全体を $f$ とすると、出力 ${\\bf y}$ は\n","$$\n","\\begin{aligned}\n","{\\bf y} &= f({\\bf x}; \\boldsymbol{\\Theta}) \\\\\n","&= a_2 ( {\\bf w}_2 a_1({\\bf w}_1 {\\bf x} + {\\bf b}_1) + {\\bf b}_2 )\n","\\end{aligned}\n","$$\n","と書くことができる\n","\n","  - ここで、1層目と2層目の，および2層目と3層目の間で線形変換のあとに施される非線形変換（活性化関数）をそれぞれ、$a_1、 a_2$としている\n","  \n","  - 以下、簡単化のため、各層間で行われた線形変換の結果を ${\\bf u}_1および {\\bf u}_2$とし，中間層の値、すなわち ${\\bf u}_1$ に活性化関数を適用した結果を ${\\bf h}_1$ とする\n","  - ただし、${\\bf u}_2$ に活性化関数を適用した結果は ${\\bf y}$ と表記する\n","\n","- これらの関係は以下のように整理できる。\n","\n","$$\n","\\begin{aligned}\n","{\\bf y} &= a_2({\\bf u}_2) \\\\\n","{\\bf u}_2 &= {\\bf w}_2 {\\bf h}_1 + {\\bf b}_2 \\\\\n","{\\bf h}_1 &= a_1({\\bf u}_1) \\\\\n","{\\bf u}_1 &= {\\bf w}_1 {\\bf x} + {\\bf b}_1\n","\\end{aligned}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"k1L6xptUs3l4"},"source":["#### パラメータ ${\\bf w}_2$ の更新量\n","\n","- 最初に、出力層に近い方のパラメータである${\\bf w}_2$ について、$\\mathcal{L}$ の勾配を求める\n","$$\n","\\begin{aligned}\n","\\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}_2}\n","&= \\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}} \\frac{\\partial {\\bf y}}{\\partial {\\bf w}_2} \\\\\n","&= \\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}} \\frac{\\partial {\\bf y}}{\\partial {\\bf u}_2} \\frac{\\partial {\\bf u}_2}{\\partial {\\bf w}_2}\n","\\end{aligned}\n","$$\n","\n","- この3つの偏微分はそれぞれ次の通りとなる\n","$$\n","\\begin{aligned}\n","\\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}}\n","&= -\\frac{2}{N} ({\\bf t} - {\\bf y}) \\\\\n","\\frac{\\partial {\\bf y}}{\\partial {\\bf u}_2}\n","&= \\frac{\\partial a_2}{\\partial {\\bf u}_2} \\\\\n","\\frac{\\partial {\\bf u}_2}{\\partial {\\bf w}_2} \n","&= {\\bf h}_1\n","\\end{aligned}\n","$$\n","\n","- ここで、活性化関数の入力に関する出力の勾配は次を求めることで得られる\n","$$\n","\\frac{\\partial a_2}{\\partial {\\bf u}_2}\n","$$\n","\n","- これは、例えば活性化関数にシグモイド関数を用いる場合では\n","$$\n","a_2({\\bf u}_2) = \\frac{1}{1 + \\exp(-{\\bf u}_2)}\n","$$\n","の微分となる\n","\n","- 実際に計算すると、\n","$$\n","\\begin{aligned}\n","\\frac{\\partial a_2({\\bf u}_2)}{\\partial {\\bf u}_2}\n","&= -\\frac{-(\\exp(-{\\bf u}_2))}{(1 + \\exp(-{\\bf u}_2))^2} \\\\\n","&= \\frac{1}{1 + \\exp(-{\\bf u}_2)} \\cdot \\frac{\\exp(-{\\bf u}_2)}{1 + \\exp(-{\\bf u}_2)} \\\\\n","&= \\frac{1}{1 + \\exp(-{\\bf u}_2)} \\cdot \\frac{1 + \\exp(-{\\bf u}_2) - 1}{1 + \\exp(-{\\bf u}_2)} \\\\\n","&= \\frac{1}{1 + \\exp(-{\\bf u}_2)} (1 - \\frac{1}{1 + \\exp(-{\\bf u}_2)}) \\\\\n","&= a_2({\\bf u}_2)(1 - a_2({\\bf u}_2))\n","\\end{aligned}\n","$$\n","となる\n","\n","つまり、シグモイド関数の勾配は、シグモイド関数の出力値を使って容易に求まることがわかる\n","- また、そのような関数が選ばれていることがわかる\n","\n","以上により、 ${\\bf w}_2$ の勾配を計算するのに必要な値は全て求まったことになる"]},{"cell_type":"markdown","metadata":{"id":"_wsLAxRdztiN"},"source":["### NumPyによる演算\n","\n","より具体的な理解を進めるため、実際にNumPyを使ってこれらを計算する\n","- ここでは簡単化のため、乱数は用いず、バイアスベクトルはすべて0で初期化されているとする\n","- 実際には重みとバイアスの初期化は乱数が基本である\n","  - 例えば0など同じ値で初期化すると、全ノードの損失関数の偏微分($\\frac{\\partial L}{\\partial w}$)が同じ値になり、最急降下法による修正量も同じになる\n","  - ノードにかかわらず重みやバイアスが同じ値になり、かつ、同じ重みやバイアスを持つノードは同じ値を伝番させ同じ勾配を得る\n","    - つまり同じ挙動を示すため、結果的に該当する層の次元数が見かけ上小さくなる\n","  - すなわち、そのニューラルネットワークが持つ表現力が低下したことを意味する\n","  - 多くの場合、学習がうまくいかないという現象が発生する\n","\n","さて、NumPyでの具体的演算は次の手順となる\n","- NumPyモジュールを読み込む\n","- 入力の配列を定義する\n"," - ここでは、図と同じとなるよう3次元ベクトル$(2, 3, 1)$を定義する\n"," - 正解として20 を与える"]},{"cell_type":"code","metadata":{"id":"fD0MA510V1f-"},"source":["import numpy as np\n","# 入力\n","x = np.array([2, 3, 1])\n","# 正解(教師データ)\n","t = np.array([20])\n","x, t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xY_osM20Ov8"},"source":["次に、パラメータを定義する\\\n","ここでは、以下の4つのパラメータを定義する\n","\n","- **1層目と2層目の間の線形変換のパラメータ**\n"," - ${\\bf w}_1 \\in \\mathbb{R}^{2 \\times 3}$ : 3次元ベクトルを2次元ベクトルに変換する行列\n"," - ${\\bf b}_1 \\in \\mathbb{R}^2$ : 2次元バイアスベクトル\n","- **2層目と3層目の間の線形変換のパラメータ**\n"," - ${\\bf w}_2 \\in \\mathbb{R}^{1 \\times 2}$ : 2次元ベクトルを1次元ベクトルに変換する行列\n"," - ${\\bf b}_2 \\in \\mathbb{R}^1$ : 1次元バイアスベクトル"]},{"cell_type":"code","metadata":{"id":"cBuj19ptXu1f"},"source":["# 1-2層間のパラメータ\n","w1 = np.array([[3, 1, 2], [-2, -3, -1]])\n","b1 = np.array([0, 0])\n","# 2-3層間のパラメータ\n","w2 = np.array([[3, 2]])\n","b2 = np.array([0])\n","w1, b1, w2, b2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2xT4AnmBXwIb"},"source":["実際の各層の計算は次の通りとなる"]},{"cell_type":"code","metadata":{"id":"d-ELmfkiKQfd"},"source":["# 中間層の計算\n","u1 = w1@x + b1\n","h1 = 1. / (1 + np.exp(-u1))\n","# 出力の計算\n","u2 = w2@h1 + b2\n","y = 1. / (1 + np.exp(-u2))\n","y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8t-YjO8BZ6kU"},"source":["答えは $0.95257194$ と求まる\n","\n","つまり、$f([2, 3, 1]^T) = 0.95257194$ となることがわかる\n","\n","次に上で求めた\n","\n","$$\n","\\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}_2}\n","= \\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}} \\frac{\\partial {\\bf y}}{\\partial {\\bf u}_2} \\frac{\\partial {\\bf u}_2}{\\partial {\\bf w}_2}\n","$$\n","\n","の右辺の3つの偏微分をそれぞれ計算する"]},{"cell_type":"code","metadata":{"id":"8RkBjaaaZ7U8"},"source":["# dL / dy\n","g_Ly = -2 / 1 * (t - y)\n","# dy / du_2\n","g_yu2 = y * (1 - y)\n","# du_2 / dw_2\n","g_u2w2 = h1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uPmRfu3_aXJG"},"source":["これらを掛け合わせると求めるパラメータ ${\\bf w}_2$ の勾配が得られる"]},{"cell_type":"code","metadata":{"id":"ZrKfXtzfaWk4"},"source":["# dL / dw_2: 求めたい勾配\n","g_Lw2 = g_Ly * g_yu2 * g_u2w2\n","g_Lw2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XN293R5NU1zP"},"source":["ここで得られる配列としてのベクトルが $\\partial \\mathcal{L} / \\partial {\\bf w}_2$ の値である\n","\n","- これを学習率でスケールさせれば、パラメータ ${\\bf w}_2$ を更新するこ値として利用できる\n","\n","更新式は、後述のSGDを用いて学習率を $\\eta$ とすると以下のようになる\n","\n","$$\n","{\\bf w}_2 \\leftarrow {\\bf w}_2 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}_2}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"HLAwYypPshj8"},"source":["#### 学習率（learning rate）について\n","\n","どのように漸近するかの程度を決める\n","- 学習率の値が大きすぎる場合、パラメータ更新の度、目的関数の値が振動したり，発散したりする\n","- また、小さすぎると収束に時間がかかる\n","  - そこで、学習率を適切に決定することがニューラルネットワークの学習においては重要\n","  \n","多くの場合、学習がきちんと進むもっとも大きな値を経験的に探すことになるが、シンプルな画像認識といったタスクであれば、大抵は最初に0.1~0.01といった値が用いられる場合が多い\n","- また、後述するが様々な最適化手法が提案されている"]},{"cell_type":"markdown","metadata":{"id":"SC0RoRpucZh9"},"source":["#### パラメータ ${\\bf w}_1$ の更新量\n","\n","次に，${\\bf w}_1$ の更新量を求める\n","\n","これには、${\\bf w}_1$ で目的関数 $\\mathcal{L}$ を偏微分した値が必要となるが、以下のように計算できる\n","\n","$$\n","\\begin{aligned}\n","\\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}_1}\n","&= \\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}} \\frac{\\partial {\\bf y}}{\\partial {\\bf w}_1} \\\\\n","&=\n","\\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}}\n","\\frac{\\partial {\\bf y}}{\\partial {\\bf u}_2}\n","\\frac{\\partial {\\bf u}_2}{\\partial {\\bf w}_1} \\\\\n","&=\n","\\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}}\n","\\frac{\\partial {\\bf y}}{\\partial {\\bf u}_2}\n","\\frac{\\partial {\\bf u}_2}{\\partial {\\bf h}_1}\n","\\frac{\\partial {\\bf h}_1}{\\partial {\\bf w}_1} \\\\\n","&=\n","\\frac{\\partial \\mathcal{L}}{\\partial {\\bf y}}\n","\\frac{\\partial {\\bf y}}{\\partial {\\bf u}_2}\n","\\frac{\\partial {\\bf u}_2}{\\partial {\\bf h}_1}\n","\\frac{\\partial {\\bf h}_1}{\\partial {\\bf u}_1}\n","\\frac{\\partial {\\bf u}_1}{\\partial {\\bf w}_1}\n","\\end{aligned}\n","$$\n","\n","これら5つの偏微分のうち、初めの1つはすでに求めた\n","\n","残りの4つもそれぞれ、\n","\n","$$\n","\\begin{aligned}\n","\\frac{\\partial {\\bf y}}{\\partial {\\bf u}_2}\n","&= {\\bf y}(1 - {\\bf y}) \\\\\n","\\frac{\\partial {\\bf u}_2}{\\partial {\\bf h}_1}\n","&= {\\bf w}_2 \\\\\n","\\frac{\\partial {\\bf h}_1}{\\partial {\\bf u}_1}\n","&= {\\bf h}_1(1 - {\\bf h}_1) \\\\\n","\\frac{\\partial {\\bf u}_1}{\\partial {\\bf w}_1}\n","&= {\\bf x}\n","\\end{aligned}\n","$$\n","\n","と計算できる\n","\n","NumPyを用いて実際に計算すると次のようになる"]},{"cell_type":"code","metadata":{"id":"v41tSnDkcbPk"},"source":["g_yu2 = y * (1 - y)\n","g_u2h1 = w2\n","g_h1u1 = h1 * (1 - h1)\n","g_u1w1 = x\n","# 上から du1 / dw1 の直前までを一旦計算\n","g_Lu1 = g_Ly * g_yu2 * g_u2h1 * g_h1u1\n","# g_u1w1は (3,) というshapeなので，g_u1w1[None]として(1, 3)に変形\n","g_u1w1 = g_u1w1[None]\n","# dL / dw_1: 求めたい勾配\n","g_Lw1 = g_Lu1.T@g_u1w1\n","g_Lw1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Al0CmLzTtyvR"},"source":["これが $\\partial \\mathcal{L} / \\partial {\\bf w}_1$ の値である\n","\n","この値を用いて、${\\bf w}_2$ と同様に以下の式でパラメータ ${\\bf w}_1$ を更新できる\n","\n","$$\n","{\\bf w}_1 \\leftarrow {\\bf w}_1 - \\eta \\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}_1}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"ZcNjZ-XTYafi"},"source":["## 最適化アルゴリズム\n","\n","ニューラルネットワークなど全ての機械学習の到達目標は**損失をゼロにする**ことであり、効率よく損失をゼロにするのが最適化アルゴリズムである\n","\n","- 何も見えない状態の山で谷底を目指すにはどうすればよいか？例えば、標高を誤差とすると、低いところを目指せばよいことになる\n","\n","まず、このような地図を書くためにはすべての点の高度を計算することになるが、2次元であればできなくもない(それでも大変であるが)\n","- 実際には数万以上の次元があるためこのような地図を書くことは非現実的である\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/approach.png\" width=300>\n","\n","ある場所にランダムに配置され、そこから最適な場所を目指すとき、次のような方針が考えられる\n","\n","- 足元の傾きを見て、より低い方法をみる\n","- 今まで辿ってきた経緯を見て、進むべき方向を決める\n","\n","様々な最適化方針があるが、これらの最適化アルゴリズムは全て最急降下法を基本としている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/ruder.io_content_images_2016_09_saddle_point_evaluation_optimizers.webp\" width=300>\n","\n","(Alec Radford Twitter)"]},{"cell_type":"markdown","metadata":{"id":"7SqvspOD2s_h"},"source":["### SGD(確率的勾配降下法)\n","$$\n","{\\bf w} \\leftarrow {\\bf w} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}}\n","$$\n","とする\n","- なお、$\\mathcal{L}は、\\mathcal{E}やE$ともしばしば表記される\n","\n","全てのデータについて勾配を計算せず、訓練データよりランダムにサンプルを取り出して勾配を求めて計算コストを抑えることを**確率的**と呼び、この点が最急降下法とSGDの唯一の違いである\n","- ローカルミニマム、つまり最小値ではなく、部分的な極小値に陥ったとしても、ランダムに選んだ結果、大きく外れてそこから抜け出すことができる可能性があることを意味する\n","- ただし、この方法は、乱択する計算する移動するを繰り返すという逐次的な計算が必要となり、並列化できないため処理速度向上が困難となる"]},{"cell_type":"markdown","metadata":{"id":"0OvGo3ykltHM"},"source":["- AdaGrad (エイダグラッド、アダグラード)\n","\n","学習が進むにつれてパラメータの更新量${\\bf h}$を低減させる手法である\n"," $$\n","{\\bf h} \\leftarrow {\\bf h} + \\left( \\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}} \\right)^2\n","$$\n","について、${\\bf h}$は単調増加し、結果として下記の${\\bf w}$は単調に減少する\n"," $$\n","{\\bf w} \\leftarrow {\\bf w} - \\eta \\frac{1}{\\sqrt h} \\frac{\\partial \\mathcal{L}}{\\partial {\\bf w}}\n","$$\n","\n","- なお、2乗を利用しているのはいつもの通り、単純に符号を外したいためである\n","\n","この方法は、更新幅が大きいままであれば収束が遅くなり、更新量が小さくなりすぎると最適解にたどり着かないため、調整が必要で、かつ調整は容易とは言えない"]},{"cell_type":"markdown","metadata":{"id":"Z9A29kgng2pP"},"source":["### ミニバッチSGD\n","\n","更新で使うデータ数を1つに限定すると並列性が活用できないため、そのデータ数を増やして並列化させる手法であり、一般的に16個や32個といった小さな塊であるミニバッチを用いて演算を行う\n","\n","しかしながら、SGDに基づいているため、ポテンシャルにおいて深い渓谷を形成するようなケース(Pathological Curvature)に対して追従が遅いという問題が残る\n","- これは、勾配が急な面が接近している場合に更新量が大きすぎ振動する結果、漸近速度が低下するためである\n","\n","  <img src=\"http://class.west.sd.keio.ac.jp/dataai/text/pathologicalcurvature.png\" width=\"50%\">\n","\n","そこで、振動を抑えるために過去の勾配変化を利用することが考えられ、次式の勾配もしくは学習\n"," \n","$$\n","\\begin{aligned}{\\bf w_{t+1}}&={\\bf w_t}-\\lambda \\frac{\\partial E({\\bf w})}{\\partial {\\bf w}}\\\\\n","&={\\bf w_t}-\\lambda \\nabla_{\\bf w}\\mathcal{L}({\\bf w})\\end{aligned}\n","$$\n","としたときの学習率$\\lambda$を調整する手法をRMSProp、ナブラとしての勾配$\\nabla_{{\\bf w}}$を調整する手法をモーメンタムと呼ぶ"]},{"cell_type":"markdown","metadata":{"id":"YlmlO8aWg52X"},"source":["### モーメンタム\n","\n","急激に変化するのを抑えたいならば、ローパスフィルタを取ればよく、最もシンプルな考え方は移動平均をとることである\n","\n","- 移動平均を用いて$\\lambda$を決定することを考える\n","\n","- 移動平均の求め方には様々あるが、ここで用いられる基本的な考え方は、最新の値$\\nabla_w\\mathcal{L}(w)$に対して、これまでの値$\\nu_{t-1}$と$N$の内分をとることである\n","\n","- ハイパーパラメタ$\\beta$を用いれば、\n"," $$\n","\\nu_t = \\beta\\nu_{t-1} + (1-\\beta)\\nabla_w\\mathcal{L}(w)\n","$$\n","となる\n","\n","- の$\\nu$を使って、\n"," $$\n","w_t = w_{t-1} - \\alpha \\nu_t\n","$$\n"," として$w_t$を更新する\n"]},{"cell_type":"markdown","metadata":{"id":"Y-s6cHZZjsku"},"source":["### RMSProp\n","\n","学習率を調整して振動を抑える手法で、振動方向の学習率を下げる、つまり、勾配の大きさに応じて学習率を調整する手法である\n"," \n","式にすると、\n","$$\n","\\nu_t = \\beta\\nu_{t-1} + (1-\\beta)(\\nabla_w\\mathcal{L}(w))^2 \\\\\n","w_t = w_{t-1} - \\frac{\\eta}{\\sqrt{\\nu_t + \\epsilon}} \\nabla_w\\mathcal{L}(w)\n","$$\n","となり、$\\epsilon$ はゼロ除算を避けるための極めて小さい値であり、それ以外の記号は既出である\n"," \n","- 負の値を避けるためであるが、移動平均の式の$N$が2乗で効いており、さらに、$\\nu_t$は$w$の更新式では分母にあるため、$w_{t-1}$の重みが結果的に増えて新しい更新値が反映されにくくなる\n","- 結果的に、振動を抑えることができる"]},{"cell_type":"markdown","metadata":{"id":"__lKeYlajtDh"},"source":["### Adam (アダム)\n","\n","一般に用いられる方法で、問題なければAdamを選択するとよい\n","\n","学習の進行度合いや過去の履歴に基づいて更新量を調整する方法で、モーメンタムとRMSPropの利点を併せた手法である\n","\n","例えば、次の式\n","$m_t = \\beta_1 m_{t-1} + (1-\\beta_1)\\frac{\\partial \\mathcal{L}}{\\partial w}$\n","について、$\\beta_1 m_{t-1}$は$t-1$つまり一つ前の情報を表し、$(1-\\beta_1)\\frac{\\partial \\mathcal{L}}{\\partial w}$は学習の進捗度合いを表しているように、過去の履歴と進捗の両方を利用する\n","\n","$$\n","m_0 = v_0 = 0\\\\\n","m_t = \\beta_1 m_{t-1} + (1-\\beta_1)\\nabla_w\\mathcal{L}(w)\\\\\n","v_t = \\beta_2 v_{t-1} + (1-\\beta_2)\\left(\\nabla_w\\mathcal{L}(w)\\right)^2\\\\\n","\\hat{m_t} = \\frac{m_t}{1-\\beta^t_1}\\\\\n","\\hat{v_t} = \\frac{v_t}{1-\\beta^t_2}\\\\\n","w_t = w_{t-1} - \\eta \\frac{\\hat{m_t}}{\\sqrt v_t + \\epsilon}\n","$$\n","\n","以上のようにして、${\\bf w_{new}} \\leftarrow {\\bf w_{old}}$の更新式を得るが、結局のところ勾配の移動平均と勾配の2乗の移動平均であり、それぞれモーメンタム及びRMSPropの構成式に他ならない\n"," 一方でパラメータも多く、$\\beta_1, \\beta_2, \\eta, \\epsilon$といった定数を定めなければならない\n","- これらのパラメータについて、提案者により妥当な値が提案されている\n","\n","なお、当然であるがAdmは万能ではない\n","- adamの場合、特定のバッチに有用な情報がたまたま集中していた場合、その情報は更新計算でかき消されてしまう、つまり、良いデータはとっておきたい、ということができない\n","\n","そこで、さらに改良版のAMSGradが提案されており、PyTorchなどもサポートしている\n","- これは、$\\hat{v_t} = max(\\hat{v}_{t-1}, v_t)$とすることで、良い値を残すという工夫がされている\n"]},{"cell_type":"markdown","metadata":{"id":"F4neOplOGg3H"},"source":["### なぜニュートン法を使わないのか\n","\n","このような漸近しつつ最適な値や解を求める方法として、ニュートン法が良く知られている\n"," $${\\bf w}_{t+1}={\\bf w}_t+\\frac{\\nabla_{\\bf w}\\mathcal{L}({\\bf w})}{\\nabla_{\\bf w}^2\\mathcal{L}({\\bf w})}$$\n"," ニュートン法が利用できれば、漸近速度は各段にアップし、2階微分まで考慮するためより正確に判定かつ収束できるが、最急降下法の2乗の計算量が必要となるという致命的欠点のため現時点で用いられることはない"]},{"cell_type":"markdown","metadata":{"id":"zIv_rP32uH1y"},"source":["## 誤差逆伝播法（バックプロパゲーション）\n","\n","各パラメータの目的関数の導関数から、実際に勾配を求めてパラメータ更新を行う方法について説明した\n","- より層数の多いニューラルネットワークの場合、同様の手順で導関数を求めることも可能であるが、ニューラルネットワークが微分可能な関数を繰り返し適用するものであるという性質を用いれば、プログラムにより自動的に勾配を与える関数を導き出すことも可能である\n","\n","下図は，(1) 3層の全結合型ニューラルネットワークの出力を得るための計算と、(2) 青い矢印でその値を使って目的関数の値を計算する過程を、さらに(3) 赤い矢印で各パラメータにおける目的関数の偏微分を計算する過程、以上の手順を表現している\n","\n","次のアニメーションはこの様子を的確に表しており、順伝播および逆伝播の様子が視覚的に示されている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/backpropagation.gif\" width=600>"]},{"cell_type":"markdown","metadata":{"id":"R8YaTki1Dhhx"},"source":["目的関数の出力を $l = \\mathcal{L}({\\bf y}, {\\bf t})$ 、丸ノードは変数、四角ノードは関数を表すとする\n","\n","ニューラルネットワーク全体を一つの巨大な合成関数 $f$ として表し、その中で各層間における線形変換の関数をそれぞれ $f_1$、$f_2$、非線形変換をそれぞれ $a_1$、 $a_2$ とすると、このような合成系での更新量の算出に**誤差逆伝搬**を用いる\n","\n","図の青矢印のように、新しい入力 ${\\bf x}$ が$f$により値 $l$を与えることを **順伝播（forward propagation）** と呼ぶ\n","\n","- ここで、各パラメータの更新量を求める際に必要となる目的関数の勾配は、各パラメータの丸ノードより先の出力側にある関数の勾配だけで計算できる\n","\n","- 具体的には上図の赤矢印のように、出力側から入力側に向かって**順伝播とは逆向きに**各関数における入力の勾配を求めて掛け合わせれば、各パラメータの目的関数の勾配が計算できる\n","\n","このように、ニューラルネットワークを構成する関数が持つパラメータの目的関数の勾配について、合成関数の微分で利用する連鎖律を用いて、**順伝播で通った経路を逆向きにたどるように**途中の関数の勾配の掛け算により求める方法を **誤差逆伝播法（backpropagation）** と呼ぶ\n","\n","- 誤差逆伝播に関する数式による説明は煩雑であるため、\n","[別途資料](http://class.west.sd.keio.ac.jp/dataai/data-AI-backpropagation.pdf)を提供するが、特に読むものでも覚えるものでもない\n","\n","- ここで理解してもらいたいのは、先人たちが、**如何に計算を楽にしつつ、過去存在した問題を解決するか**に挑戦し、解決する手法を構築してくれたということ、その手法を手に入れたので**大量にノードを繋げることができ、かつ最適化をきちんとできるようになった**ということ、そして大量につながった状態を人間が追いかけることに意味はなく、**その基本的な原理を正しく理解していれば利用できる**ということである\n","\n","  - プロセッサの動作原理は理解していても、数億トランジスタの配置や配線を一人でやるのはまず無理だ、というのと同じである"]},{"cell_type":"markdown","metadata":{"id":"uHGp6qIBcKOI"},"source":["## 勾配消失\n","\n","活性化関数について、シグモイド関数は勾配消失という現象が起きやすく、あまり利用されていないと述べた\n","\n","ガイダンスにおいても実験的に示されているが、この点について概説する\n","\n","シグモイド関数の導関数は、\n","\n","$$\n","\\begin{aligned}\n","f\\left( u\\right) &=\\dfrac {1}{1+e^{-u}} \\\\\n","f'\\left( u\\right) &= f\\left( u\\right) \\left( 1-f\\left( u\\right) \\right)\n","\\end{aligned}\n","$$\n","\n","と表現でき、この導関数のグラフは次の通りとなる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/3-09.png\" width=\"50%\">\n","\n","このように、入力が原点から遠くなるにつれ勾配の値が減少し、0に漸近する\n","\n","- 各パラメータの更新量を求めるためには、**そのパラメータよりも先のすべての関数の勾配を掛け合わせる**必要があるが、活性化関数にシグモイド関数を用いた場合、勾配は**最大でも0.25**となる\n","\n","- 結果として、層数が増えるほど入力に近い層の勾配が0に近づく\n","\n","**勾配消失（vanishing gradient）**とは、\n","\n","- ディープラーニングではより多くの層を積み重ねたNNが用いられるため、活性化関数としてシグモイド関数を使用すると**目的関数の勾配が入力に近い関数が持つパラメータへ全く伝わらず**、パラメータの更新量がほぼ0となる\n","\n","- 目的関数を大きな値にしても、入力層に近い関数が持つパラメータが更新により変化しなくなる、つまり、学習が行われないという状況に陥る\n","\n","- このことが深い（十数層を超えるような）ニューラルネットワークの学習が困難であった一つの要因であった\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IRvZlChZ9Qna"},"source":["## レイヤとは\n","\n","ニューラルネットワークを実装する際に利用する各種フレームワークでは、多くの場合その層タイプ(layer type)として様々な関数がまとめられており、この関数に対しても「層」もしくは「レイヤ」という言葉を用いる\n","- 誤差逆伝播法の図における丸ノード(中間出力などの値)に限らず、四角ノード(関数)についても層(layer)と呼ぶことに注意する\n","- この慣習は授業ではマイナスになる可能性もあるため、特に区別する際にはノード、もしくはニューロンと呼ぶ"]},{"cell_type":"markdown","metadata":{"id":"7dD2mgCOTvdW"},"source":["## 様々なレイヤタイプ\n","\n","ニューラルネットワークには大別して線形変換と非線形変換の二種類の関数が含まれ、特に線形変換の例として **全結合層（fully-connected layer）** について述べた\n","\n","実際のニューラルネットワークの構成要素として用いるレイヤは、全結合層と活性化関数だけではなく、例えば、画像データの扱いに長けている**畳み込み層(convolution layer)**を線形変換に用いる\n","\n","- 画像認識や画像生成、画像の変換や超解像(低解像の画像から解像度を高めた画像を作る技術)など、DNNでは画像応用が活発に行われているように、画像との相性がよい\n","\n","- これは、畳み込み層による恩恵といっても過言ではない\n","\n","  - レイヤは(一部微分不可能な点があってもよいが基本的に)微分可能な関数であればよい\n","  - **畳み込みニューラルネットワーク(convolutional neural networks; CNN)** では、畳込み層に加えてプーリング層（pooling layer）と呼ばれるレイヤを用いる\n","\n","そこで、CNNでよく用いられる**畳み込み層**と**プーリング層**について、その概要を説明する"]},{"cell_type":"markdown","metadata":{"id":"w-3rsIzXpCBo"},"source":["### 畳み込み層(convolution layer)\n","\n","全結合層は、出力を求めるためにパラメータ行列${\\bf W}$が全次元を備えており、かつその全ての要素（ベクトルであれば全次元の値）を用いる\n","\n","先に示した通り、順伝播ではノードの結合は、行列の要素の積で表現されており、パラメータ行列${\\bf W}$の$i, j$要素である$W_{ij}$と、入力データ${\\bf x}$の全要素で結合を表現している、つまり、ある層の全ノードが、次の層の全ノードへの結合を有することを意味す\\\n","これを全結合(fully-connected)と表現する\n","\n","- 畳み込み層は全結合層とは異なり、パラメータと入力データの間の結合が局所的にしか存在しない\n","\n","- 例えば、2次元畳み込み層では、パラメータはカーネル(もしくはフィルタ)と呼ばれる小さな画像パッチ(例えば6x6といった画像の一部分)を表す行列の集合とみなし、パッチごとに入力データの一部との間で演算が行われる\n","\n","次の図を用いて、$3 \\times 3$のサイズの小さな画像パッチに関する畳み込みカーネルを2つ持つ畳み込み層の計算過程を考える\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/convolution.gif\" width=\"50%\">\n","\n","左の青ブロックは入力画像を表す\\\n","入力は$5 \\times 5$ の大きさを持つRGBの3チャネル画像であり、チャネル数分縦に並べている\n","- これに次に説明するパディング処理により7$\\times$7に拡張されている\n","- $W0$、$W1$それぞれについて以下を計算する(アニメーションは$W1$のみ)\n","  - 後述するストライドは2である\n","  - 青のブロックと赤のブロックのアダマール積を各チャネル毎求めて、さらにその結果の全要素を足し集める\n","    - チャネル毎9要素、さらにチャネル3つ分、さらにバイアス値も全て足し合わせる\n","  - すると対象となるフィルタの3$\\times$3の行列が完成する"]},{"cell_type":"markdown","metadata":{"id":"7E6_6RsCF7t-"},"source":["#### パディング\n","\n","まず、パディング(padding)処理により、入力画像の周囲に値が0となる領域を付け足す\\\n","ここでは、幅1の領域をパディングしている\n","\n","- パディング処理は、行列演算上配列要素がデータの存在しない領域、具体的にはアクセスが許されていないメモリ部分へのアクセスを行わないように工夫している\n","\n","- 中央2列ある赤ブロックは、それぞれの列が1つの畳み込みカーネルを表す\n","  - 1つの畳み込みカーネルは、入力画像、もしくは中間層では特徴マップ(feature map)呼ばれる一つ前の層の出力が持つのと同数のチャネルを持つ\n","\n","- 3チャネル分の縦に並んだ3つの赤い$3 \\times 3$ブロックで表されており、$b$はバイアス、$W$はオペレータを意味する"]},{"cell_type":"markdown","metadata":{"id":"DMWhpjewGdYh"},"source":["#### ストライド\n","\n","各カーネルの各チャネルは、対応する入力のチャネルに対してスライドしながら計算を行う\n","\n","- このスライド幅をストライド(stride)と呼ぶ\n","図では2マス飛びに入力画像上を$3 \\times 3$の枠が移動しているため、ストライドは2である\n","\n","- 対象となる$3 \\times 3 = 9$個の要素を$W1$とそれぞれ掛け合わせた結果を全て足し(オペレータ演算)、さらにバイアス$b0$を足せば、$o[:,:,0]$の対応する左上の値$o[0,0,0]$が得られる\n","  - $W0$と$W1$に対応する演算があるため、出力の緑ブロックに2つの行列が存在する\n","  - これらを**フィルタ**と呼ぶ\n","\n","  - なお、ここでの掛け算は、アダマール積であり、結果として得られる$3 \\times 3$の値を全て足し集めれば、このカーネルの1つ目のチャンネルの1つ目の計算結果が得られる。ここでは、-2となる。\n","\n","このような演算がなぜ画像と親和性が高いかは、マルチメディアデザインの授業で学んだ画像処理の基本であるオペレータの概念が含まれていることから感覚的に理解できるであろう\n","\n","- オペレータは様々な特徴量、例えば、直線や三角、四角などの図形に特徴的に反応することができるため、これを抽出しているといえる\n","\n","- 2チャンネル目および3チャネル目も同様に計算すると、それぞれ0および1となり、最後に全てのチャネルの結果を足し合わせると結果は-1となる"]},{"cell_type":"markdown","metadata":{"id":"Tp9Ets7CG056"},"source":["#### バイアス\n","\n","最後に、これにカーネルごとに用意されるバイアスの値、例えば図では1つ目のカーネルのバイアスは$b0$であり1を足せば、このカーネルの入力の左上隅の領域に対する出力結果である0となる\n","\n","右の緑色ブロックで示される畳込み層の出力値について、1つ目のブロックの左上のマスには、この結果である0が記載されている\n","\n","- ここまで、個別のパラメータ値を用いた**重みを掛けてバイアスを足す** というシンプルな線形変換のみで構成されており、この変換はパラメータおよび入力について微分可能である\n","\n","  - 実際、カーネルサイズが $1 \\times 1$ のカーネルを用いた畳み込み演算は各入力次元に同一の重み行列を用いた線形変換を施すのと同じである\n","\n","  - たとえば，入力幅$W$と高さ$H$の$W \\times H$ で3チャンネルである場合、カーネルサイズが $1 \\times 1$ の畳み込み層のカーネルは $1 \\times 1 \\times 3$ のテンソル、バイアスは1次元のスカラーとなる\n","\n","- この$W \\times H$ 個の全ての入力次元について、テンソルとスカラーによる線形変換を施すことになる\n","\n","このように、畳み込み層はカーネルを様々に定義することで多様なデータ形式を扱うことができる\n","- データに合わせて、例えば温度センサの時系列データであれば1次元のカーネルを、動画やボクセルであれば3次元のカーネルを用いればよい"]},{"cell_type":"markdown","metadata":{"id":"SUEmd9pOKe2D"},"source":["### プーリング層（pooling layer）\n","\n","プーリングは主に特徴マップに対して行われる操作であり、特徴マップの空間方向の次元(spatial dimension、つまり入力画像における幅・高さに対応する次元)の大きさを削減し計算量を抑える目的や、物体の微小な平行移動によって出力が変化しないようにして画像認識処理におけるロバスト性向上をはかる目的に利用する\n","\n","- プーリングにおける計算対象範囲や方法は畳み込みと類似しているが、対応する入力の部分領域に対する平均や最大値を求める演算が行われる\n","- 従って、畳み込みカーネルを用いるような計算は行わず、また、関連するパラメータも存在しない\n","\n","部分領域ごとの平均値を計算する場合を平均値プーリング(average pooling)、最大値を計算する場合を最大値プーリング(max pooling)と呼ぶ\n","\n","具体的には、次の図のような処理が行われる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/pooling.png\" width=\"50%\">\n","\n","図の左側は、プーリング層を用いたダウンサンプリング処理を示している\n","- サイズが$224 \\times 224$、$64$ チャネルの特徴マップに適用し、縦横両方について半分の大きさ($112 \\times 112$のサイズで情報量は1/4)の特徴マップに変換している\n","- このとき、チャネル数(画像ではdepthとも呼ぶ)は$64$で維持されている\n","\n","図の右側にその具体的な計算方法を示す\n","- $8 \\times 8$の入力について、$2 \\times 2$ 領域ごとに最大値で置き換えるという処理が示されている\n","- 例えば左上の$[1,1,5,6]$という要素について、その領域の最大値である6が選択されている\n","- これをストライド数2でずらしながら求めれば、右の$2 \\times 2$の行列が得られる"]},{"cell_type":"markdown","metadata":{"id":"Zo9ueLQWXeZ9"},"source":["## 普遍性定理\n","\n","隠れ層を一つしか持たないネットワークでも任意の関数を近似できることが証明されている\n","\n","- では、深いネットワークではなく、多数のノードからなる隠れ層を一つだけ持つ浅いネットワークを用いれば十分ではないか？と考えるかもしれない\n","\n","- 原理的にはその通りであるが、深い構造を使って**段階的に複雑な関数を近似する**方が、浅い構造を用いるよりも全体のノード数を削減できることがわかっており、浅くするのはノード数が爆発し非現実的であるといえる\n","\n","- これは、脳の構造も複雑な処理や機能を限られた期間で実現するために複雑なネットワークを構成していることにも通じる\n","\n","  - 例えば、パリティ演算を行う際に、浅いネットワークではビット長に対して指数関数的にノード数が必要となり大量のノードが必要となる\n","  - これを深いネットワークとすることでビットの組についてパリティ演算を繰り返すことになるため規模を削減できる\n","    - パリティ演算は、XOR演算であり初期の機械学習において分類不能であった問題である\n","\n","- また、区分線形関数を活性化関数に用いたネットワークに関しても、深いネットワークに優位性があることが示されている\n","\n","## なぜ深いネットワークは2010年頃までタブーであったか？\n","\n","とにかく収束せず、計算コストが大きい割に、メリットがなかったというのが当時の状況であったが次のような技術の登場で状況が変化した\n","\n","- ReLU\n","\n"," $max(0, x)$を活性化関数に用いて、長いネットワークにおける勾配消失問題に対応できるようになった\n","  - なぜこのような簡単な関数が使われなかったのか？なぜ誰も指摘しなかったのか？\n","\n","- Dropout\n","\n"," ランダムに学習に用いる際のネットワーク結合の計算を意図的にスキップすることで、正則化効果が得られる\n","  - そんなことをしてよいのか、それほど適当でよいのか？\n","  - 過学習を防ぐという意味では様々な提案が行われており、Dropoutの必要性は薄れている\n","\n","- Resideual Learning\n","\n"," あるブロック(複数のレイヤの纏まり)の出力に、そのブロックへの入力を足すという構造を持たせる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/residualunit.png\" width=\"40%\">\n","\n","> この図から表現できる、$f^{(l+)}(x)= f^{(l)}(x)+x$  という関係式について勾配を計算すると、\n","$$\n","\\begin{align}\n","{\\partial f^{(l+)} \\over \\partial x} &= {\\partial f^{(l)} \\over \\partial x} + 1\\\\\n","&= w_l + 1\n","\\end{align}\n","$$\n","となる\n","\n","つまり、この構造を$l$個つなげても、\n","$$(w_l+1)(w_{l-1}+1)(w_{l-2}+1)(w_{l-3}+1)\\cdots(w_1+1)$$となり、$w$が小さな値の場合でも$(w+1)$はほぼ1になる\n","- 従って勾配消失を防ぐことができる\n","\n","- ミニバッチ\n","\n"," 毎回パラメータを更新せず、ミニバッチ毎の平均でパラメータを更新する\n","  - ローカルミニマムからの脱出できる可能性が増大\n","  - GPUなど科学技術計算用ハードウエアとの相性が抜群によい\n","  - 過学習も抑える\n","\n","- 最適化手法の発展\n","\n","- 様々なtrickの発見\n","\n","但し、既に述べた通り、計算資源を10倍にしても、機械学習としての性能は数%しか向上しないという状況が多い中で、閉塞感が漂いつつある\n"]},{"cell_type":"markdown","metadata":{"id":"WWfaNea0aFYz"},"source":["## エポック・バッチ\n","\n","学習を行う際の単位について概説する\n","\n","特に混乱するのは、エポックとバッチの違いである\n","\n","**エポック(epoch)**とは\n","- 全ての訓練データを1通り学習すること\n","- 1エポックで訓練データを全て使い切る\n","\n","**バッチ(batch)**とは\n","- 入力と正解のペア(データの要素、サンプル)の集合\n","- 学習の単位でバッチごとに学習が行われる\n","- **バッチサイズ**はバッチに含まれるサンプル数\n","\n","つまり、1エポックは複数のバッチで構成される\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/batch.png\" width=\"30%\">"]},{"cell_type":"markdown","metadata":{"id":"jo9DlGKXgcPj"},"source":["### バッチと学習方法\n","\n","バッチに基づく学習方法には次の種類がある\n","\n","**バッチ学習**\n","- バッチサイズは訓練データの数に等しく、全ての訓練データを1度の学習で使い切る\n","- 全データを利用するため学習が安定しやすいが、全データを使うとポテンシャルの形状が複雑になりやすく局所最適解に陥りやすい\n","\n","**オンライン学習**\n","- バッチサイズは1つまり、1サンプル毎学習するため、1エポックの学習回数は訓練データの数に等しい\n","- 毎回学習させるため、学習が決まった方向に進みづらく、局所最適解に陥りにくい\n","- 一方で、毎回異なる方向に進みがちであるため学習を安定させることが難しくなる\n","- コストが大きいため、殆ど応用では見られない\n","\n","**ミニバッチ学習**\n","- 訓練データを小さなサイズのバッチに分割し、バッチごとに学習する\n","- バッチ学習とオンライン学習の中間的存在で利点を併せ持つ手法\n","\n","学習の例\n","- 訓練データが1000サンプルある場合\n","  - バッチ学習では1エポックで全部使って1回学習\n","  - オンライン学習では1エポックで1000回学習\n","  - ミニバッチ学習では、例えばバッチサイズを50に設定すると、1エポックあたり20回学習\n","    - 一般的にミニバッチ学習が用いられ、バッチサイズは10から100程度が多い\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SgQBJAEcj1xU"},"source":["### DataLoader\n","\n","バッチ処理の煩雑さを低減するため、ライブラリにはDataLoaderと呼ばれる機能が備わっている\n","- scikit-learn、PyTorchなどの機械学習フレームワークでも標準で準備されている機能\n","\n","- データセットからデータをバッチサイズごとにまとめて返す\n","- ランダムにデータを集めてバッチを構成する機能を提供する\n","- データの読み込み、前処理、ミニバッチ法を\n","簡単に実装できる\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dv49v9qMkDDB"},"source":["### CPU、GPU、TPU\n","\n","CPU（Central Processing Unit）\n","- コンピュータにおける中心的な処理装置\n","\n","GPU（Graphics Processing Unit）\n","- 画像処理に特化した演算装置だが、画像処理以外でも活用される\n","- CPUよりも並列演算性能にすぐれ、行列演算が得意\n","- ディープラーニングでよく利用される\n","  - 本来は3Dなど高速にコンピュータグラフィックスを描画するために設計された専用の計算機ハードウエア\n","  - 3DグラフィックスはゲームやGUIなどで求められ、大量の行列演算が伴う\n","  - GPUは**異なる大量データセットに同一の演算を高速に行うことに特化**しているのが特徴\n","  - この特徴は、多くの科学計算にも共通して現れるため、GPUを一般化し、行列演算などを高速化するハードウエアとして利用することも広く行われている。これを特に、GPGPU (General Purpose GPU)と呼ぶ\n","  - 現在のハイエンドGPUボードは基本的にAI演算用に特化しており、また用いられる\n","    - 機械学習やビットコインのマイニング、力学や環境学シミュレーションなどで利用されている\n","  - 特に汎用演算にも考慮したGPUをGPGPU(General Purpose GPU)と呼び、nVIDIAが提供するGPGPUライブラリとして著名なのがcudaである\n","\n","TPU（Tensor processing unit）\n","- Google社が開発した機械学習計算用集積回路"]},{"cell_type":"markdown","metadata":{"id":"kAOYXorEeCqP"},"source":["## 深層学習のプログラミング\n","\n","次のような技術用語が各計算用語が用いられるので、整理する\n","\n","- 各種レイヤのforward計算：全結合のような線形変換、各種活性化関数、Dropout、ロス関数など\n","- 各種レイヤのbackword計算：自動微分(autograd)を用いて出力に対する入力の微分を求める\\\n","autogradでは、ロス関数に対する全パラメータについての勾配を計算し、連鎖率で求める\n","- 最適化手法(optimizer)：計算した勾配を用いてパラメータを更新する\n","\n","## 深層学習の歴史\n","\n","- 2010年にImageNet Large Scale Visual Recognition Challenge (ILSVRC)がスタートしたことに始まる\n","\n"," - 1000万枚、1万クラスのサブセット128万枚1000クラスを学習データとして用いるコンペ\n"," \n","  - 2010は画像、2011年は矩形で場所を特定、2012年は犬の種類、2013年は物体検出、2015年は動画の物体検出とシーン分類、2016年はシーンのセグメンテーションタスクが追加\n","\n","- 2011年 IBM Watsonがクイズ番組「ジェパディ!」での人間と対戦デモし勝利\n","\n","- 2012年にトロント大学のチームがDLを用いて2位以下を10%以上引き離す圧倒的な認識率をたたき出すことでDLブームに\n","\n","- 2010年に28.2%程度存在したエラー率は、2011年25.8%、2012年に16.3%(凄い！)、2013年11.7%、2014年にGoogleNetが6.66%、2015年にはResNetで3.57%を達成、ここで5.1%のエラー率である人間を抜き去り、2017年では2.25%までエラー率が削減、人間を超える\n","\n","- 2012年 Alexnet\n","\n"," ReLU、max poolingなどが利用された。このpre-trained modelを初期値とした転移学習の研究も多く登場\n","\n","- 2014年 GoogleNet\n","\n"," Inceptionモジュールと呼ばれる複数の枝分かれをもったブロックを含む22層の畳み込みネットワーク\n","\n","- 2014年 VGG\n","\n"," 3x3の小さなカーネルサイズの畳み込み層を重ねて並べて配置した構造を利用することで、大きなカーネルを1つ備えるよりも少ないパラメータ数で大きな領域の情報を扱う\n","\n","- 2015年 ResNet\n","\n"," 22層から152層へと拡張させ、会場騒然オーマイガー！に\n","   - 1502層まで学習に成功するが精度向上には至っていない\n","\n"," - Google DeepMindによるAlphaGoがプロ囲碁棋士を互先（ハンディキャップなし）で勝利、AIブームの火付け役に\n"," \n","- 2016年 Wide-ResNet\n","\n"," ResNetの各層を広くし、30%から40%のDropoutを入れるなどの提案\n","\n","- 2016年 ResNeXt\n","\n"," 同じトポロジのブロックを重ねてハイパーパラメータチューニングを易化させる提案\n","\n"," cardinalityという次元を設け、同一の計算量ならば、深さや幅よりも、cardinalityを増やす方が性能が向上することを示している\n","\n"," cardinalityとは、情報密度・情報濃度のような概念であり、\n"," - 低cardinality\n","\n","   性別や存在するしない、アンケートのYes/Noといったデータの場合、カラムのデータの種類がテーブルのレコード数に比べて二種類と少なくなるが、このような状態を**カーディナリティが低い**という\n"," \n"," - 高cardinality\n"," \n","    一般に度合いやIDなどの情報で、カラムのデータの種類がテーブルのレコード数に比べて多い場合、 **カーディナリティが高い**という\n","\n"," ダミー変数化として、既に学習済みで国名や都市名などは、one-hotに加工したが、cardinalityが低下している\n","\n"," ターゲットエンコーディングは、カテゴリのうち正解である割合や確率を変数として与える手法\n","\n"," スムージングでは、確率的に少ない数の目的変数が全て1であった場合、これは逆に信頼するべきではない\n","\n","  - 例えば、大会で和歌山県1回出場1回入賞で入賞率100%と、東京都10出場9回入賞で入賞率90%、どちらがこの大会に強い都道府県といえるだろうか？\n","\n","  ターゲットエンコーディングでは、クラスタ$i$のデータ数$n_i$そのうち目的変数が1である数を$n_{iy}$とすると、$S_i=\\frac{n_{iy}}{n_i}$としている\n","  \n","  スムージングでは、さらにデータ総数$n_{tr}$、そのうちの全ての目的変数が1である数を$n_y$とすると、\n","    - $S_i = \\lambda(n_i)\\frac{n_{iy}}{n_i}+(1-\\lambda(n_i))\\frac{n_y}{n_{tr}}$とする\n","    - $\\lambda$は単調増加[0,1]の区間の値をとる関数である\n","    - 具体的には、 $\\lambda(n_i)=\\frac{1}{1+e^{-\\frac{n_j-k}{f}}}$という式が知られており、$k$および$f$のパラメタを用いてチューニングする\n","\n","- 2017年 DenseNet\n","\n"," ResNetのようなResidual connectionをあちこちに配置することで、より勾配が伝達しやすくした\n","\n","- 2017年 Squeeze-and-Excitation\n"," グローバルな情報を使って、有益な特徴を強調し、そうではない特徴を抑制す る手法で、チャネルの空間方向の和を取得した(squeeze)後、チャネル数の次元を持つベクトルで特徴マップに重み付け(excitation)する\n","\n"," - ILSVRCは2017年を最後に、Kaggleへと移行\n"," - 議論はソフトからハードへ\n","   ハードウェアでは、プルーニングやdropoub最適化、層の融合と分解、量子化などでメリットが活用できる\n","   - 各社よりライブラリが提案される\n"," \n","- 2018年 エッジAIという概念が浸透し、専用ハードウェアが次々に登場\n","  - マイクロアーキによるAI\n","   - 様々なAIエッジコンピューティングノードが提案された\n","\n","- 2019年 説明可能性・説明能力の議論が活発化\\\n"," 利用先が進むにつれてメジャーになった問題\\\n"," 教育課程化や応用の議論が活発化\\\n"," 実世界AI、協調型AI、Federated Learning(連合学習)といった考え方\n","\n"," - 既に「ディープラーニングはすでに限界に達しているのではないか？」という意見も出つつある\n","\n"," - LightGBM\n"," 決定木アルゴリズムに基づいた勾配ブースティングの機械学習フレームワークでマイクロソフトがスポンサー\n","\n"," - Neural Network Console\\\n","ソニーが提供するコーディングなしでDLによるAI開発ができるフレームワーク\n","  - このような性能よりも民生化を訴えるシステム・サービスも登場\n","  - https://dl.sony.com/ja/\n","\n","**Kaggle上位が利用するアルゴリズムは注目しておくとよい**\n"]},{"cell_type":"markdown","metadata":{"id":"d7lxBDHgqn0a"},"source":["# 課題\n","\n","## 用語のまとめ\n","\n","次の用語について、それぞれ100文字程度でまとめなさい。これらは、今後の授業でも扱います。\n","- 最適化アルゴリズム\n","- バッチとエポック\n","- 畳み込み層\n","\n","## 調査とまとめ\n","\n","2010年頃まで、層数の多いネットワークはタブーであった。\n","- なぜ層数の多いネットワークは利用されなかったのか\n","- どのような技術が層数の拡大を可能としたのか\n","\n","以上についてそれぞれ100文字程度で説明しなさい\n","\n"]}]}